{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ea33c3d-33ef-4d16-b6dd-dab49894ae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2df49a4-e3b4-4312-a3c7-07b83b30d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "from joblib import Parallel, delayed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07783727-bed0-4967-9aa6-8d039795b92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv('inputs/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09122991-da4b-4efe-b8e9-15d392e5d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['length_of_text'] = train['discourse_text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8907ed3d-c2b2-4472-a5d8-4ef879afbd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner(df_texts, df_train):\n",
    "    all_entities = []\n",
    "    for _,  row in tqdm(df_texts.iterrows(), total=len(df_texts)):\n",
    "        total = len(row['text_split'])\n",
    "        entities = ['0'] * total\n",
    "\n",
    "        for _, row2 in df_train[df_train['id'] == row['id']].iterrows():\n",
    "            discourse = row2['discourse_type']\n",
    "            list_ix = [int(x) for x in row2['predictionstring'].split(' ')]\n",
    "            entities[list_ix[0]] = f'B-{discourse}'\n",
    "            for k in list_ix[1:]: entities[k] = f'I-{discourse}'\n",
    "        all_entities.append(entities)\n",
    "\n",
    "    df_texts['entities'] = all_entities\n",
    "    print('Completed mapping discourse to each token.')\n",
    "    return df_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d5baf6-5938-477d-bbaf-57676b6704f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73e32979-dd15-4290-8dca-43e65ea4b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_essays(train_flg):\n",
    "    folder = 'train' if train_flg else 'test'\n",
    "    names, texts =[], []\n",
    "    for f in tqdm(glob.glob(f'inputs/{folder}/*.txt')):\n",
    "        names.append(f.split('/')[-1].replace('.txt', ''))\n",
    "        texts.append(open(f, 'r').read())\n",
    "        \n",
    "\n",
    "    df_texts = pd.DataFrame({'id': names, 'text': texts})\n",
    "    df_texts['text_split'] = df_texts.text.str.split()\n",
    "    print('Completed tokenizing texts.')\n",
    "    return df_texts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac3dbb21-33bf-452c-bcdb-efa23f200520",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15594/15594 [00:00<00:00, 37145.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed tokenizing texts.\n"
     ]
    }
   ],
   "source": [
    "df_texts = agg_essays(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b62ecd0-f58e-452d-9479-1258fb645bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15594/15594 [05:12<00:00, 49.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed mapping discourse to each token.\n"
     ]
    }
   ],
   "source": [
    "df_texts = ner(df_texts,train_corrected )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "88b1d5a7-8846-40fc-a361-c9140d0f547f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_split</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>293C1D45E66B</td>\n",
       "      <td>During the summer, students get do to do as th...</td>\n",
       "      <td>[During, the, summer,, students, get, do, to, ...</td>\n",
       "      <td>[B-Position, I-Position, I-Position, I-Positio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6DFF43AD5171</td>\n",
       "      <td>Dear Principle,\\n\\nI think we should have cell...</td>\n",
       "      <td>[Dear, Principle,, I, think, we, should, have,...</td>\n",
       "      <td>[0, 0, B-Position, I-Position, I-Position, I-P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84D2A6C75C67</td>\n",
       "      <td>Talking to more than one person for ideas or a...</td>\n",
       "      <td>[Talking, to, more, than, one, person, for, id...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>838005D1D7DC</td>\n",
       "      <td>The Face on Mars is just a natural landform. M...</td>\n",
       "      <td>[The, Face, on, Mars, is, just, a, natural, la...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F59DDBF5DB0B</td>\n",
       "      <td>Have you ever wondered why so many people in t...</td>\n",
       "      <td>[Have, you, ever, wondered, why, so, many, peo...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text  \\\n",
       "0  293C1D45E66B  During the summer, students get do to do as th...   \n",
       "1  6DFF43AD5171  Dear Principle,\\n\\nI think we should have cell...   \n",
       "2  84D2A6C75C67  Talking to more than one person for ideas or a...   \n",
       "3  838005D1D7DC  The Face on Mars is just a natural landform. M...   \n",
       "4  F59DDBF5DB0B  Have you ever wondered why so many people in t...   \n",
       "\n",
       "                                          text_split  \\\n",
       "0  [During, the, summer,, students, get, do, to, ...   \n",
       "1  [Dear, Principle,, I, think, we, should, have,...   \n",
       "2  [Talking, to, more, than, one, person, for, id...   \n",
       "3  [The, Face, on, Mars, is, just, a, natural, la...   \n",
       "4  [Have, you, ever, wondered, why, so, many, peo...   \n",
       "\n",
       "                                            entities  \n",
       "0  [B-Position, I-Position, I-Position, I-Positio...  \n",
       "1  [0, 0, B-Position, I-Position, I-Position, I-P...  \n",
       "2  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "3  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "4  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef25c6e3-d2e8-4a96-88ee-a6db3ef2498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_check(df_texts,train_corrected):\n",
    "    \n",
    "    ids = df_texts[\"id\"].unique()\n",
    "\n",
    "    ids_splits = np.array_split(ids, 4)\n",
    "#     multiprocessing\n",
    "    results = Parallel(n_jobs=4, backend=\"multiprocessing\")(\n",
    "        delayed(ner)(df_texts[df_texts.id.isin(idx)],train_corrected) for idx in ids_splits\n",
    "    )\n",
    "   \n",
    "    df_results = pd.concat(results)\n",
    "    \n",
    "    return df_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9a253a-92c0-4343-932f-39b18bb8822e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "595a500e-4f33-416b-a40b-606cf39551d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e57c747d-4c0f-42f0-b920-da60901bbaa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3899/3899 [01:40<00:00, 38.96it/s]\n",
      " 98%|█████████▊| 3839/3899 [01:38<00:01, 32.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed mapping discourse to each token."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 3846/3898 [01:36<00:01, 40.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3898/3898 [01:37<00:00, 40.00it/s]\n",
      "100%|█████████▉| 3888/3899 [01:39<00:00, 29.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed mapping discourse to each token.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3899/3899 [01:39<00:00, 39.05it/s]\n",
      " 98%|█████████▊| 3812/3898 [01:36<00:02, 41.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed mapping discourse to each token.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3898/3898 [01:38<00:00, 39.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed mapping discourse to each token.\n",
      "total time taken is 113.8557538986206\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "cc  = prepare_data_check(df_texts,train_corrected)\n",
    "print(f'total time taken is {time.time()-start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "737a0e1f-103c-4131-ab4f-9bbf5c09d0e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_split</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>293C1D45E66B</td>\n",
       "      <td>During the summer, students get do to do as th...</td>\n",
       "      <td>[During, the, summer,, students, get, do, to, ...</td>\n",
       "      <td>[B-Position, I-Position, I-Position, I-Positio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6DFF43AD5171</td>\n",
       "      <td>Dear Principle,\\n\\nI think we should have cell...</td>\n",
       "      <td>[Dear, Principle,, I, think, we, should, have,...</td>\n",
       "      <td>[0, 0, B-Position, I-Position, I-Position, I-P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84D2A6C75C67</td>\n",
       "      <td>Talking to more than one person for ideas or a...</td>\n",
       "      <td>[Talking, to, more, than, one, person, for, id...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>838005D1D7DC</td>\n",
       "      <td>The Face on Mars is just a natural landform. M...</td>\n",
       "      <td>[The, Face, on, Mars, is, just, a, natural, la...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F59DDBF5DB0B</td>\n",
       "      <td>Have you ever wondered why so many people in t...</td>\n",
       "      <td>[Have, you, ever, wondered, why, so, many, peo...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15589</th>\n",
       "      <td>44A73349B60A</td>\n",
       "      <td>When looking for advice on a decision, do you ...</td>\n",
       "      <td>[When, looking, for, advice, on, a, decision,,...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15590</th>\n",
       "      <td>0C8E8861F91A</td>\n",
       "      <td>I agree with the claim against the value of us...</td>\n",
       "      <td>[I, agree, with, the, claim, against, the, val...</td>\n",
       "      <td>[B-Position, I-Position, I-Position, I-Positio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15591</th>\n",
       "      <td>6E534D6E2282</td>\n",
       "      <td>Some people like to drive while otherss don't ...</td>\n",
       "      <td>[Some, people, like, to, drive, while, otherss...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15592</th>\n",
       "      <td>A2A4548C52DA</td>\n",
       "      <td>Phones have come a very long way since 1973, p...</td>\n",
       "      <td>[Phones, have, come, a, very, long, way, since...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15593</th>\n",
       "      <td>7003A818F22D</td>\n",
       "      <td>Our Founding Fathers created a new concept of ...</td>\n",
       "      <td>[Our, Founding, Fathers, created, a, new, conc...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15594 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                               text  \\\n",
       "0      293C1D45E66B  During the summer, students get do to do as th...   \n",
       "1      6DFF43AD5171  Dear Principle,\\n\\nI think we should have cell...   \n",
       "2      84D2A6C75C67  Talking to more than one person for ideas or a...   \n",
       "3      838005D1D7DC  The Face on Mars is just a natural landform. M...   \n",
       "4      F59DDBF5DB0B  Have you ever wondered why so many people in t...   \n",
       "...             ...                                                ...   \n",
       "15589  44A73349B60A  When looking for advice on a decision, do you ...   \n",
       "15590  0C8E8861F91A  I agree with the claim against the value of us...   \n",
       "15591  6E534D6E2282  Some people like to drive while otherss don't ...   \n",
       "15592  A2A4548C52DA  Phones have come a very long way since 1973, p...   \n",
       "15593  7003A818F22D  Our Founding Fathers created a new concept of ...   \n",
       "\n",
       "                                              text_split  \\\n",
       "0      [During, the, summer,, students, get, do, to, ...   \n",
       "1      [Dear, Principle,, I, think, we, should, have,...   \n",
       "2      [Talking, to, more, than, one, person, for, id...   \n",
       "3      [The, Face, on, Mars, is, just, a, natural, la...   \n",
       "4      [Have, you, ever, wondered, why, so, many, peo...   \n",
       "...                                                  ...   \n",
       "15589  [When, looking, for, advice, on, a, decision,,...   \n",
       "15590  [I, agree, with, the, claim, against, the, val...   \n",
       "15591  [Some, people, like, to, drive, while, otherss...   \n",
       "15592  [Phones, have, come, a, very, long, way, since...   \n",
       "15593  [Our, Founding, Fathers, created, a, new, conc...   \n",
       "\n",
       "                                                entities  \n",
       "0      [B-Position, I-Position, I-Position, I-Positio...  \n",
       "1      [0, 0, B-Position, I-Position, I-Position, I-P...  \n",
       "2      [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "3      [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "4      [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "...                                                  ...  \n",
       "15589  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "15590  [B-Position, I-Position, I-Position, I-Positio...  \n",
       "15591  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "15592  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "15593  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "\n",
       "[15594 rows x 4 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d678e490-9ef0-46fa-8eec-fe93fda8580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7d0e91a3-e56b-488b-a0f3-71bef8d40ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prepare_data_helper_check(tokenizer, df,df_train,inference=False):\n",
    "    samples = []\n",
    "    all_entities = []\n",
    "    for _, row in tqdm(df.iterrows(),total=len(df)):\n",
    "          \n",
    "        \n",
    "        text = row['text']\n",
    "        encoded_text = tokenizer.encode_plus(\n",
    "            text.split(),\n",
    "            is_split_into_words = True,\n",
    "            padding = 'max_length',\n",
    "            return_attention_mask = True,\n",
    "            add_special_tokens=True,\n",
    "            return_offsets_mapping=True,\n",
    "            truncation = True,\n",
    "            max_length = 2022\n",
    "        )\n",
    "        input_ids = encoded_text[\"input_ids\"]\n",
    "        input_labels = copy.deepcopy(input_ids)\n",
    "        word_ids = encoded_text.word_ids()\n",
    "        offset_mapping = encoded_text[\"offset_mapping\"]\n",
    "        attention_mask = encoded_text[\"attention_mask\"]\n",
    "\n",
    "        for k in range(len(input_labels)):\n",
    "            input_labels[k] = \"O\"\n",
    "\n",
    "        sample = {\n",
    "            \"id\": row['id'],\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\":attention_mask,\n",
    "            \"text\": text,\n",
    "            \"offset_mapping\": offset_mapping,\n",
    "            \"word_ids\" : word_ids\n",
    "        }\n",
    "        \n",
    "        if inference:\n",
    "            samples.append(sample)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            total = len(row['text_split'])\n",
    "            entities = ['O'] * total\n",
    "\n",
    "            for _, row2 in df_train[df_train['id'] == row['id']].iterrows():\n",
    "                discourse = row2['discourse_type']\n",
    "                list_ix = [int(x) for x in row2['predictionstring'].split(' ')]\n",
    "                entities[list_ix[0]] = f'B-{discourse}'\n",
    "                for k in list_ix[1:]: entities[k] = f'I-{discourse}'\n",
    "#                 all_entities.append(entities)\n",
    "                sample['input_labels'] = entities      \n",
    "        samples.append(sample)\n",
    "    \n",
    "    return samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5d5a921-9e15-4d2a-b979-61f678257beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df,df_train, tokenizer,inference=False):\n",
    "    samples = []\n",
    "    ids = df[\"id\"].unique()\n",
    "\n",
    "    ids_splits = np.array_split(ids, 4)\n",
    "#     multiprocessing\n",
    "    results = Parallel(n_jobs=4, backend=\"multiprocessing\")(\n",
    "        delayed(_prepare_data_helper_check)(tokenizer, df[df.id.isin(idx)], df_train[df_train.id.isin(idx)],inference=inference) for idx in ids_splits\n",
    "    )\n",
    "    for result in results:\n",
    "        samples.extend(result)\n",
    "\n",
    "    return samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "40e2c432-40b3-47b0-8048-04c17b5a901a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3899/3899 [00:46<00:00, 83.14it/s]\n",
      "100%|██████████| 3899/3899 [00:46<00:00, 83.23it/s]\n",
      "100%|██████████| 3898/3898 [00:46<00:00, 82.97it/s]\n",
      "100%|██████████| 3898/3898 [00:48<00:00, 79.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time taken is 74.00049901008606\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "checking_new =  prepare_data(df_texts,train_corrected,tokenizer)\n",
    "print(f'total time taken is {time.time()-start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01cd022e-6595-485a-aab6-c1fe948bdc2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DatasetRetriever_to_do(torch.utils.data.Dataset):\n",
    "    def __init__(self, samples, max_len ,test=False, inference=False):\n",
    "        super(DatasetRetriever_to_do, self).__init__()\n",
    "        self.samples = samples\n",
    "        self.max_len = max_len\n",
    "        self.inference = inference\n",
    "        self.test = test\n",
    "        \n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        input_ids = self.samples[item][\"input_ids\"]\n",
    "        attention_mask = self.samples[item][\"attention_mask\"]\n",
    "        word_ids = self.samples[item][\"word_ids\"]\n",
    "        \n",
    "        if self.inference:\n",
    "            \n",
    "            return {\t\n",
    "                    \"ids\": input_ids,\t\n",
    "                    \"mask\": attention_mask,\t\n",
    "                    \"word_ids\" :word_ids\n",
    "                   } \n",
    "            \n",
    "        else:\n",
    "            input_labels = self.samples[item][\"input_labels\"]\n",
    "            pad_labels = ['PAD' for i in range(self.max_len)]\n",
    "            pad_labels[1:len(input_labels)] = input_labels[1:]\n",
    "            pad_labels = [target_id_map[x] for x in pad_labels]\n",
    "            \n",
    "            \n",
    "            return {\n",
    "                    \"ids\": torch.tensor(input_ids, dtype=torch.long),\n",
    "                    \"mask\": torch.tensor(attention_mask, dtype=torch.long),\n",
    "                    \"targets\": torch.tensor(pad_labels, dtype=torch.long),\n",
    "                    \"word_ids\" :torch.tensor(word_ids, dtype=torch.long)\n",
    "                    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1557bed9-d83a-4367-9431-adcda19922ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_split</th>\n",
       "      <th>entities</th>\n",
       "      <th>length_of_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>293C1D45E66B</td>\n",
       "      <td>During the summer, students get do to do as th...</td>\n",
       "      <td>[During, the, summer,, students, get, do, to, ...</td>\n",
       "      <td>[B-Position, I-Position, I-Position, I-Positio...</td>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6DFF43AD5171</td>\n",
       "      <td>Dear Principle,\\n\\nI think we should have cell...</td>\n",
       "      <td>[Dear, Principle,, I, think, we, should, have,...</td>\n",
       "      <td>[0, 0, B-Position, I-Position, I-Position, I-P...</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84D2A6C75C67</td>\n",
       "      <td>Talking to more than one person for ideas or a...</td>\n",
       "      <td>[Talking, to, more, than, one, person, for, id...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>838005D1D7DC</td>\n",
       "      <td>The Face on Mars is just a natural landform. M...</td>\n",
       "      <td>[The, Face, on, Mars, is, just, a, natural, la...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F59DDBF5DB0B</td>\n",
       "      <td>Have you ever wondered why so many people in t...</td>\n",
       "      <td>[Have, you, ever, wondered, why, so, many, peo...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text  \\\n",
       "0  293C1D45E66B  During the summer, students get do to do as th...   \n",
       "1  6DFF43AD5171  Dear Principle,\\n\\nI think we should have cell...   \n",
       "2  84D2A6C75C67  Talking to more than one person for ideas or a...   \n",
       "3  838005D1D7DC  The Face on Mars is just a natural landform. M...   \n",
       "4  F59DDBF5DB0B  Have you ever wondered why so many people in t...   \n",
       "\n",
       "                                          text_split  \\\n",
       "0  [During, the, summer,, students, get, do, to, ...   \n",
       "1  [Dear, Principle,, I, think, we, should, have,...   \n",
       "2  [Talking, to, more, than, one, person, for, id...   \n",
       "3  [The, Face, on, Mars, is, just, a, natural, la...   \n",
       "4  [Have, you, ever, wondered, why, so, many, peo...   \n",
       "\n",
       "                                            entities  length_of_text  \n",
       "0  [B-Position, I-Position, I-Position, I-Positio...             617  \n",
       "1  [0, 0, B-Position, I-Position, I-Position, I-P...             328  \n",
       "2  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...             461  \n",
       "3  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...             385  \n",
       "4  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...             334  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "210da6da-e74b-4d13-9ee3-875b6bc40845",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_check_laoder = DatasetRetriever_to_do(checking_new,tokenizer, 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1cfbb5ed-282f-4ae2-8bdf-8059958d6565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([   0, 1590,    5,  ...,    1,    1,    1]),\n",
       " 'mask': tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       " 'targets': tensor([  14,    2,    3,  ..., -100, -100, -100])}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_check_laoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "28e1fcdd-1813-477a-8427-cd9e7a0c7579",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datasetloader_check:\n",
    "    def __init__(self, samples,max_len,test,inference,collate=None):\n",
    "        self.samples = samples\n",
    "        self.test = test\n",
    "        self.inference= inference\n",
    "        self.collate = collate\n",
    "        self.max_len = max_len\n",
    "        self.dataset = DatasetRetriever_to_do(samples=self.samples, max_len=self.max_len ,test=self.test, inference=self.inference)\n",
    "\n",
    "    def fetch(self, batch_size, num_workers, drop_last=False, shuffle=True):\n",
    "        if not self.test:\n",
    "            sampler = torch.utils.data.RandomSampler(self.dataset)\n",
    "        else:\n",
    "            sampler = torch.utils.data.SequentialSampler(self.dataset)\n",
    "\n",
    "        data_loader = torch.utils.data.DataLoader(\n",
    "            self.dataset, batch_size=batch_size, sampler=sampler, shuffle=shuffle, num_workers=num_workers, pin_memory=True, drop_last=drop_last,collate_fn=self.collate)\n",
    "        return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "cd50b308-d2b4-4de0-8fd0-9722f753f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "96ed617c-2b2e-4011-805f-c7d112f167c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cc_loader= Datasetloader_check(samples=checking_new[:4] ,max_len= 2022 ,test=False,inference=False).fetch(\n",
    "    batch_size=2, num_workers=0, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "fdf3d3ca-e76d-4076-9559-620d735a30c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cc = next(iter(cc_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "3212c0e2-7f40-40f7-80f4-9c51a09373c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([[    0,  1590,     5,  ...,     1,     1,     1],\n",
       "         [    0, 12191, 44528,  ...,     1,     1,     1]]),\n",
       " 'mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'targets': tensor([[-100,    3,    3,  ..., -100, -100, -100],\n",
       "         [-100,   14,    2,  ..., -100, -100, -100]])}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aebac3f0-8f6a-4160-b4ac-d46e07d109bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([   0, 1590,    5,  ...,    1,    1,    1]),\n",
       " 'mask': tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       " 'targets': tensor([  14,    2,    3,  ..., -100, -100, -100])}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417cd024-23ef-40e8-956f-33e9049aae6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6298bea5-5a79-41c4-aec3-d2c97c530682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15594"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4141d0a2-3e7e-45be-aca8-5bd9c9b5a79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folds = pd.read_csv('inputs/train_folds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d5bf456-61c2-46df-8d9f-4cdb5f6b84fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corrected = pd.read_csv('inputs/train_corrected_kfold.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b66f58c-ca08-4424-9ad2-3d1a77ec8b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    28997\n",
       "2    28968\n",
       "3    28904\n",
       "1    28737\n",
       "4    28687\n",
       "Name: kfold, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folds.kfold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8dee516e-8203-4d66-b7e3-9eb865c73cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_info = train_folds.groupby('id').agg({'kfold':'first'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3fb9a03e-6860-4d58-a506-aae3be399d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# number of words in a text file \n",
    "train.groupby('id')['length_of_text'].sum().reset_index()['length_of_text'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "18391160-dc2a-4f80-8f07-6e35142e7fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAFNCAYAAAD7F1LEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvBElEQVR4nO3deZhkVX3/8feHfd9kBAQRRBSNQYRxCy4ouIugISpuYIz8TMTdjGsUfWKCo5FESVQUBQ0qiyiIK6Kg4gKDgGwakH1kWERWUbbv7497Goqmu6tmpqurZ+b9ep771N3v9566Vf3tU+fek6pCkiRJ0uRWGnUAkiRJ0mxn0ixJkiT1YdIsSZIk9WHSLEmSJPVh0ixJkiT1YdIsSZIk9WHSLGmJJDkgyf+OOo4VXZKtklSSVaZpf/+a5Loki6ZjfwMe89Iku03j/rZMckuSladrn5Jk0ixpQi3pGBvuTnJbz/QrhnTMA1oC+IRh7H8mJdklyZVD2O+0Jpjj9r0l8HbgUVW16TCOsbSS7Jvkrp5r8ZIkX0jy8LF1quryqlqnqu4aZaySli8mzZIm1JKOdapqHeByYPeeeUdM9/GSBHg1cH17nXbWPPa1JfCHqrpm1IH08fN2Xa4P7AbcBpyR5NGjDev+pusXAEmjZ9IsaWmsluSLSW5Ocl6SuWMLkjwoydeSXNtqA9/UZ19PATYD3gS8LMlqbT/fSbJ/74pJzk7y4ja+XZITk1yf5LdJXtKz3mFJPpXk20luBZ6e5PlJzkxyU5Irkhwwbt+vTnJZkj8k+Zfemt0kKyV5V5LfteVHJdlocQttqrJpte1HTVSuSb5El9h+s9WyzuvZ7SuSXN6aVrx3imOv3/Z9bTvP97Xz2g04EXhQ2/dhk2z/giRnJbkhyc+SbN+zbKxsbk5yfpIXjdv2dUku6Fm+Y8/iHZL8OsmNSY5Mska/cqyqu6rqd1X1T8ApwAHtOPdpstJqpy9ux72k95eSyWJK8sgkJ7fzPC/JC3u2OTnJP/RM75vkpz3TleQNSS4ELkznoCTXtOvunLEEP8nqST7W3rurk3w6yZr9zl3SCFSVg4ODw5QDcCmw27h5BwB/Bp4HrAz8O/CLtmwl4Azg/cBqwEOBi4FnT3GMQ4GjgFWBPwB/2+a/Gji1Z71HATcAqwNrA1cArwFWAR4LXEfXvADgMOBGYOcW0xrALsBft+ntgauBPXv2fQvw5Bb3x4A7xs4deDPwC2CLdvzPAF+Z5Hx2Aa6cYP6UZTNVuU70XgBbAQV8FlgTeAzwF+CRk8T1ReA4YN227f8Br50q5p5tHwtcAzyhxbZPi2f1tvzvgAe1c3wpcCuwWc+yhcDjgAAPAx7Sc06ntW03Ai4AXj9JDPsCP51g/t8DV48rk1XaNXIT8Ii2bDPgr6aKie4avAh4T3uPngHc3LOPk4F/mCymduwT27msCTy7vecbtOM8sqdcDgKOb+uuC3wT+PdRf+YdHBzuP1jTLGlp/LSqvl1d29Ev0SVs0CUhc6rqQ1V1e1VdTJfUvWyinSRZiy6B+XJV3QEcw71NNL5OVwv5kDb9CuDYqvoL8ALg0qr6QlXdWVVnAl9r+xpzXFWdWlV3V9Wfq+rkqjqnTf8a+ArwtLbuXsA3q+qnVXU7XWJbPft6PfDeqrqyHf8AYK8s3k/wg5TNZOU6lQ9W1W1VdTZw9kTbpGue8jLg3VV1c1VdCvwH8KoBY98P+ExV/bK6Wt7D6RL0JwJU1dFV9ftWtkcCFwKPb9v+AzC/qk6vzkVVdVnPvj/Rtr2eLnHcYcCYxvyeLvGcyN3Ao5OsWVVXVdV5fWJ6IrAOcGB7j34InADsvRjx/HtVXV9Vt9H947UusB2Qqrqgqq5KEroyfWtb92bg35jkcyJptEyaJS2N3ics/AlYoyWQD6H7mf+GsYGu1m6TSfbzIuBO4Ntt+gjguUnmtETiW9ybSOzdltOO84Rxx3kF0HsT2xW9B0ryhCQ/as0TbqRLhDduix/Uu35V/Ymu1nvMQ4Cv9xzrAuCuKc5rIoOUzWTlOpXx26wzwTob09Wi9iarlwGbL0bsbx8X+4Ppym2sactZPcsezb1l+2Dgd0sZ/1Q2p2sPfx9VdStdrffrgauSfCvJdn1iehBwRVXd3TNvccoJ7nsd/RA4GPhv4JokhyRZD5gDrEXXHnuszL7b5kuaZUyaJQ3DFcAlVbVBz7BuVT1vkvX3oUuSLk/3qLOj6ZK7l7flXwH2TvIkuiYWP+o5zinjjrNOVf1jz757a4oBvkz3c/iDq2p94NN0P5kDXEXX9AKA1rb0AePO67njjrdGVS0ctGBY/LIZb/z5LI7r6Go9H9Izb0u6JgqDuAL48LjY16qqr7RfAj4L7A88oKo2AM7l3rK9AthmKWLv50XATyZaUFXfq6pn0jXN+E2Lc6qYfg88OEnv38jecrqVLtkdM9GTRu7zPlXVJ6pqJ7omQA8H/pnu/biNrrnIWHmuX91NjpJmGZNmScNwGnBzkncmWTPJykkeneRx41dMsjmwK11Tix3a8BjgI9zbROPbdIneh4Aje2oATwAenuRVSVZtw+OSPHKK2NYFrq+qPyd5PPcm5tA1C9k9yd+kuxHxAO5N+qBLsD881lQkyZwke0xVEEnW6B0Wp2wmcTVdO+jF1pp7HNXOYd12Hm8DBn3e9meB17fa+iRZO92NlevStR0u4FqAJK+hq2ke8zngHUl2ats+rKfJzRJpZbd1kk/Stcf+4ATrbJJkjyRr0zUluYWuucZUMf2SrrZ7XrumdgF2B77atjsLeHGStZI8DHhtnzgf18psVbqE+8/A3e06/ixwUJIHtnU3T/LsJS0TScNj0ixp2rXkbCwJvoSuRu1zdI8IG+9VwFlV9f2qWjQ2AJ8Atk/y6NZ++Fi6x4t9uec4NwPPomu68Xu6n/g/QneT3mT+CfhQkpvp2iwf1bO/84A30iVHV9ElWNfQJVsA/0VXS/39tv0v6G6Km8zmdDWJvcPWi1E2E/l34H3t5/x3DLhNrzfSJW4XAz+lK8/PD7JhVS0AXkfX1OCPdDfL7duWnU/XPvrndIn9XwOn9mx7NPDhdrybgW8weRvkfp6U5Ba6G/xOBtYDHldV50yw7kp0/xj8nq75xtOAf5wqptaefXfguXTvz/8Ar66q37R9HgTc3s7zcO5tLjSZ9eiS4z/SNfP4A/DRtuyddOX4iyQ3AT8AHjFYMUiaSalaml/6JGn5lWQduid1bFtVl4w4HEnSCFnTLEk9kuzefnZfm+6Rc+fQPRJNkrQCM2mWpPvag+6n/N8D2wIvK3+Sk6QVns0zJEmSpD6saZYkSZL6MGmWJEmS+licrl9HZuONN66tttpq1GFIkiRpOXbGGWdcV1UT9sq5TCTNW221FQsWLBh1GJIkSVqOJblssmVDbZ6R5K1JzktybpKvtB6xtk7yyyQXJTmy9bolSZIkzVpDS5pb17hvAuZW1aOBlel67foIcFBVPYyud6Qpux+VJEmSRm3YNwKuAqyZZBVgLbpuaZ8BHNOWHw7sOeQYJEmSpKUytKS5qhbS9aZ1OV2yfCNwBnBDVd3ZVrsS2HxYMUiSJEnTYZjNMzak61lra+BBwNrAcxZj+/2SLEiy4Nprrx1SlJIkSVJ/w2yesRtwSVVdW1V3AMcCOwMbtOYaAFsACyfauKoOqaq5VTV3zpwJn/whSZIkzYhhJs2XA09MslaSALsC5wM/AvZq6+wDHDfEGCRJkqSlNsw2zb+ku+HvV8A57ViHAO8E3pbkIuABwKHDikGSJEmaDkPt3KSqPgB8YNzsi4HHD/O4kiRJ0nQa9iPnJEmSpGXeMtGNtqRlz7x581i0aBGbbrop8+fPH3U4kiQtFZNmSUOxaNEiFi6c8OE4kiQtc2yeIUmSJPVhTbO0HNj5kzuPOoT7We2G1ViJlbjihitmXXynvvHUUYcgSVrGWNMsSZIk9WFNs6ShqLWKu7mbWqtGHYokSUvNpFnSUNyx8x2jDkGSpGlj8wxJkiSpD5NmSZIkqQ+TZkmSJKkPk2ZJkiSpD5NmSZIkqQ+TZkmSJKkPk2ZJkiSpD5NmSZIkqQ+TZkmSJKkPk2ZJkiSpD5NmSZIkqQ+TZkmSJKkPk2ZJkiSpD5NmSZIkqQ+TZkmSJKkPk2ZJkiSpj6ElzUkekeSsnuGmJG9JslGSE5Nc2F43HFYMkiRJ0nQYWtJcVb+tqh2qagdgJ+BPwNeBdwEnVdW2wEltWpIkSZq1Zqp5xq7A76rqMmAP4PA2/3BgzxmKQZIkSVoiM5U0vwz4ShvfpKquauOLgE1mKAZJkiRpiQw9aU6yGvBC4Ojxy6qqgJpku/2SLEiy4Nprrx1ylJIkSdLkZqKm+bnAr6rq6jZ9dZLNANrrNRNtVFWHVNXcqpo7Z86cGQhTkiRJmthMJM17c2/TDIDjgX3a+D7AcTMQgyRJkrTEhpo0J1kbeCZwbM/sA4FnJrkQ2K1NS5IkSbPWKsPceVXdCjxg3Lw/0D1NQ5IkSVom2COgJEmS1IdJsyRJktSHSbMkSZLUh0mzJEmS1IdJsyRJktSHSbMkSZLUh0mzJEmS1IdJsyRJktSHSbMkSZLUh0mzJEmS1IdJsyRJktSHSbMkSZLUh0mzJEmS1IdJsyRJktSHSbMkSZLUh0mzJEmS1IdJsyRJktSHSbMkSZLUh0mzJEmS1IdJsyRJktSHSbMkSZLUxyqjDkCSpOXJvHnzWLRoEZtuuinz588fdTiSpolJsyRJ02jRokUsXLhw1GFImmY2z5AkSZL6sKZZkrTMOvjt3xx1CPdzw3W33vM6G+Pb/z92H3UI0jJpqDXNSTZIckyS3yS5IMmTkmyU5MQkF7bXDYcZgyRJkrS0ht0847+A71bVdsBjgAuAdwEnVdW2wEltWpIkSZq1hpY0J1kfeCpwKEBV3V5VNwB7AIe31Q4H9hxWDJIkzbS1V1uPtVffgLVXW2/UoUiaRsNs07w1cC3whSSPAc4A3gxsUlVXtXUWAZtMtHGS/YD9ALbccsshhilJ0vTZeZsXjzoESUMwzOYZqwA7Ap+qqscCtzKuKUZVFVATbVxVh1TV3KqaO2fOnCGGKUmSJE1tmEnzlcCVVfXLNn0MXRJ9dZLNANrrNUOMQZIkSVpqQ0uaq2oRcEWSR7RZuwLnA8cD+7R5+wDHDSsGSZIkaToM+znNbwSOSLIacDHwGrpE/agkrwUuA14y5BgkSZKkpTLUpLmqzgLmTrBo12EeV5IkSZpOdqMtSZIk9WHSLEmSJPVh0ixJkiT1YdIsSZIk9WHSLEmSJPVh0ixJkiT1YdIsSZIk9WHSLEmSJPVh0ixJkiT10bdHwCQ7AwcAD2nrB6iqeuhwQ5MkSZJmh0G60T4UeCtwBnDXcMORJEmSZp9BkuYbq+o7Q49EkiRJmqUmTZqT7NhGf5Tko8CxwF/GllfVr4YcmyRJkjQrTFXT/B/jpuf2jBfwjOkPR5IkSZp9Jk2aq+rpAEkeWlUX9y5L4k2AkiRJWmEM8si5YyaYd/R0ByJJkiTNVlO1ad4O+Ctg/SQv7lm0HrDGsAOTJEmSZoup2jQ/AngBsAGwe8/8m4HXDTEmSZIkaVaZqk3zccBxSZ5UVT+fwZiWK/PmzWPRokVsuummzJ8/f9ThSJIkaQkM8pzmlyfZe9y8G4EFLbHWFBYtWsTChQtHHYYkSZKWwiA3Aq4O7ABc2IbtgS2A1yb5z6FFJkmSJM0Sg9Q0bw/sXFV3AST5FPAT4MnAOUOMbbHs9M9fHHUIE1r3uptZGbj8uptnXYxnfPTVow5BkiRpmTBITfOGwDo902sDG7Uk+i8TbyJJkiQtPwapaZ4PnJXkZCDAU4F/S7I28IMhxiZJkiTNCn2T5qo6NMm3gce3We+pqt+38X+eatskl9I9ou4u4M6qmptkI+BIYCvgUuAlVfXHJYp+GXD3amvf51WSJEnLnkFqmqFrxnFtW/9hSR5WVT8ecNunV9V1PdPvAk6qqgOTvKtNv3PgiJcxt277rFGHIEmSpKXUN2lO8hHgpcB5wN1tdgGDJs3j7QHs0sYPB05mOU6aJUmStOwbpKZ5T+ARVbUkN/0V8P0kBXymqg4BNqmqq9ryRcAmS7BfSZIkacYMkjRfDKzKkj0p48lVtTDJA4ETk/ymd2FVVUuo7yfJfsB+AFtuueUSHFqSJEmaHoMkzX+ie3rGSfQkzlX1pn4bVtXC9npNkq/T3Ux4dZLNquqqJJsB10yy7SHAIQBz586dMLGWJEmSZsIgSfPxbVgs7ZF0K1XVzW38WcCH2r72AQ5sr3bFLUmSpFltkEfOHZ5kTWDLqvrtYux7E+DrScaO8+Wq+m6S04GjkrwWuAx4yRLELUmSJM2YQZ6esTvwMWA1YOskOwAfqqoXTrVdVV0MPGaC+X8Adl2iaCVJkqQRGKQb7QPo2iLfAFBVZwEPHVpEkiRJ0iwzSNJ8R1XdOG7e3ROuKUmSJC2HBrkR8LwkLwdWTrIt8CbgZ8MNS5IkSZo9BqlpfiPwV3SPm/sycCPw5mEGJUmSJM0mgzw940/Ae9sAQJIj6brWliRJkpZ7g9Q0T+RJ0xqFJEmSNIstadIsSZIkrTAmbZ6RZMfJFgGrDiccSZIkafaZqk3zf0yx7DfTHYgkSZI0W02aNFfV02cyEEmSJGm2sk2zJEmS1IdJsyRJktSHSbMkSZLUR9+kOclJg8yTJEmSlldTPXJuDWAtYOMkG9I9ag5gPWDzGYhNkiRJmhWmeuTc/wPeAjwIOIN7k+abgIOHG5YkSZI0e0z1yLn/Av4ryRur6pMzGJMkSZI0qwxyI+ADk6w8NpFkvSRfGGJMkiRJ0qwySNK8MnBaku2TPBM4na65hiRJkrRCmKpNMwBV9Z72tIxfAn8EnlpVFw09MkmSJGmWGOSRc08FPgF8CDgZ+GSSBw05LkmSJGnW6FvTDHwM+LuqOh8gyYuBHwLbDTMwSZIkabYYJGl+UlXdNTZRVccmOWWIMUmSJEmzyiA3Am6T5KQk5wIk2R74x+GGJUmSJM0egyTNnwXeDdwBUFW/Bl426AGSrJzkzCQntOmtk/wyyUVJjkyy2pIELkmSJM2UQZLmtarqtHHz7lyMY7wZuKBn+iPAQVX1MLqncbx2MfYlSZIkzbhJk+YkW7bR65JsA1Sbvxdw1SA7T7IF8Hzgc206wDOAY9oqhwN7LkngkiRJ0kyZ6kbAbwA7AvsDnwG2S7IQuAR45YD7/09gHrBum34AcENVjdVUXwlsvnghS5IkSTNrqqQ5AFX1O2C3JGsDK1XVzYPsOMkLgGuq6owkuyxuYEn2A/YD2HLLLfusLUmSJA3PVEnz5kk+MX5m18ICqupNffa9M/DCJM8D1gDWA/4L2CDJKq22eQtg4UQbV9UhwCEAc+fOrT7HkiRJkoZmqqT5NuCMJd1xVb2b7qkbtJrmd1TVK5IcDewFfBXYBzhuSY8hSZIkzYSpkuY/VNXhQzjmO4GvJvlX4Ezg0CEcQ5IkSZo2UyXNt0/XQarqZODkNn4x8Pjp2rckSZI0bJM+cq6qnjiTgUiSJEmz1SCdm0iSJEkrNJNmSZIkqY+BkuYkT07ymjY+J8nWww1LkiRJmj36Js1JPkD3xIt3t1mrAv87zKAkSZKk2WSQmuYXAS8EbgWoqt9zb7fYkiRJ0nJvkKT59qoqoABad9qSJEnSCmOQpPmoJJ+h6/76dcAPgM8ONyxJkiRp9piqcxMAqupjSZ4J3AQ8Anh/VZ049MgkSZKkWaJv0gzQkmQTZUmSJK2Q+ibNSW6mtWfucSOwAHh76xZbkiRJWm4NUtP8n8CVwJeBAC8DtgF+BXwe2GVIsUmSJEmzwiA3Ar6wqj5TVTdX1U1VdQjw7Ko6EthwyPFJkiRJIzdI0vynJC9JslIbXgL8uS0b32xDkiRJWu4MkjS/AngVcA1wdRt/ZZI1gf2HGJskSZI0KwzyyLmLgd0nWfzT6Q1HkiRJmn0GeXrGGsBrgb8C1hibX1V/P8S4JEmSpFljkOYZXwI2BZ4NnAJsAdw8zKAkSZKk2WSQpPlhVfUvwK1VdTjwfOAJww1LkiRJmj0GSZrvaK83JHk0sD7wwOGFJEmSJM0ug3RuckiSDYH3AccD6wD/MtSoJEmSpFlkyqQ5yUrATVX1R+DHwENnJCpJkiRpFpmyeUZV3Q3Mm6FYJEmSpFlpkDbNP0jyjiQPTrLR2DD0yCRJkqRZYpA2zS9tr2/omVf0aarRnu/8Y2D1dpxjquoDSbYGvgo8ADgDeFVV3b64gUuSJEkzZZAeAbdewn3/BXhGVd2SZFXgp0m+A7wNOKiqvprk03Qdp3xqCY8hSZIkDV3f5hlJ1kryviSHtOltk7yg33bVuaVNrtqGAp4BHNPmHw7suSSBS5IkSTNlkDbNXwBuB/6mTS8E/nWQnSdZOclZwDXAicDvgBuq6s62ypXA5osTsCRJkjTTBkmat6mq+bROTqrqT0AG2XlV3VVVO9B1vf14YLtBA0uyX5IFSRZce+21g24mSZIkTbtBkubbk6xJ17SCJNvQtVceWFXdAPwIeBKwQZKxttRb0NVcT7TNIVU1t6rmzpkzZ3EOJ0mSJE2rQZLmA4DvAg9OcgRwEgM8uznJnCQbtPE1gWcCF9Alz3u11fYBjlvsqCVJkqQZNMjTM76f5AzgiXTNMt5cVdcNsO/NgMOTrEyXnB9VVSckOR/4apJ/Bc4EDl3y8CVJkjRbzJs3j0WLFrHpppsyf/78UYczrfomzUm+CXwZOL6qbh10x1X1a+CxE8y/mK59syRJkpYjixYtYuHCCVveLvMGaZ7xMeApwPlJjkmyV+u4RJIkSVohDNI84xTglNbM4hnA64DPA+sNOTZJkiRN4IIP/3DUIUzo9utvu+d1tsX4yPc+Y6m2H6Qb7bEb+Xan61J7R7pOSSRJkqQVwiBtmo+ia4P8XeBg4JSqunvYgUmSJEmzxSA1zYcCe1fVXQBJnpxk76p6w3BDkyRJ0rLkAWusf5/X5ckgbZq/l+SxSfYGXgJcAhw79MgkSZK0TNn/sS8fdQhDM2nSnOThwN5tuA44EkhVPX2GYpMkSZJmhalqmn8D/AR4QVVdBJDkrTMSlSRJkjSLTPWc5hcDVwE/SvLZJLvS9QgoSZIkrVAmTZqr6htV9TJgO+BHwFuAByb5VJJnzVB8kiRJ0sj17RGwqm6tqi9X1e7AFsCZwDuHHpkkSZI0SwzSjfY9quqPVXVIVe06rIAkSZKk2WagHgElSZKWBfPmzWPRokVsuummzJ8/f9ThaDli0ixJkpYbixYtYuHChaMOQ8uhxWqeIUmSJK2IrGmWJElL5MOv3GvUIdzP9dfc2L0uumrWxffe/z1m1CFoKVjTLEmSJPVhTbMkSVpurLHySvd5laaLSbMkSVpuPPYB6446BC2n/DdMkiRJ6sOkWZIkSerDpFmSJEnqw6RZkiRJ6sOkWZIkSerDpFmSJEnqY2hJc5IHJ/lRkvOTnJfkzW3+RklOTHJhe91wWDFIkiRJ02GYNc13Am+vqkcBTwTekORRwLuAk6pqW+CkNi1JkiTNWkNLmqvqqqr6VRu/GbgA2BzYAzi8rXY4sOewYpAkSZKmw4y0aU6yFfBY4JfAJlV1VVu0CNhkkm32S7IgyYJrr712JsKUJEmSJjT0pDnJOsDXgLdU1U29y6qqgJpou6o6pKrmVtXcOXPmDDtMSZIkaVJDTZqTrEqXMB9RVce22Vcn2awt3wy4ZpgxSJIkSUtrmE/PCHAocEFVfbxn0fHAPm18H+C4YcUgSZIkTYdVhrjvnYFXAeckOavNew9wIHBUktcClwEvGWIMkiRJ0lIbWtJcVT8FMsniXYd1XGnMvHnzWLRoEZtuuinz588fdTiSJGkZNsyaZq1ALv/QX486hPu58vyNuPq2Vbjz+stmZXxbvv+cUYcgSZIGZDfakiRJUh/WNGu5tfEadwN3tldJkqQlZ9Ks5dY7tr9h1CFoBXDKU5826hCWOU/78SmjDkGSFpvNMyRJkqQ+TJolSZKkPkyaJUmSpD5MmiVJkqQ+TJolSZKkPkyaJUmSpD5MmiVJkqQ+TJolSZKkPkyaJUmSpD5MmiVJkqQ+TJolSZKkPkyaJUmSpD5MmiVJkqQ+TJolSZKkPkyaJUmSpD5MmiVJkqQ+TJolSZKkPkyaJUmSpD5MmiVJkqQ+TJolSZKkPoaWNCf5fJJrkpzbM2+jJCcmubC9bjis40uSJEnTZZg1zYcBzxk3713ASVW1LXBSm5YkSZJmtaElzVX1Y+D6cbP3AA5v44cDew7r+JIkSdJ0mek2zZtU1VVtfBGwyQwfX5IkSVpsI7sRsKoKqMmWJ9kvyYIkC6699toZjEySJEm6r5lOmq9OshlAe71mshWr6pCqmltVc+fMmTNjAUqSJEnjzXTSfDywTxvfBzhuho8vSZIkLbZhPnLuK8DPgUckuTLJa4EDgWcmuRDYrU1LkiRJs9oqw9pxVe09yaJdh3VMSZIkaRjsEVCSJEnqw6RZkiRJ6sOkWZIkSerDpFmSJEnqw6RZkiRJ6sOkWZIkSerDpFmSJEnqw6RZkiRJ6sOkWZIkSerDpFmSJEnqw6RZkiRJ6sOkWZIkSerDpFmSJEnqw6RZkiRJ6sOkWZIkSerDpFmSJEnqw6RZkiRJ6sOkWZIkSerDpFmSJEnqw6RZkiRJ6sOkWZIkSerDpFmSJEnqw6RZkiRJ6sOkWZIkSepjJElzkuck+W2Si5K8axQxSJIkSYOa8aQ5ycrAfwPPBR4F7J3kUTMdhyRJkjSoUdQ0Px64qKourqrbga8Ce4wgDkmSJGkgo0iaNweu6Jm+ss2TJEmSZqVU1cweMNkLeE5V/UObfhXwhKraf9x6+wH7tclHAL+d0UCn18bAdaMOYgVl2Y+W5T9alv/oWPajZfmP1rJc/g+pqjkTLVhlpiMBFgIP7pneos27j6o6BDhkpoIapiQLqmruqONYEVn2o2X5j5blPzqW/WhZ/qO1vJb/KJpnnA5sm2TrJKsBLwOOH0EckiRJ0kBmvKa5qu5Msj/wPWBl4PNVdd5MxyFJkiQNahTNM6iqbwPfHsWxR2S5aGayjLLsR8vyHy3Lf3Qs+9Gy/EdruSz/Gb8RUJIkSVrW2I22JEmS1IdJ8xJKcssQ9nlpko2ne7/LoiR3JTkryblJjk6y1mJu/6Akx7TxHZI8r2fZC+2+/b56yntsmLJ8knw7yQYTzD8gyTuGFugKLMmmSb6a5HdJzmjvwcOTnNtnu3s+C7PRZOc1jfvfJckJi7nNPddxkg8l2W2aYvn7JOck+XX7btujzd83yYMG2H6g9YYlyZ6D9uA7Q+/r30zj/vr+TU/ys+k63mwz7m/uNyf6fh+3/mHtEcKLc4z39IxvkOSfBtxu2vOtJWXSrNnqtqraoaoeDdwOvH5xNq6q31fV2Ad6B+B5PcuOr6oDpy3S5cNYeY8NU5ZPVT2vqm6YodhWeEkCfB04uaq2qaqdgHcDm/TbdtxnYVZZmvOaKVX1/qr6wdLuJ8kWwHuBJ1fV9sATgV+3xfsCgyTDg643LHsCfZPmGXpfdwEWK2lOslT3cVXVtCXps1Dv39zrgTcM4Rjv6RnfABgoaZ5NTJqnUZJtkny3/Vf9kyTbtfm7J/llkjOT/CDJJm3+A5J8P8l5ST4HZKQnMHv9BHhYko2SfKPV0vwiyfYASZ7WU0N6ZpJ1k2zV/mNeDfgQ8NK2/KWttubgtu1WSX7Y9nlSki3b/MOSfCLJz5JcvLj/US8PkjwnydE90/fU2PX+KpLkvUn+L8lP6ToiGlt/ss/DpGWb5J2tJu7sJAdOtZ8VzNOBO6rq02MzqupsenpXbdfyT5L8qg1/0zP/3Da+b/sMndjew/2TvK19bn6RZKPZcF5V9ZN0Pto+x+ckeWk7h12SnJzkmCS/SXJES9JI8rh2XZ2d5LQk6/YeLON+CWn73qqNT3Yd31Oj1srsg618z+m5pue0Mj0vyeeSXJb7/2r4QOBm4JZ2nrdU1SVt33OBI9p31JpJ3p/k9BbfIa0sJlpvpySntM/G95Js1uI5OclBSRYkuaCVy7FJLkzyrz3n9spWTmcl+UySldv8W5J8uJXjL5Js0q6nFwIfbetvs7jvK/DTKd7Te34NSHJwkn0nK/P2nr0eeGuL5SntPfhaK7fTk+zc855/KcmpwJfauXy9ndvZGVdbnWSddH8Lxo63R8+yW3riPSXJcem+ww5M8opWluf0KZtlwc9pPTVn6u/f3do19n9JXtDWv+fva5s+oZXXgcCa7f06AjgQ2KZNf3Sqcp9VqsphCQbglgnmnQRs28afAPywjW/IvTdd/gPwH238E8D72/jzgQI2HvW5zYZhrHzpnvByHPCPwCeBD7T5zwDOauPfBHZu4+u0bbYCzm3z9gUO7tn3PdNt233a+N8D32jjhwFH0/1j+SjgolGXyZDL+y7grJ7hpa0cLwfWbut8CnhlG7+UrsennYBzgLWA9YCLgHe0dSb7PExYtsBzgZ8Ba7Xpjabaz4o0AG8CDppgfu91vhawRhvfFlgwwTr7tvdoXWAOcCPw+rbsIOAts+G82rK/BU6kezTpJu1a3IyuhvFGuo6xVqL7A/9kYDXgYuBxbfv12jW8C3BCm3fA2PXZps9t5TPVdXwYsFfPdf/GNv5PwOfa+MHAu9v4c5jgu7ydx/faeXwB2L1n2cnA3J7pjXrGvzS2bu96wKrt8zKnTb+U7hGuY+t9pI2/Gfh9K7vVgSuBBwCPpPv+W7Wt9z/Aq9t49RxzPvC+8WWxhNfrVO/pCT3rHQzs26fMx7+XX6arxQfYErigZ70zgDXb9JG067zFsX4b7/2bs14b37hdCxm3zi7ADT1luhD4YE95/+dMfo6m6bM4dm4r030/P6dNT/U9/l26z+C27bpag/v/vT0B2KX3GG18K9r30qDlPhuGkTxybnmUZB26n4qOTu6pMF69vW4BHNlqAVYDLmnznwq8GKCqvpXkjzMX8ay3ZpKz2vhPgEOBX9J96VJVP0xXU78ecCrw8fbf67FVdWXPe9DPk2jvAd0fp/k9y75RVXcD56f9OrAcu62qdhg/M8l3gd3TtYl9PjBv3CpPAb5eVX9q6x/fXqf6PMDEZbsb8IWxfVXV9QPsR/daFTg4yQ50/wRN1n70R1V1M3BzkhvpEifoksbthx7l4J4MfKWq7gKuTnIK8DjgJuC0qroSoH1PbEWXSF9VVacDVNVNbfkgx5rwOp7Ese31DO797ngy8KJ23O9O9F1eVXcleU47h12Bg5LsVFUHTHCMpyeZR5fEbwScx73v05hHAI8GTmznuDJwVc/ysXM4Bzivqq5q53YxXa+8T6b7Z+H0tv2awDVtm9vpkp2x83zmJGWxuKZ6T6cyUZmPtxvwqJ73e732/QFwfFXd1safAbwauveE7rrpFeDfkjwVuJuuxnUTYNG49U7vKdPfAd9v88+hq2lf1oz9zd0cuIDuuur3/XtU+x6/sF1XS/Mr4KDlPlImzdNnJeCGiRIPuhrSj1fV8Ul2ofvPV1O7XxI32R+/qjowybfo2i2fmuTZwJ+nIYa/9B5+Gva3LPoqsD9dG7cFLdkaxFSfBxi8bPvtZ0VxHtCvidBbgauBx9CV22Sfgd6yv7tn+m5m/m/CIOc1kd5zuIvB476T+zZLXGMpjr04xwWgumqz04DTkpxIV+N8QO86Sdagq/WdW1VXJDlgkjhDlww/qU+cve/x2PQqbfvDq+rdE2x7R4sVluA8Wfz3td/7MkiZrwQ8saruc923vxu3LkYsr6D7FWanqrojyaUTxNMbE4z+czQdbquqHdLddP89ujbNhzH19+/4ZxYXS/4ZG7TcR8o2zdOk1WpckuTvoLsRIslj2uL16X6+AdinZ7MfAy9v6z+XrhmHJvcTug8W7Z+P66rqpiTbVNU5VfURum7ax/+3ezPdz9ET+RldV+60ff9kuoNexp0C7Ai8ji6BHu/HwJ7p2leuC+wOfT8PkzkReE370ibJRku4n+XRD4HVk+w3NiNdm/4H96yzPl1N693Aq+hqHme7Cc8ryVPoPosvTbJykjl0v8ydNsW+fgtsluRxbT/r5v43fl1Kdz2TZEdg6zZ/wut4MZwKvKTt91lM8F2e7ikmO/bM2gG4rI33fkeNJQrXtZq+3uSzd73fAnOSPKntf9Ukf7UYMZ8E7JXkgW37jZI8pM82U32X9prser2Bid/Ty+hqiVdP99SGXQc4xvhYvg+8sed4O0yy3Ul0zf1ocaw/bvn6wDUtcXs60K9Mlivt15Y3AW8H/sTU379/l2SldG24H0p3TV4K7NDmPxh4fM/6dyRZtY2Pf/+WiXI3aV5yayW5smd4G13S9dokZ9P9pz3WkP0Aup83zgCu69nHB4GnJjmP7ieny2cu/GXSAcBOSX5NdxPB2D8gb0l3Y8mvgTuA74zb7kd0X8hnpd140uONdInar+kSjTcPLfrZbewGjbHhQLjn58sT6Nob3++xXVX1K7o2gmfTlfvpPYsn+zxMqKq+S/eT8oL2M+HYDVuLtZ/lUav1exHdjTe/a98Z/859f7r8H2CfVk7bsXi1ayPR57y+Tvd0ibPpkrB5VTXpT7VVdTtdu95PtjI4kfvXVH0N2KgdZ3/g/9q2U13Hg/gg8Kx0N1z+XYt//K8yqwIfS3fz4lkt1rHvm8OAT7f5fwE+S9fe+nvjYuldb2W6hPoj7XzPYjGeJlFV5wPvA77fvv9OpGujO5WvAv+c7sbRSW92m+J9/TITvKdVdQVwVDvno4AzBziFbwIvat9XT6FL9Oamu6n7fCZ/4tKb6Zq/nEPX3GP800COaPs5h64Zx28GiGW5UlVn0r1PezP19+/ldP/0fIfu3og/0/0DeQlwPt19W7/qWf8Q4NdJjqiqP9D9Mnxuko+yjJS7PQJKkrQUkqwO3FVVd7aa30/ZpEha/iyL7W4kSZpNtgSOSrIS3U10rxtxPJKGwJpmSZIkqQ/bNEuSJEl9mDRLkiRJfZg0S5IkSX2YNEvSNEhyV3v81XlJzk7y9nZjGEnmJvnEqGMcVJL/budyfpLbeh5FuCQdkUjScsEbASVpGiS5parWaeMPpHsm7alV9YERxbNKVd25lPvYCjihqh49PVFJ0rLLmmZJmmZVdQ2wH7B/60VrlyQnACR5Wk/N7ZmtBzqSvDPJOa2W+sA2b4ckv2gdNnw9yYZt/slJ5rbxjdN1OUuSfZMcn+SHwElJNkvy43asc1snECR5VpKfJ/lVkqPT9Tw3pSRfTLJnz/QRSfZoxzyuxXRhkg/0rPPKJKe1438mybLQS6EkTcikWZKGoKoupuu17YHjFr0DeEPr/OIpwG1JnkvX09YTquoxwPy27heBd1bV9sA5wCC11jsCe1XV04CXA99rx3oMcFaSjel6gtutqnYEFgBvG2C/hwL7AqTrevhvgG+1ZY8H/hbYnq5r3blJHknX693O7fh30fUuJknLJDs3kaSZdSrw8SRHAMdW1ZVJdgO+UFV/Aqiq61tiukFVndK2Oxw4eoD9n1hV17fx04HPJ1kV+EZVnZXkaXRdB5+aBGA14Of9dlpVpyT5nyRz6BLkr7Ue8MaO+QeAJMcCTwbuBHYCTm/rrAlcM0D8kjQrmTRL0hAkeShd7eo1wCPH5lfVgUm+BTyPLnF99hLs/k7u/aVwjXHLbu051o+TPBV4PnBYko8Df6RLcvdeguN+EXgl8DLgNT3zx98cU0CAw6vq3UtwHEmadWyeIUnTrNXGfho4uMbdbZ1km6o6p6o+QlcTvB1wIvCaJGu1dTaqqhuBP461QwZeBYzVOl9KV4sLMOkTLZI8BLi6qj4LfI6u6cYvgJ2TPKyts3aShw94aocBbwGoqvN75j8zyUZJ1gT2pKtNPwnYq90USVv+kAGPI0mzjjXNkjQ91kxyFrAqXU3wl4CPT7DeW5I8HbgbOA/4TlX9JckOwIIktwPfBt4D7AN8uiXTF3Nv7e7HgKOS7Me97Yonsgvwz0nuAG4BXl1V1ybZF/hKktXbeu8D/q/fCVbV1UkuAL4xbtFpwNeALYD/raoFAEneB3y/PXrvDuANwGX9jiNJs5GPnJMkDaQl7+cAO7aacFoCPreq9h9lbJI0bDbPkCT11W5WvAD45FjCLEkrEmuaJUmSpD6saZYkSZL6MGmWJEmS+jBpliRJkvowaZYkSZL6MGmWJEmS+jBpliRJkvr4/6xN7A6z2fF0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "sns.barplot(x=\"discourse_type\", y=\"length_of_text\", data=train)\n",
    "ax.set_title(\"The Average Lenth of each Discourse\")\n",
    "ax.set_xlabel(\"Discourse Type\")\n",
    "ax.set_ylabel(\"Average Text Length\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21e02520-abd4-4053-9879-02644fd0767a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = (\n",
    "    train[\"discourse_type\"]\n",
    "    .value_counts(ascending=True)\n",
    "    .plot(kind=\"barh\", figsize=(10, 5))\n",
    ")\n",
    "ax.set_title(\"Discourse Label Frequency (in train)\", fontsize=16)\n",
    "ax.bar_label(ax.containers[0], label_type=\"edge\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a1b6e5-b294-4287-9f19-c2b5de89ff4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea372107-a797-47f0-b49b-9697c4591b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_id_map = {\n",
    "    \"B-Lead\": 0,\n",
    "    \"I-Lead\": 1,\n",
    "    \"B-Position\": 2,\n",
    "    \"I-Position\": 3,\n",
    "    \"B-Evidence\": 4,\n",
    "    \"I-Evidence\": 5,\n",
    "    \"B-Claim\": 6,\n",
    "    \"I-Claim\": 7,\n",
    "    \"B-Concluding Statement\": 8,\n",
    "    \"I-Concluding Statement\": 9,\n",
    "    \"B-Counterclaim\": 10,\n",
    "    \"I-Counterclaim\": 11,\n",
    "    \"B-Rebuttal\": 12,\n",
    "    \"I-Rebuttal\": 13,\n",
    "    \"O\": 14,\n",
    "    \"PAD\": -100,\n",
    "}\n",
    "\n",
    "\n",
    "id_target_map = {v: k for k, v in target_id_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01e83674-c963-44aa-9d43-1ac76451b55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'B-Lead',\n",
       " 1: 'I-Lead',\n",
       " 2: 'B-Position',\n",
       " 3: 'I-Position',\n",
       " 4: 'B-Evidence',\n",
       " 5: 'I-Evidence',\n",
       " 6: 'B-Claim',\n",
       " 7: 'I-Claim',\n",
       " 8: 'B-Concluding Statement',\n",
       " 9: 'I-Concluding Statement',\n",
       " 10: 'B-Counterclaim',\n",
       " 11: 'I-Counterclaim',\n",
       " 12: 'B-Rebuttal',\n",
       " 13: 'I-Rebuttal',\n",
       " 14: 'O',\n",
       " -100: 'PAD'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_target_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62e1437e-1cf6-41c9-b7d5-190dda8dc9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0da49450-b665-4b76-9696-41f78bd9e901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-07 22:18:56.581449: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "# import config\n",
    "# import preprocessing\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44b7d177-ae69-48d3-a1bd-28b7617f36b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"model_obj/longformer-base-4096/\",add_prefix_space = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da49bff6-a117-4c8c-bcb4-2dbf143724d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='model_obj/longformer-base-4096/', vocab_size=50265, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71bcad4b-c99e-40bb-b29b-b638d587301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train[train.id.isin(['EDC567D40996' ,'6B4F7A0165B9'])] #\"423A1CA112E2\", 'A8445CABFECE', ,'4C471936CD75'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2bdf43f-bb57-464f-9bf3-dfe1f2eedabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_folds[train_folds.kfold==0]  #\"423A1CA112E2\", 'A8445CABFECE', ,'4C471936CD75'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8d957b0-5b60-478b-ab98-78c30577561c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A8445CABFECE</td>\n",
       "      <td>1.622576e+12</td>\n",
       "      <td>18.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Drivers should not be able to use phones while...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>3 4 5 6 7 8 9 10 11 12 13 14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A8445CABFECE</td>\n",
       "      <td>1.622576e+12</td>\n",
       "      <td>86.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>Drivers who used their phone while operating a...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 3...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A8445CABFECE</td>\n",
       "      <td>1.622576e+12</td>\n",
       "      <td>203.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>According to an article by the Edgar Snyder Fi...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 5...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A8445CABFECE</td>\n",
       "      <td>1.622576e+12</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>1243.0</td>\n",
       "      <td>In conclusion, drivers should not able to work...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>177 178 179 180 181 182 183 184 185 186 187 18...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>A97DE0D49AEA</td>\n",
       "      <td>1.622645e+12</td>\n",
       "      <td>63.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>Driver's should desist from using their Cell ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>11 12 13 14 15 16 17 18 19 20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144235</th>\n",
       "      <td>0814426B27DF</td>\n",
       "      <td>1.617896e+12</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>1563.0</td>\n",
       "      <td>that one of the people you asked for advice ma...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 5</td>\n",
       "      <td>290 291 292 293 294 295 296 297 298 299 300 30...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144236</th>\n",
       "      <td>0814426B27DF</td>\n",
       "      <td>1.617896e+12</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>Some don't think all the same things if you we...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 3</td>\n",
       "      <td>315 316 317 318 319 320 321 322 323 324 325 32...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144237</th>\n",
       "      <td>0814426B27DF</td>\n",
       "      <td>1.617896e+12</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>Some people will disagree with my three reasons</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Counterclaim 1</td>\n",
       "      <td>391 392 393 394 395 396 397 398</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144238</th>\n",
       "      <td>0814426B27DF</td>\n",
       "      <td>1.617896e+12</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>2075.0</td>\n",
       "      <td>but I don't like to listen to the people who d...</td>\n",
       "      <td>Rebuttal</td>\n",
       "      <td>Rebuttal 1</td>\n",
       "      <td>399 400 401 402 403 404 405 406 407 408 409 41...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144239</th>\n",
       "      <td>0814426B27DF</td>\n",
       "      <td>1.617896e+12</td>\n",
       "      <td>2076.0</td>\n",
       "      <td>2359.0</td>\n",
       "      <td>Maybe this helped you maybe it didn't.\\n\\nTo s...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>413 414 415 416 417 418 419 420 421 422 423 42...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28997 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  discourse_id  discourse_start  discourse_end  \\\n",
       "10      A8445CABFECE  1.622576e+12             18.0           85.0   \n",
       "11      A8445CABFECE  1.622576e+12             86.0          202.0   \n",
       "12      A8445CABFECE  1.622576e+12            203.0         1030.0   \n",
       "13      A8445CABFECE  1.622576e+12           1031.0         1243.0   \n",
       "71      A97DE0D49AEA  1.622645e+12             63.0          129.0   \n",
       "...              ...           ...              ...            ...   \n",
       "144235  0814426B27DF  1.617896e+12           1440.0         1563.0   \n",
       "144236  0814426B27DF  1.617896e+12           1564.0         1955.0   \n",
       "144237  0814426B27DF  1.617896e+12           1956.0         2003.0   \n",
       "144238  0814426B27DF  1.617896e+12           2004.0         2075.0   \n",
       "144239  0814426B27DF  1.617896e+12           2076.0         2359.0   \n",
       "\n",
       "                                           discourse_text  \\\n",
       "10      Drivers should not be able to use phones while...   \n",
       "11      Drivers who used their phone while operating a...   \n",
       "12      According to an article by the Edgar Snyder Fi...   \n",
       "13      In conclusion, drivers should not able to work...   \n",
       "71       Driver's should desist from using their Cell ...   \n",
       "...                                                   ...   \n",
       "144235  that one of the people you asked for advice ma...   \n",
       "144236  Some don't think all the same things if you we...   \n",
       "144237    Some people will disagree with my three reasons   \n",
       "144238  but I don't like to listen to the people who d...   \n",
       "144239  Maybe this helped you maybe it didn't.\\n\\nTo s...   \n",
       "\n",
       "              discourse_type      discourse_type_num  \\\n",
       "10                  Position              Position 1   \n",
       "11                     Claim                 Claim 1   \n",
       "12                  Evidence              Evidence 1   \n",
       "13      Concluding Statement  Concluding Statement 1   \n",
       "71                  Position              Position 1   \n",
       "...                      ...                     ...   \n",
       "144235                 Claim                 Claim 5   \n",
       "144236              Evidence              Evidence 3   \n",
       "144237          Counterclaim          Counterclaim 1   \n",
       "144238              Rebuttal              Rebuttal 1   \n",
       "144239  Concluding Statement  Concluding Statement 1   \n",
       "\n",
       "                                         predictionstring  kfold  \n",
       "10                           3 4 5 6 7 8 9 10 11 12 13 14      0  \n",
       "11      15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 3...      0  \n",
       "12      36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 5...      0  \n",
       "13      177 178 179 180 181 182 183 184 185 186 187 18...      0  \n",
       "71                          11 12 13 14 15 16 17 18 19 20      0  \n",
       "...                                                   ...    ...  \n",
       "144235  290 291 292 293 294 295 296 297 298 299 300 30...      0  \n",
       "144236  315 316 317 318 319 320 321 322 323 324 325 32...      0  \n",
       "144237                    391 392 393 394 395 396 397 398      0  \n",
       "144238  399 400 401 402 403 404 405 406 407 408 409 41...      0  \n",
       "144239  413 414 415 416 417 418 419 420 421 422 423 42...      0  \n",
       "\n",
       "[28997 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4194e377-03df-44fa-a91d-6d445c46b00f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>length_of_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144261</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>Imagine seeking advice from multiple people an...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144262</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>229.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>Seeking multiple opinions can help someone mak...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>39 40 41 42 43 44 45 46 47 48</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144263</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>303.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>they can see which advice is better</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>50 51 52 53 54 55 56</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144264</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>340.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>more experienced</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 2</td>\n",
       "      <td>57 58</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144265</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>362.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>see the persons point of view.</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 3</td>\n",
       "      <td>60 61 62 63 64 65</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144266</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>470.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>Let's say this person needs to ask their teach...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 9...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144267</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>876.0</td>\n",
       "      <td>1267.0</td>\n",
       "      <td>For instance, they need help picking a collag...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>152 153 154 155 156 157 158 159 160 161 162 16...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144268</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>1356.0</td>\n",
       "      <td>1679.0</td>\n",
       "      <td>For example, they can see what other people ha...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 3</td>\n",
       "      <td>234 235 236 237 238 239 240 241 242 243 244 24...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144269</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>2052.0</td>\n",
       "      <td>In conclusion, asking advice can help someone ...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>295 296 297 298 299 300 301 302 303 304 305 30...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144270</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>There has been at least one point in everyone'...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144271</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>318.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>Because of this, sometimes, asking just one pe...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 7...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144272</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>684.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>mistake,</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144273</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>693.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>misunderstanding,</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 2</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144274</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>714.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>misdeed.</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 3</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144275</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>725.0</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>While mistakes and misunderstanding might have...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>124 125 126 127 128 129 130 131 132 133 134 13...</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144276</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>1361.0</td>\n",
       "      <td>1471.0</td>\n",
       "      <td>The more similar iterations people give you, t...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 4</td>\n",
       "      <td>234 235 236 237 238 239 240 241 242 243 244 24...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144277</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>1881.0</td>\n",
       "      <td>Misunderstandings are harder to avoid because ...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>252 253 254 255 256 257 258 259 260 261 262 26...</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144278</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>1882.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>The best thing to do in a situation like that ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 5</td>\n",
       "      <td>326 327 328 329 330 331 332 333 334 335 336 33...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144279</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>2029.0</td>\n",
       "      <td>2123.0</td>\n",
       "      <td>misdeeds are when the advice-giver is purpose...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 6</td>\n",
       "      <td>354 355 356 357 358 359 360 361 362 363 364 36...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144280</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>2123.0</td>\n",
       "      <td>2702.0</td>\n",
       "      <td>An example of this is when you ask Generic_Nam...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 3</td>\n",
       "      <td>368 369 370 371 372 373 374 375 376 377 378 37...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144281</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>2703.0</td>\n",
       "      <td>2799.0</td>\n",
       "      <td>Now, I know what you probably saying \"But what...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Counterclaim 1</td>\n",
       "      <td>465 466 467 468 469 470 471 472 473 474 475 47...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144282</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>2817.0</td>\n",
       "      <td>2907.0</td>\n",
       "      <td>what are the odds that seven of your close fr...</td>\n",
       "      <td>Rebuttal</td>\n",
       "      <td>Rebuttal 1</td>\n",
       "      <td>487 488 489 490 491 492 493 494 495 496 497 49...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144283</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>2907.0</td>\n",
       "      <td>3140.0</td>\n",
       "      <td>The odds are in your favor; and the on the off...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>505 506 507 508 509 510 511 512 513 514 515 51...</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  discourse_id  discourse_start  discourse_end  \\\n",
       "144261  408A7D3D2EEC  1.618325e+12              0.0          228.0   \n",
       "144262  408A7D3D2EEC  1.618325e+12            229.0          294.0   \n",
       "144263  408A7D3D2EEC  1.618325e+12            303.0          339.0   \n",
       "144264  408A7D3D2EEC  1.618325e+12            340.0          356.0   \n",
       "144265  408A7D3D2EEC  1.618325e+12            362.0          392.0   \n",
       "144266  408A7D3D2EEC  1.618325e+12            470.0          779.0   \n",
       "144267  408A7D3D2EEC  1.618325e+12            876.0         1267.0   \n",
       "144268  408A7D3D2EEC  1.618325e+12           1356.0         1679.0   \n",
       "144269  408A7D3D2EEC  1.618325e+12           1680.0         2052.0   \n",
       "144270  AFEC37C2D43F  1.617803e+12              0.0          317.0   \n",
       "144271  AFEC37C2D43F  1.617803e+12            318.0          515.0   \n",
       "144272  AFEC37C2D43F  1.617803e+12            684.0          692.0   \n",
       "144273  AFEC37C2D43F  1.617803e+12            693.0          710.0   \n",
       "144274  AFEC37C2D43F  1.617803e+12            714.0          724.0   \n",
       "144275  AFEC37C2D43F  1.617803e+12            725.0         1360.0   \n",
       "144276  AFEC37C2D43F  1.617803e+12           1361.0         1471.0   \n",
       "144277  AFEC37C2D43F  1.617803e+12           1472.0         1881.0   \n",
       "144278  AFEC37C2D43F  1.617803e+12           1882.0         2019.0   \n",
       "144279  AFEC37C2D43F  1.617803e+12           2029.0         2123.0   \n",
       "144280  AFEC37C2D43F  1.617803e+12           2123.0         2702.0   \n",
       "144281  AFEC37C2D43F  1.617803e+12           2703.0         2799.0   \n",
       "144282  AFEC37C2D43F  1.617803e+12           2817.0         2907.0   \n",
       "144283  AFEC37C2D43F  1.617803e+12           2907.0         3140.0   \n",
       "\n",
       "                                           discourse_text  \\\n",
       "144261  Imagine seeking advice from multiple people an...   \n",
       "144262  Seeking multiple opinions can help someone mak...   \n",
       "144263               they can see which advice is better    \n",
       "144264                                   more experienced   \n",
       "144265                     see the persons point of view.   \n",
       "144266  Let's say this person needs to ask their teach...   \n",
       "144267   For instance, they need help picking a collag...   \n",
       "144268  For example, they can see what other people ha...   \n",
       "144269  In conclusion, asking advice can help someone ...   \n",
       "144270  There has been at least one point in everyone'...   \n",
       "144271  Because of this, sometimes, asking just one pe...   \n",
       "144272                                           mistake,   \n",
       "144273                                  misunderstanding,   \n",
       "144274                                          misdeed.    \n",
       "144275  While mistakes and misunderstanding might have...   \n",
       "144276  The more similar iterations people give you, t...   \n",
       "144277  Misunderstandings are harder to avoid because ...   \n",
       "144278  The best thing to do in a situation like that ...   \n",
       "144279   misdeeds are when the advice-giver is purpose...   \n",
       "144280  An example of this is when you ask Generic_Nam...   \n",
       "144281  Now, I know what you probably saying \"But what...   \n",
       "144282   what are the odds that seven of your close fr...   \n",
       "144283  The odds are in your favor; and the on the off...   \n",
       "\n",
       "              discourse_type      discourse_type_num  \\\n",
       "144261                  Lead                  Lead 1   \n",
       "144262              Position              Position 1   \n",
       "144263                 Claim                 Claim 1   \n",
       "144264                 Claim                 Claim 2   \n",
       "144265                 Claim                 Claim 3   \n",
       "144266              Evidence              Evidence 1   \n",
       "144267              Evidence              Evidence 2   \n",
       "144268              Evidence              Evidence 3   \n",
       "144269  Concluding Statement  Concluding Statement 1   \n",
       "144270                  Lead                  Lead 1   \n",
       "144271              Position              Position 1   \n",
       "144272                 Claim                 Claim 1   \n",
       "144273                 Claim                 Claim 2   \n",
       "144274                 Claim                 Claim 3   \n",
       "144275              Evidence              Evidence 1   \n",
       "144276                 Claim                 Claim 4   \n",
       "144277              Evidence              Evidence 2   \n",
       "144278                 Claim                 Claim 5   \n",
       "144279                 Claim                 Claim 6   \n",
       "144280              Evidence              Evidence 3   \n",
       "144281          Counterclaim          Counterclaim 1   \n",
       "144282              Rebuttal              Rebuttal 1   \n",
       "144283  Concluding Statement  Concluding Statement 1   \n",
       "\n",
       "                                         predictionstring  length_of_text  \n",
       "144261  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...              39  \n",
       "144262                      39 40 41 42 43 44 45 46 47 48              10  \n",
       "144263                               50 51 52 53 54 55 56               7  \n",
       "144264                                              57 58               2  \n",
       "144265                                  60 61 62 63 64 65               6  \n",
       "144266  79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 9...              57  \n",
       "144267  152 153 154 155 156 157 158 159 160 161 162 16...              67  \n",
       "144268  234 235 236 237 238 239 240 241 242 243 244 24...              61  \n",
       "144269  295 296 297 298 299 300 301 302 303 304 305 30...              65  \n",
       "144270  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...              61  \n",
       "144271  61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 7...              32  \n",
       "144272                                                120               1  \n",
       "144273                                                121               1  \n",
       "144274                                                123               1  \n",
       "144275  124 125 126 127 128 129 130 131 132 133 134 13...             110  \n",
       "144276  234 235 236 237 238 239 240 241 242 243 244 24...              18  \n",
       "144277  252 253 254 255 256 257 258 259 260 261 262 26...              74  \n",
       "144278  326 327 328 329 330 331 332 333 334 335 336 33...              27  \n",
       "144279  354 355 356 357 358 359 360 361 362 363 364 36...              14  \n",
       "144280  368 369 370 371 372 373 374 375 376 377 378 37...              97  \n",
       "144281  465 466 467 468 469 470 471 472 473 474 475 47...              17  \n",
       "144282  487 488 489 490 491 492 493 494 495 496 497 49...              18  \n",
       "144283  505 506 507 508 509 510 511 512 513 514 515 51...              46  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.id.isin(['408A7D3D2EEC', 'AFEC37C2D43F'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b1ae645-78e3-4830-aad3-2113592a9059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['TOKENIZERS_PARALLELISM']= \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9fbb80a-8a26-45e3-a4a6-c7fc37af276e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [00:03<00:00, 125.54it/s]\n",
      "100%|██████████| 390/390 [00:03<00:00, 120.36it/s]\n",
      "100%|██████████| 390/390 [00:03<00:00, 103.48it/s]\n",
      "100%|██████████| 390/390 [00:03<00:00, 104.63it/s]\n",
      "100%|██████████| 390/390 [00:03<00:00, 116.94it/s]\n",
      "100%|██████████| 389/389 [00:03<00:00, 110.08it/s]\n",
      "100%|██████████| 389/389 [00:03<00:00, 100.09it/s]\n",
      "100%|██████████| 389/389 [00:03<00:00, 99.20it/s] \n"
     ]
    }
   ],
   "source": [
    "check_samples= preprocessing.prepare_data(sample, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "170cd817-5134-49e2-92ea-47c3dbe902db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 65.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 54.41it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "check_samples_valid = preprocessing.prepare_data(train[train.id.isin(['408A7D3D2EEC', 'AFEC37C2D43F'])], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c406dd43-e819-481c-8fa4-96dacad524f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0c3f204-ee30-47da-b969-a051f60b9f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "input_ids\n",
      "text\n",
      "offset_mapping\n",
      "input_labels\n"
     ]
    }
   ],
   "source": [
    "for k,_ in check_samples[0].items(): print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76e73e16-91ab-4dca-b040-441d2277797d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'408A7D3D2EEC'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_samples_valid[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "949180e1-c8e2-4304-871e-41ef2b8c9a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(444, 2030, 444)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(check_samples[0]['input_ids']) , len(check_samples[0]['text']) , len(check_samples[0]['offset_mapping'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37595a19-b8bc-4121-9475-78bc0fc96a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420, 2052, 420)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(check_samples_valid[0]['input_ids']) , len(check_samples_valid[0]['text']) , len(check_samples_valid[0]['offset_mapping'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a835722d-cd20-406d-a75e-dc23dbf37b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Imagine seeking advice from multiple people and choosing the best decision that suits you. How does that make you feel? Asking for advice can be defined as someone who asks help from multiple people and makes the right decision. Seeking multiple opinions can help someone make a better decision because they can see which advice is better, more experienced, and see the persons point of view.\\n\\nAsking advice from multiple people can help you\\xa0see\\xa0which advice is better. Let's say this person needs to ask their teacher what book to choose. But, they also asked their friends the same question. They can now see which decision is better for them. It also depends if the advice is decent or not because if the advice is horrible, then that decision you make can affect the outcome.\\n\\nAnother way asking advice from multiple people can help you is they might have more experience. For instance, they need help picking a collage that suits their interest. When they ask their parents for advice, the parent might pick a different collage that could be better. But, that's because they have more experience and can see whats best for them. Grandparents especially, went through a lot when they were kids. So, if you need advice, ask adults who are more experienced in life!\\n\\nLastly, asking advice from multiple people can help you see the persons point of view. For example, they can see what other people have to say and can help you make that better decision. Let's say they need help painting their house but dont know what paint color to choose. But, when they ask someone for advice, they can see what the other person has to say and make the right decision based on that advice.\\n\\nIn conclusion, asking advice can help someone make a better decision because they can see the persons point of view, more experienced, and they can see which advice is better. Asking for advice is important because they can see which\\xa0advice is better and can see other peoples perspective. This affects you because its on you to ask for advice and make the right decision!\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_samples_valid[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1434385d-3fa8-49de-94d5-5d207b346a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There has been at least one point in everyone\\'s life where you have asked or been asked for advice on a certain topic or subject. Everyone needs help with something, and it is a genetic trait to ask someone else for advice. However, a lot of people can be dishonest, and in this day and age, that number only goes up. Because of this, sometimes, asking just one person is not enough. Now a days, a person looking for help will most likely confront multiple people for advice to prevent problems with misinformation. The problem, while gigantic in scale now, can be rooted down to three different source problems I call \"The Three Probl-Ms of Advice-giving\". These three problems are: mistake, misunderstanding, and misdeed.\\n\\nWhile mistakes and misunderstanding might have similar definitions, in this context they are two completely different things. First of all, mistakes are when the advice-giver confuses two similar things and gives the wrong advice. A good example of this is when you are talking about a level on a video game you are having trouble with, and your friend, thinking about a similar level, gives you incorrect advice. Now you are going to have a harder time beating the level because your friend told you about a different level. However, this could have all been avoided if you had asked three or four more people for advice on the level. The more similar iterations people give you, the better the chance that the information your getting is true.\\n\\nMisunderstandings are harder to avoid because these problems will most likely arise from the environment or conditions you are in. an example of this is you are making a phone call, and the connection is pretty terrible. It is hard to understand what uncle Generic_Name is trying to tell you through all the static. There is really no way to fix the connection nor is there a way to prevent all of the static. The best thing to do in a situation like that is to just get more advice from more people. Uncle Generic_Name is only one person any way.\\n\\nFinally, misdeeds are when the advice-giver is purposely tampering with information to mess with you. An example of this is when you ask Generic_Name how to play the accordion better. Generic_Name, thinking that it would be funny, tells you that you need to aggressively compress and decompress the accordion repeatedly. you accidentally break the accordion, and Now you have a broken accordion, some damaged pride, and still no idea how to play the accordion. However, this could have all been avoided if you had asked all of the accordion players from your music class for advice on playing the accordion. Also you should not have trusted Generic_Name advice in the first place.\\n\\nNow, I know what you probably saying \"But what if everyone you ask gives you incorrect advice?\" and to that I say: what are the odds that seven of your close friends do not no what you are talking about? The odds are in your favor; and the on the off chance that the odds are not in you favor? Just expand your focus group, ask new people, be confident. You just need to ask more people. Now go ask those questions, and get some answers.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_samples_valid[1]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "020bef32-01a9-44a2-b457-9af7ba52a866",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'O', 'B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'B-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'I-Position', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'O', 'O', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'O', 'O', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'O', 'O', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'O', 'O', 'B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'I-Claim', 'B-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'I-Evidence', 'B-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'I-Concluding Statement', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(check_samples[0]['input_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75ef3a9c-2437-4d6a-b9de-2135cdfa40e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e076c35-1fb5-457a-bb94-55ce9aa15313",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate = preprocessing.Collate(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21314c35-290e-422b-86f5-0439f5d80696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "\n",
    "\n",
    "valid_dataloader = dataset.Datasetloader(samples=check_samples_valid,tokenizer=tokenizer ,max_len= 2036 ,test=False,inference=False).fetch(\n",
    "    batch_size=4, num_workers=config.NUM_WORKERS, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba725f2d-7e60-4be6-b2c6-3d41a01dcb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = dataset.Datasetloader(samples=check_samples,tokenizer=tokenizer ,max_len= 2036 ,test=False,inference=False).fetch(\n",
    "    batch_size=2, num_workers=config.NUM_WORKERS, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9b12204-84fe-41eb-a109-5725816fd2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([[    0,   970,    34,  ...,     1,     1,     1],\n",
       "         [    0, 31206,  1818,  ...,     1,     1,     1]]),\n",
       " 'mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'targets': tensor([[  14,    0,    1,  ..., -100, -100, -100],\n",
       "         [  14,    0,    1,  ..., -100, -100, -100]])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(valid_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45b6c95a-05df-4fb3-a4e8-a5321a16a807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([[    0, 23314,   331,  ...,     1,     1,     1],\n",
       "         [    0,  2895,   521,  ...,     1,     1,     1]]),\n",
       " 'mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'targets': tensor([[  14,   14,   14,  ..., -100, -100, -100],\n",
       "         [  14,    0,    1,  ..., -100, -100, -100]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b78e9ee0-06cc-4b19-87f9-013342137598",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = next(iter(valid_dataloader))\n",
    "cc1 = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0aa31cb-8f57-4a2d-b1b3-c497a397f06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(665, 665)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cc['mask'][0]) , len(cc['ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "972aa05a-17af-41b5-9d2f-ef2f7ba06887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2036"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cc1['mask'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4f90ec2-0e56-42b1-b647-67a5e1b4a522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_logits(raw_logits, word_ids):\n",
    "    word_ids = word_ids.view(-1)\n",
    "    active_mask = word_ids.unsqueeze(1).expand(word_ids.shape[0], Config.num_labels)\n",
    "    active_mask = active_mask != NON_LABEL\n",
    "    active_logits = raw_logits.view(-1, Config.num_labels)\n",
    "    active_logits = torch.masked_select(active_logits, active_mask) # return 1dTensor\n",
    "    active_logits = active_logits.view(-1, Config.num_labels) \n",
    "    return active_logits\n",
    "\n",
    "def active_labels(labels):\n",
    "    active_mask = labels.view(-1) != IGNORE_INDEX\n",
    "    active_labels = torch.masked_select(labels.view(-1), active_mask)\n",
    "    return active_labels\n",
    "\n",
    "def active_preds_prob(active_logits):\n",
    "    active_preds = torch.argmax(active_logits, axis = 1)\n",
    "    active_preds_prob, _ = torch.max(active_logits, axis = 1)\n",
    "    return active_preds, active_preds_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c80040-4303-4fc0-97b3-b7e698a9207d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78df45d8-5d47-453f-987b-a7007b67fa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import dataset\n",
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d067845c-773f-4c48-9a07-12b2371028f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the training and early stopping function\n",
    "import engine\n",
    "from model import LongformerModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74adbc7a-7474-4314-a59c-ec070514807b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at model_obj/longformer-base-4096/ were not used when initializing LongformerModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LongformerModel(\n",
       "  (longformer): LongformerModel(\n",
       "    (embeddings): LongformerEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): LongformerEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): LongformerPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (dropout3): Dropout(p=0.3, inplace=False)\n",
       "  (dropout4): Dropout(p=0.4, inplace=False)\n",
       "  (dropout5): Dropout(p=0.5, inplace=False)\n",
       "  (output): Linear(in_features=768, out_features=15, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Intialize Model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_config = AutoConfig.from_pretrained(config.CONFIG_NAME)\n",
    "model = LongformerModel(config.MODEL_PATH, config=model_config)\n",
    "\n",
    "\n",
    "\n",
    "# optimizer\n",
    "optimizer = engine.get_optimizer(model, type=\"i\")\n",
    "\n",
    "\n",
    "# mixed precision training with NVIDIA Apex\n",
    "if config.FP16:\n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=config.FP16_OPT_LEVEL)\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# # scheduler\n",
    "# num_training_steps = math.ceil(\n",
    "#     len(train_dataloader) / config.GRADIENT_ACC_STEPS) * config.EPOCHS\n",
    "# if config.WARMUP_RATIO > 0:\n",
    "#     num_warmup_steps = int(config.WARMUP_RATIO * num_training_steps)\n",
    "# else:\n",
    "#     num_warmup_steps = 0\n",
    "# print(\n",
    "#     f\"Total Training Steps: {num_training_steps}, Total Warmup Steps: {num_warmup_steps}\")\n",
    "\n",
    "# scheduler = engine.get_scheduler(\n",
    "#     optimizer, num_warmup_steps, num_training_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78ae6ccc-2b3e-4826-b754-e4905cc1b5ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1560/1560 [13:19<00:00,  1.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 1/10\n",
      "| Train Loss = 1.0519027082870405 | Valid Loss = 0.7603307962417603 | F1 Score  :{'f1': 0.386818356891241} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1560/1560 [13:14<00:00,  1.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 2/10\n",
      "| Train Loss = 0.6771706224586337 | Valid Loss = 0.7649502754211426 | F1 Score  :{'f1': 0.49478702061841406} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 897/1560 [07:36<05:37,  1.97it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22757/3258712773.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     train_loss = engine.train_fn(\n\u001b[0m\u001b[1;32m      3\u001b[0m         train_dataloader, model, optimizer, device, scheduler)\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     test_loss, predictions ,true_vals, metrics = engine.evaluate(\n",
      "\u001b[0;32m~/workspace/feedback/engine.py\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(dataloader, model, optimizer, device, scheduler)\u001b[0m\n\u001b[1;32m    229\u001b[0m                     \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    train_loss = engine.train_fn(\n",
    "        train_dataloader, model, optimizer, device, scheduler)\n",
    "\n",
    "    test_loss, predictions ,true_vals, metrics = engine.evaluate(\n",
    "        valid_dataloader, model, device)\n",
    "    \n",
    "#     _, predictions ,_, _ = engine.evaluate(\n",
    "#         valid_dataloader, model, device,inference=True)\n",
    "\n",
    "    valid_features_ =   copy.deepcopy(check_samples_valid)\n",
    "    df_pred, valid_features_ = get_preds_per_epoch(predictions,valid_features_)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    print(f\"EPOCH : {epoch + 1}/{config.EPOCHS}\")\n",
    "    print(f\"| Train Loss = {train_loss} | Valid Loss = {test_loss} | F1 Score  :{metrics} \")\n",
    "    f1_score_avg = gen_validation_report(submission,valid_features_)\n",
    "    print(f\"Overall Validation avg F1: {f1_score_avg:.4f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "016a6ff1-2dab-45ec-a5af-9537d01f7927",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'output/longformers/model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a9d22cd-fd7e-426a-9c81-40b569c9dc5d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LongformerModel(\n",
       "  (longformer): LongformerModel(\n",
       "    (embeddings): LongformerEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): LongformerEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): LongformerPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (dropout3): Dropout(p=0.3, inplace=False)\n",
       "  (dropout4): Dropout(p=0.4, inplace=False)\n",
       "  (dropout5): Dropout(p=0.5, inplace=False)\n",
       "  (output): Linear(in_features=768, out_features=15, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load model\n",
    "\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load('output/longformers/model.bin', map_location=device))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a656808-7067-4a44-9f16-92a3151e7b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, valid_set_ = train_folds[train_folds['kfold']!= 0], train_folds[train_folds['kfold'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2af02f7e-3d78-4771-8bd7-47c180e62ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_set = preprocessing.prepare_data(valid_set_, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b2b53f8-cc34-4d15-9bb1-87b70123f11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59951</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>1.617735e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>Some people belive that the so called \"face\" o...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59952</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>1.617735e+12</td>\n",
       "      <td>170.0</td>\n",
       "      <td>357.0</td>\n",
       "      <td>It was not created by aliens, and there is no ...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 4...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59953</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>1.617735e+12</td>\n",
       "      <td>358.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>A mesa is a naturally occuring rock formation,...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>69 70 71 72 73 74 75 76 77 78 79 80 81 82 83</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59954</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>1.617735e+12</td>\n",
       "      <td>438.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>This \"face\" on mars only looks like a face bec...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 9...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59955</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>1.617735e+12</td>\n",
       "      <td>627.0</td>\n",
       "      <td>722.0</td>\n",
       "      <td>Many conspiracy theorists believe that NASA is...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Counterclaim 1</td>\n",
       "      <td>117 118 119 120 121 122 123 124 125 126 127 12...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59956</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>1.617735e+12</td>\n",
       "      <td>722.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>These people would be very wrong. If NASA foun...</td>\n",
       "      <td>Rebuttal</td>\n",
       "      <td>Rebuttal 1</td>\n",
       "      <td>134 135 136 137 138 139 140 141 142 143 144 14...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59957</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>1.617735e+12</td>\n",
       "      <td>836.0</td>\n",
       "      <td>1014.0</td>\n",
       "      <td>NASA's budget would increase drasticly, which ...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 3</td>\n",
       "      <td>154 155 156 157 158 159 160 161 162 163 164 16...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59958</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>1.617735e+12</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>1343.0</td>\n",
       "      <td>So, NASA is not hiding life on Mars from us, a...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>186 187 188 189 190 191 192 193 194 195 196 19...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  discourse_id  discourse_start  discourse_end  \\\n",
       "59951  0000D23A521A  1.617735e+12              0.0          170.0   \n",
       "59952  0000D23A521A  1.617735e+12            170.0          357.0   \n",
       "59953  0000D23A521A  1.617735e+12            358.0          438.0   \n",
       "59954  0000D23A521A  1.617735e+12            438.0          626.0   \n",
       "59955  0000D23A521A  1.617735e+12            627.0          722.0   \n",
       "59956  0000D23A521A  1.617735e+12            722.0          836.0   \n",
       "59957  0000D23A521A  1.617735e+12            836.0         1014.0   \n",
       "59958  0000D23A521A  1.617735e+12           1015.0         1343.0   \n",
       "\n",
       "                                          discourse_text  \\\n",
       "59951  Some people belive that the so called \"face\" o...   \n",
       "59952  It was not created by aliens, and there is no ...   \n",
       "59953  A mesa is a naturally occuring rock formation,...   \n",
       "59954  This \"face\" on mars only looks like a face bec...   \n",
       "59955  Many conspiracy theorists believe that NASA is...   \n",
       "59956  These people would be very wrong. If NASA foun...   \n",
       "59957  NASA's budget would increase drasticly, which ...   \n",
       "59958  So, NASA is not hiding life on Mars from us, a...   \n",
       "\n",
       "             discourse_type      discourse_type_num  \\\n",
       "59951              Position              Position 1   \n",
       "59952              Evidence              Evidence 1   \n",
       "59953              Evidence              Evidence 2   \n",
       "59954                 Claim                 Claim 1   \n",
       "59955          Counterclaim          Counterclaim 1   \n",
       "59956              Rebuttal              Rebuttal 1   \n",
       "59957              Evidence              Evidence 3   \n",
       "59958  Concluding Statement  Concluding Statement 1   \n",
       "\n",
       "                                        predictionstring  kfold  \n",
       "59951  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...      3  \n",
       "59952  34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 4...      3  \n",
       "59953       69 70 71 72 73 74 75 76 77 78 79 80 81 82 83      3  \n",
       "59954  84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 9...      3  \n",
       "59955  117 118 119 120 121 122 123 124 125 126 127 12...      3  \n",
       "59956  134 135 136 137 138 139 140 141 142 143 144 14...      3  \n",
       "59957  154 155 156 157 158 159 160 161 162 163 164 16...      3  \n",
       "59958  186 187 188 189 190 191 192 193 194 195 196 19...      3  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folds[train_folds.id ==\"0000D23A521A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f64a4d93-d3ff-4d6e-8c4c-110b41b3506b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Some people belive that the so called \"face\" on mars was created by life on mars. This is not the case. The face on Mars is a naturally occuring land form called a mesa. ',\n",
       "       'It was not created by aliens, and there is no consiracy to hide alien lifeforms on mars. There is no evidence that NASA has found that even suggests that this face was created by aliens. ',\n",
       "       'A mesa is a naturally occuring rock formation, that is found on Mars and Earth. ',\n",
       "       'This \"face\" on mars only looks like a face because humans tend to see faces wherever we look, humans are obviously extremely social, which is why our brain is designed to recognize faces. ',\n",
       "       'Many conspiracy theorists believe that NASA is hiding life on Mars from the rest of the world. ',\n",
       "       \"These people would be very wrong. If NASA found life on Mars, then they would get millions of people's attention. \",\n",
       "       \"NASA's budget would increase drasticly, which means that their workers would get paid more. There is no good reason that NASA would hide life on Mars from the rest of the world.\\n\",\n",
       "       'So, NASA is not hiding life on Mars from us, and they are not trying to trick us into thinking that the \"face\" on mars is just a mesa, because it actually is. NASA hiding life would be illogical, because if they found life on Mars, they would make a lot of money, and we all know that the people at NASA aren\\'t illogical people.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folds[train_folds.id ==\"0000D23A521A\"]['discourse_text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62afe68b-df83-4d1d-a3f5-8bbd7ae4821a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some people belive that the so called \"face\" on mars was created by life on mars. This is not the case. The face on Mars is a naturally occuring land form called a mesa. It was not created by aliens, and there is no consiracy to hide alien lifeforms on mars. There is no evidence that NASA has found that even suggests that this face was created by aliens. A mesa is a naturally occuring rock formation, that is found on Mars and Earth. This \"face\" on mars only looks like a face because humans tend to see faces wherever we look, humans are obviously extremely social, which is why our brain is designed to recognize faces. Many conspiracy theorists believe that NASA is hiding life on Mars from the rest of the world. These people would be very wrong. If NASA found life on Mars, then they would get millions of people\\'s attention. NASA\\'s budget would increase drasticly, which means that their workers would get paid more. There is no good reason that NASA would hide life on Mars from the rest of the world.\\nSo, NASA is not hiding life on Mars from us, and they are not trying to trick us into thinking that the \"face\" on mars is just a mesa, because it actually is. NASA hiding life would be illogical, because if they found life on Mars, they would make a lot of money, and we all know that the people at NASA aren\\'t illogical people.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(train_folds[train_folds.id ==\"0000D23A521A\"]['discourse_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8437ba59-e5ed-427f-9b93-aa4a31647eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=False,\n",
    "            return_offsets_mapping=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fa2588c-ed26-47ad-804c-2bdd310f4343",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataloader = dataset.Datasetloader(samples=valid_set,tokenizer=tokenizer ,max_len= config.MAX_SEQ_LEN  , test=False,inference=False).fetch(\n",
    "        batch_size=2, num_workers=config.NUM_WORKERS, shuffle=False, drop_last=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a02b9e95-0e06-4ef7-a192-81ecb5d41d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "151e76e5-a097-4058-9f3d-cbe547616c92",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): LongformerModel(\n",
       "    (longformer): LongformerModel(\n",
       "      (embeddings): LongformerEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): LongformerEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): LongformerLayer(\n",
       "            (attention): LongformerAttention(\n",
       "              (self): LongformerSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (output): LongformerSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): LongformerIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): LongformerOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): LongformerLayer(\n",
       "            (attention): LongformerAttention(\n",
       "              (self): LongformerSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (output): LongformerSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): LongformerIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): LongformerOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): LongformerLayer(\n",
       "            (attention): LongformerAttention(\n",
       "              (self): LongformerSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (output): LongformerSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): LongformerIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): LongformerOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): LongformerLayer(\n",
       "            (attention): LongformerAttention(\n",
       "              (self): LongformerSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (output): LongformerSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): LongformerIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): LongformerOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): LongformerLayer(\n",
       "            (attention): LongformerAttention(\n",
       "              (self): LongformerSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (output): LongformerSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): LongformerIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): LongformerOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): LongformerLayer(\n",
       "            (attention): LongformerAttention(\n",
       "              (self): LongformerSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (output): LongformerSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): LongformerIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): LongformerOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): LongformerLayer(\n",
       "            (attention): LongformerAttention(\n",
       "              (self): LongformerSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (output): LongformerSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): LongformerIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): LongformerOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): LongformerLayer(\n",
       "            (attention): LongformerAttention(\n",
       "              (self): LongformerSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (output): LongformerSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): LongformerIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): LongformerOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): LongformerLayer(\n",
       "            (attention): LongformerAttention(\n",
       "              (self): LongformerSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (output): LongformerSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): LongformerIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): LongformerOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): LongformerLayer(\n",
       "            (attention): LongformerAttention(\n",
       "              (self): LongformerSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (output): LongformerSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): LongformerIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): LongformerOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): LongformerLayer(\n",
       "            (attention): LongformerAttention(\n",
       "              (self): LongformerSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (output): LongformerSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): LongformerIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): LongformerOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): LongformerLayer(\n",
       "            (attention): LongformerAttention(\n",
       "              (self): LongformerSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (output): LongformerSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): LongformerIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): LongformerOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): LongformerPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (dropout2): Dropout(p=0.2, inplace=False)\n",
       "    (dropout3): Dropout(p=0.3, inplace=False)\n",
       "    (dropout4): Dropout(p=0.4, inplace=False)\n",
       "    (dropout5): Dropout(p=0.5, inplace=False)\n",
       "    (output): Linear(in_features=768, out_features=15, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.DataParallel(model)\n",
    "model.load_state_dict(torch.load('output/longformers/checkpoint-fold-0/pytorch_model.bin', map_location=device))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ffd5c29-e690-42d0-85c5-83320f3ab2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1559 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|██████████| 1559/1559 [02:39<00:00,  9.75it/s]\n"
     ]
    }
   ],
   "source": [
    "test_loss, predictions ,true_vals, metrics = engine.evaluate_testing(valid_dataloader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd550e46-8e0d-4f56-a541-1cae5b3f5943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1559"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3697759e-bb70-4949-a185-6975160ebe4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1559"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c3978197-9334-4bed-9820-d1c76fd96b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_features_ =   copy.deepcopy(valid_set)\n",
    "df_pred, valid_features_ = get_preds_per_epoch(predictions,valid_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8794bb14-3ee0-4c56-9f4a-2eff664f0130",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = link_evidence(df_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "95139642-0029-482b-af86-8be23d0c1bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A8445CABFECE</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>89 90 91 92 93 94 95 96 97 98 99 100 101 102 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A8445CABFECE</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>168 169 170 171 172 173 174 175 176 177 178 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A97DE0D49AEA</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>181 182 183 184 185 186 187 188 189 190 191 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A97DE0D49AEA</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>261 262 263 264 265 266 267 268 269 270 271 27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AC594194F01C</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23856</th>\n",
       "      <td>0814426B27DF</td>\n",
       "      <td>Claim</td>\n",
       "      <td>52 53 54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23857</th>\n",
       "      <td>0814426B27DF</td>\n",
       "      <td>Claim</td>\n",
       "      <td>55 56 57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23858</th>\n",
       "      <td>0814426B27DF</td>\n",
       "      <td>Claim</td>\n",
       "      <td>58 59 60 61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23859</th>\n",
       "      <td>0814426B27DF</td>\n",
       "      <td>Claim</td>\n",
       "      <td>63 64 65 66 67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23860</th>\n",
       "      <td>0814426B27DF</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>438 439 440 441 442 443 444 445 446 447 448 44...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23861 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                 class  \\\n",
       "0      A8445CABFECE              Evidence   \n",
       "1      A8445CABFECE              Evidence   \n",
       "2      A97DE0D49AEA              Evidence   \n",
       "3      A97DE0D49AEA              Evidence   \n",
       "4      AC594194F01C              Evidence   \n",
       "...             ...                   ...   \n",
       "23856  0814426B27DF                 Claim   \n",
       "23857  0814426B27DF                 Claim   \n",
       "23858  0814426B27DF                 Claim   \n",
       "23859  0814426B27DF                 Claim   \n",
       "23860  0814426B27DF  Concluding Statement   \n",
       "\n",
       "                                        predictionstring  \n",
       "0      89 90 91 92 93 94 95 96 97 98 99 100 101 102 1...  \n",
       "1      168 169 170 171 172 173 174 175 176 177 178 17...  \n",
       "2      181 182 183 184 185 186 187 188 189 190 191 19...  \n",
       "3      261 262 263 264 265 266 267 268 269 270 271 27...  \n",
       "4      31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 4...  \n",
       "...                                                  ...  \n",
       "23856                                           52 53 54  \n",
       "23857                                           55 56 57  \n",
       "23858                                        58 59 60 61  \n",
       "23859                                     63 64 65 66 67  \n",
       "23860  438 439 440 441 442 443 444 445 446 447 448 44...  \n",
       "\n",
       "[23861 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8b59939e-d30d-4822-9291-17a692a0485e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 scores\n",
      " * Lead      : 0.290125\n",
      " * Position  : 0.105572\n",
      " * Claim     : 0.094359\n",
      " * Counterclaim: 0.009217\n",
      " * Rebuttal  : 0.007220\n",
      " * Evidence  : 0.284033\n",
      " * Concluding Statement: 0.086588\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f1_score_avg = preprocessing.gen_validation_report(df_pred,valid_set_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e711ec7f-4eda-4a02-a32c-b0be1bbb5e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12530195021012183"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5f733af-d651-490c-b24c-5d86754e3e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_per_epoch(predictions,valid_dataset):\n",
    "    \n",
    "    valid_dataset = pred_class_probabilty(predictions,valid_dataset) \n",
    "    df_pred = generate_submission(valid_dataset)\n",
    "\n",
    "    return df_pred, valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2820e12b-e424-45fa-891b-565e1d4cdd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_class_probabilty(predictions,valid_dataset):\n",
    "    final_preds = []\n",
    "    final_scores = []\n",
    "\n",
    "    for rp in predictions:\n",
    "        pred_class = np.argmax(rp, axis=2)\n",
    "        pred_scrs = np.max(rp, axis=2)\n",
    "        for pred, pred_scr in zip(pred_class, pred_scrs):\n",
    "            pred = pred.tolist()\n",
    "            pred_scr = pred_scr.tolist()\n",
    "            final_preds.append(pred)\n",
    "            final_scores.append(pred_scr)\n",
    "            \n",
    "            \n",
    "    for j in range(len(valid_dataset)):\n",
    "        tt = [id_target_map[p] for p in final_preds[j][1:]]\n",
    "        tt_score = final_scores[j][1:]\n",
    "        valid_dataset[j][\"preds\"] = tt\n",
    "        valid_dataset[j][\"pred_scores\"] = tt_score\n",
    "        \n",
    "    return valid_dataset\n",
    "\n",
    "        \n",
    "        \n",
    "def generate_submission(valid_dataset):\n",
    "\n",
    "    submission = []\n",
    "    for sample_idx, sample in enumerate(valid_dataset):\n",
    "\n",
    "        preds = sample[\"preds\"]\n",
    "        offset_mapping = sample[\"offset_mapping\"]\n",
    "        sample_id = sample[\"id\"]\n",
    "        sample_text = sample[\"text\"]\n",
    "        sample_input_ids = sample[\"input_ids\"]\n",
    "        sample_pred_scores = sample[\"pred_scores\"]\n",
    "        sample_preds = []\n",
    "\n",
    "        if len(preds) < len(offset_mapping):\n",
    "\n",
    "            preds = preds + [\"O\"] * (len(offset_mapping) - len(preds))\n",
    "            sample_pred_scores = sample_pred_scores + [0] * (len(offset_mapping) - len(sample_pred_scores))\n",
    "\n",
    "        idx = 0\n",
    "        phrase_preds = []\n",
    "        while idx < len(offset_mapping):\n",
    "            start, _ = offset_mapping[idx]\n",
    "            if preds[idx] != \"O\":\n",
    "                label = preds[idx][2:]\n",
    "            else:\n",
    "                label = \"O\"\n",
    "            phrase_scores = []\n",
    "            phrase_scores.append(sample_pred_scores[idx])\n",
    "            idx += 1\n",
    "            while idx < len(offset_mapping):\n",
    "                if label == \"O\":\n",
    "                    matching_label = \"O\"\n",
    "                else:\n",
    "                    matching_label = f\"I-{label}\"\n",
    "                if preds[idx] == matching_label:\n",
    "                    _, end = offset_mapping[idx]\n",
    "\n",
    "                    phrase_scores.append(sample_pred_scores[idx])\n",
    "                    idx += 1\n",
    "                else:\n",
    "                    break\n",
    "            if \"end\" in locals():\n",
    "                phrase = sample_text[start:end]\n",
    "                phrase_preds.append((phrase, start, end, label, phrase_scores))\n",
    "\n",
    "\n",
    "        temp_df = []\n",
    "        for phrase_idx, (phrase, start, end, label, phrase_scores) in enumerate(phrase_preds):\n",
    "            word_start = len(sample_text[:start].split())\n",
    "            word_end = word_start + len(sample_text[start:end].split())\n",
    "            word_end = min(word_end, len(sample_text.split()))\n",
    "            ps = \" \".join([str(x) for x in range(word_start, word_end)])\n",
    "\n",
    "            if label != \"O\":\n",
    "                if sum(phrase_scores) / len(phrase_scores) >= proba_thresh[label]:\n",
    "                    if len(ps.split()) >= min_thresh[label]:\n",
    "                        temp_df.append((sample_id, label, ps))\n",
    "    \n",
    "\n",
    "        temp_df = pd.DataFrame(temp_df, columns=[\"id\", \"class\", \"predictionstring\"])\n",
    "        submission.append(temp_df)\n",
    "        \n",
    "        \n",
    "    submission = pd.concat(submission).reset_index(drop=True)  \n",
    "    return submission\n",
    "\n",
    "        \n",
    "def gen_validation_report(submission,valid_dataset):\n",
    "    f1score =[]\n",
    "    classes = ['Lead', 'Position', 'Claim','Counterclaim', 'Rebuttal','Evidence','Concluding Statement']\n",
    "    print(f\"Validation F1 scores\")\n",
    "\n",
    "    for c in classes:\n",
    "        pred_df = submission.loc[submission['class'] == c].copy()\n",
    "        gt_df = valid_dataset.loc[valid_dataset['discourse_type'] == c].copy()\n",
    "        f1 = preprocessing.score_feedback_comp(pred_df, gt_df)\n",
    "        print(f' * {c:<10}: {f1:4f}')\n",
    "        f1score.append(f1)\n",
    "    f1avg = np.mean(f1score)\n",
    "    \n",
    "    return f1avg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d9bcb1b2-c67f-45f6-8345-27f89bee56d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "final_scores = []\n",
    "\n",
    "for rp in predictions:\n",
    "    pred_class = np.argmax(rp, axis=2)\n",
    "    pred_scrs = np.max(rp, axis=2)\n",
    "    for pred, pred_scr in zip(pred_class, pred_scrs):\n",
    "        pred = pred.tolist()\n",
    "        pred_scr = pred_scr.tolist()\n",
    "        final_preds.append(pred)\n",
    "        final_scores.append(pred_scr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b473f15f-1237-415e-8649-99c3461d38c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc['length_of_text'] = cc['text_split'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "960b543f-1dd0-4a75-b8a0-5121570d0e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    15594.000000\n",
       "mean       421.258048\n",
       "std        191.065363\n",
       "min        144.000000\n",
       "25%        278.000000\n",
       "50%        384.000000\n",
       "75%        520.000000\n",
       "max       1656.000000\n",
       "Name: length_of_text, dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc['length_of_text'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fdb5a339-a4fd-45ab-bfec-2d5a722e2618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>293C1D45E66B</td>\n",
       "      <td>During the summer, students get do to do as th...</td>\n",
       "      <td>[During, the, summer,, students, get, do, to, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6DFF43AD5171</td>\n",
       "      <td>Dear Principle,\\n\\nI think we should have cell...</td>\n",
       "      <td>[Dear, Principle,, I, think, we, should, have,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84D2A6C75C67</td>\n",
       "      <td>Talking to more than one person for ideas or a...</td>\n",
       "      <td>[Talking, to, more, than, one, person, for, id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>838005D1D7DC</td>\n",
       "      <td>The Face on Mars is just a natural landform. M...</td>\n",
       "      <td>[The, Face, on, Mars, is, just, a, natural, la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F59DDBF5DB0B</td>\n",
       "      <td>Have you ever wondered why so many people in t...</td>\n",
       "      <td>[Have, you, ever, wondered, why, so, many, peo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text  \\\n",
       "0  293C1D45E66B  During the summer, students get do to do as th...   \n",
       "1  6DFF43AD5171  Dear Principle,\\n\\nI think we should have cell...   \n",
       "2  84D2A6C75C67  Talking to more than one person for ideas or a...   \n",
       "3  838005D1D7DC  The Face on Mars is just a natural landform. M...   \n",
       "4  F59DDBF5DB0B  Have you ever wondered why so many people in t...   \n",
       "\n",
       "                                          text_split  \n",
       "0  [During, the, summer,, students, get, do, to, ...  \n",
       "1  [Dear, Principle,, I, think, we, should, have,...  \n",
       "2  [Talking, to, more, than, one, person, for, id...  \n",
       "3  [The, Face, on, Mars, is, just, a, natural, la...  \n",
       "4  [Have, you, ever, wondered, why, so, many, peo...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "defbff54-d52d-44fb-bafe-1b5c8adb9451",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_vals = tokenizer.encode_plus(\n",
    "            df_texts['text'].head(1).values[0].split(),\n",
    "            is_split_into_words = True,\n",
    "            add_special_tokens=True,\n",
    "            padding = 'max_length',\n",
    "            return_attention_mask=True,\n",
    "            truncation = True,\n",
    "            max_length = 2022,\n",
    "            return_offsets_mapping=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ac0c4364-0f31-4e56-bc51-b59473ccd908",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = tokenizer.encode_plus(\n",
    "             cc['text'].head(1).values[0],\n",
    "            add_special_tokens=False,\n",
    "            return_offsets_mapping=True,\n",
    "            truncation = True,\n",
    "            max_length = 2022\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "04d07959-657f-4675-8c4b-860e29f636c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 39, 40, 41, 42, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 93, 94, 95, 96, 97, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 128, 129, 130, 131, 132, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 178, 179, 180, 181, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 195, 196, 197, 197, 198, 199, 200, 201, 202, 203, 204, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 221, 222, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 277, 278, 279, 280, 281, 282, 283, 284, 285, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 297, 298, 299, 300, 301, 301, 301, 302, 303, 304, 305, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 412, 413, 414, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 473, 474, 475, 476, 477, 478, 479, 480, 481, 481, 481, 481, 482, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 499, 500, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 569, 570, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 616, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "print(encoding_vals.word_ids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dc71e8ad-d56b-41af-a905-981da1758342",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(encoding_vals['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "88459a68-fb37-470f-9d6e-1da9861013f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_labels = cc['entities'].head(1).values[0]\n",
    "input_labels = [target_id_map[x] for x in input_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "64066a42-0b23-4b1a-a91c-c5ef35f3df20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617\n"
     ]
    }
   ],
   "source": [
    "print(len(input_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ebc21d5c-ba71-4b7c-801f-4ca6dc6fd5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n"
     ]
    }
   ],
   "source": [
    "print([target_id_map[x] for x in input_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "63b3a41e-8c50-4667-90cd-7463ad44caef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1590, 5, 1035, 6, 521, 120, 109, 7, 109, 25, 51, 2540, 98, 24, 74, 129, 28, 2105, 13, 5, 521, 7, 1521, 49, 308, 695, 4, 6983, 197, 28, 441, 7, 1521, 49, 308, 1035, 1377, 13, 10, 346, 9, 2188, 4, 870, 608, 98, 6, 201, 25, 5, 521, 40, 28, 441, 7, 5486, 84, 308, 11140, 4, 85, 74, 492, 201, 55, 10563, 7, 120, 24, 626, 6, 25, 157, 25, 141, 5, 2948, 4730, 99, 5, 1159, 32, 2157, 4, 50118, 50118, 29413, 74, 28, 441, 7, 5486, 49, 308, 11140, 30, 608, 3046, 51, 236, 13, 5, 695, 4, 287, 10, 1294, 2185, 6, 38, 460, 120, 269, 2283, 77, 2948, 905, 5, 1159, 1339, 99, 51, 236, 7, 109, 13, 1377, 142, 24, 16, 101, 10, 1472, 9, 3519, 8, 10, 1203, 9, 14207, 4, 520, 38, 21, 410, 6, 65, 9, 127, 2948, 851, 201, 10, 695, 147, 52, 56, 7, 492, 10, 5209, 59, 99, 84, 2674, 3477, 21, 4, 85, 1299, 372, 14, 52, 46405, 33, 7, 7, 10, 5209, 59, 10, 3477, 14, 5, 3254, 74, 492, 201, 142, 99, 114, 24, 21, 3999, 84, 2674, 3477, 116, 2612, 197, 52, 33, 7, 109, 10, 695, 59, 10, 3477, 14, 52, 32, 3999, 2509, 11, 116, 125, 30, 5, 3254, 6901, 201, 4689, 6, 38, 21, 441, 7, 33, 1531, 608, 5, 695, 8, 38, 300, 41, 3973, 4978, 15, 24, 4, 50118, 50118, 19192, 4, 83, 1294, 1887, 695, 40, 67, 146, 1159, 236, 7, 109, 24, 4, 13308, 1072, 7, 109, 10, 15305, 695, 14, 16, 164, 7, 185, 6000, 81, 1035, 1108, 4, 318, 5, 521, 300, 7, 2845, 15, 99, 7, 109, 6, 52, 74, 33, 169, 55, 1531, 19, 24, 142, 24, 40, 146, 201, 236, 7, 109, 24, 6, 8, 67, 142, 24, 8382, 201, 5486, 4288, 4, 2223, 24, 74, 28, 2579, 13, 5, 521, 7, 1339, 5, 695, 6, 89, 32, 67, 12071, 4376, 4, 509, 9, 5, 12071, 4376, 40, 28, 14, 45, 961, 40, 109, 5, 695, 142, 51, 1169, 33976, 216, 99, 7, 109, 13, 5, 695, 50, 51, 32, 95, 22414, 4, 1578, 148, 5, 1035, 82, 32, 5796, 10, 319, 98, 103, 1159, 17672, 1498, 5, 695, 6, 1650, 63, 142, 51, 95, 33976, 236, 7, 50, 51, 17672, 142, 9, 49, 2259, 4, 50118, 50118, 47849, 1311, 201, 5, 1973, 7, 109, 42, 40, 146, 5, 521, 2239, 55, 1531, 4, 85, 74, 146, 24, 55, 1531, 142, 5, 2948, 32, 1311, 5, 521, 10, 945, 7, 1994, 1235, 8, 1311, 201, 10, 2236, 4, 318, 70, 52, 222, 21, 109, 99, 5, 2948, 770, 201, 7, 109, 6, 24, 74, 3999, 28, 2105, 142, 52, 32, 608, 2682, 14, 51, 206, 16, 205, 13, 201, 77, 5, 205, 631, 269, 16, 77, 5, 521, 120, 7, 1339, 1377, 4, 1491, 129, 16, 6901, 201, 1339, 5, 1377, 205, 13, 201, 6, 53, 24, 16, 67, 10, 2239, 676, 13, 5, 2948, 25, 157, 4, 38, 224, 14, 142, 114, 52, 1339, 5, 1377, 6, 5, 3254, 16, 164, 7, 1532, 141, 1159, 73, 13665, 14979, 206, 6, 8, 40, 386, 2992, 383, 62, 98, 14, 52, 64, 70, 5486, 430, 383, 11, 5, 8171, 4, 50118, 50118, 28965, 6, 318, 52, 905, 5, 1159, 4689, 1377, 81, 5, 1035, 24, 40, 28, 10, 2239, 676, 13, 961, 4, 20, 2948, 40, 269, 120, 7, 216, 141, 5, 521, 32, 269, 2157, 6, 8, 51, 64, 185, 14, 335, 8, 860, 7, 6396, 5, 1159, 11, 10, 430, 169, 148, 5, 334, 76, 4, 178, 24, 40, 28, 205, 13, 5, 521, 142, 52, 32, 67, 2239, 59, 4288, 25, 10, 621, 4, 13392, 14979, 32, 269, 6336, 142, 51, 33, 98, 171, 8597, 8, 47, 95, 17672, 1137, 141, 52, 32, 2157, 70, 5, 86, 4, 125, 38, 524, 1313, 14, 114, 52, 300, 7, 1521, 84, 308, 695, 6, 24, 74, 146, 201, 619, 55, 101, 3362, 8, 3032, 19, 2098, 4]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_text['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9959a336-c9a7-4c20-a9e9-2bc0b254c1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1590, 5, 1035, 6, 521, 120, 109, 7, 109, 25, 51, 2540, 98, 24, 74, 129, 28, 2105, 13, 5, 521, 7, 1521, 49, 308, 695, 4, 6983, 197, 28, 441, 7, 1521, 49, 308, 1035, 1377, 13, 10, 346, 9, 2188, 4, 870, 608, 98, 6, 201, 25, 5, 521, 40, 28, 441, 7, 5486, 84, 308, 11140, 4, 85, 74, 492, 201, 55, 10563, 7, 120, 24, 626, 6, 25, 157, 25, 141, 5, 2948, 4730, 99, 5, 1159, 32, 2157, 4, 6983, 74, 28, 441, 7, 5486, 49, 308, 11140, 30, 608, 3046, 51, 236, 13, 5, 695, 4, 287, 10, 1294, 2185, 6, 38, 460, 120, 269, 2283, 77, 2948, 905, 5, 1159, 1339, 99, 51, 236, 7, 109, 13, 1377, 142, 24, 16, 101, 10, 1472, 9, 3519, 8, 10, 1203, 9, 14207, 4, 520, 38, 21, 410, 6, 65, 9, 127, 2948, 851, 201, 10, 695, 147, 52, 56, 7, 492, 10, 5209, 59, 99, 84, 2674, 3477, 21, 4, 85, 1299, 372, 14, 52, 46405, 33, 7, 7, 10, 5209, 59, 10, 3477, 14, 5, 3254, 74, 492, 201, 142, 99, 114, 24, 21, 3999, 84, 2674, 3477, 116, 2612, 197, 52, 33, 7, 109, 10, 695, 59, 10, 3477, 14, 52, 32, 3999, 2509, 11, 116, 125, 30, 5, 3254, 6901, 201, 4689, 6, 38, 21, 441, 7, 33, 1531, 608, 5, 695, 8, 38, 300, 41, 3973, 4978, 15, 24, 4, 4130, 4, 83, 1294, 1887, 695, 40, 67, 146, 1159, 236, 7, 109, 24, 4, 13308, 1072, 7, 109, 10, 15305, 695, 14, 16, 164, 7, 185, 6000, 81, 1035, 1108, 4, 318, 5, 521, 300, 7, 2845, 15, 99, 7, 109, 6, 52, 74, 33, 169, 55, 1531, 19, 24, 142, 24, 40, 146, 201, 236, 7, 109, 24, 6, 8, 67, 142, 24, 8382, 201, 5486, 4288, 4, 2223, 24, 74, 28, 2579, 13, 5, 521, 7, 1339, 5, 695, 6, 89, 32, 67, 12071, 4376, 4, 509, 9, 5, 12071, 4376, 40, 28, 14, 45, 961, 40, 109, 5, 695, 142, 51, 1169, 33976, 216, 99, 7, 109, 13, 5, 695, 50, 51, 32, 95, 22414, 4, 1578, 148, 5, 1035, 82, 32, 5796, 10, 319, 98, 103, 1159, 17672, 1498, 5, 695, 6, 1650, 63, 142, 51, 95, 33976, 236, 7, 50, 51, 17672, 142, 9, 49, 2259, 4, 24817, 1311, 201, 5, 1973, 7, 109, 42, 40, 146, 5, 521, 2239, 55, 1531, 4, 85, 74, 146, 24, 55, 1531, 142, 5, 2948, 32, 1311, 5, 521, 10, 945, 7, 1994, 1235, 8, 1311, 201, 10, 2236, 4, 318, 70, 52, 222, 21, 109, 99, 5, 2948, 770, 201, 7, 109, 6, 24, 74, 3999, 28, 2105, 142, 52, 32, 608, 2682, 14, 51, 206, 16, 205, 13, 201, 77, 5, 205, 631, 269, 16, 77, 5, 521, 120, 7, 1339, 1377, 4, 1491, 129, 16, 6901, 201, 1339, 5, 1377, 205, 13, 201, 6, 53, 24, 16, 67, 10, 2239, 676, 13, 5, 2948, 25, 157, 4, 38, 224, 14, 142, 114, 52, 1339, 5, 1377, 6, 5, 3254, 16, 164, 7, 1532, 141, 1159, 73, 13665, 14979, 206, 6, 8, 40, 386, 2992, 383, 62, 98, 14, 52, 64, 70, 5486, 430, 383, 11, 5, 8171, 4, 7806, 6, 318, 52, 905, 5, 1159, 4689, 1377, 81, 5, 1035, 24, 40, 28, 10, 2239, 676, 13, 961, 4, 20, 2948, 40, 269, 120, 7, 216, 141, 5, 521, 32, 269, 2157, 6, 8, 51, 64, 185, 14, 335, 8, 860, 7, 6396, 5, 1159, 11, 10, 430, 169, 148, 5, 334, 76, 4, 178, 24, 40, 28, 205, 13, 5, 521, 142, 52, 32, 67, 2239, 59, 4288, 25, 10, 621, 4, 13392, 14979, 32, 269, 6336, 142, 51, 33, 98, 171, 8597, 8, 47, 95, 17672, 1137, 141, 52, 32, 2157, 70, 5, 86, 4, 125, 38, 524, 1313, 14, 114, 52, 300, 7, 1521, 84, 308, 695, 6, 24, 74, 146, 201, 619, 55, 101, 3362, 8, 3032, 19, 2098, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(encoding_vals['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "211a73a3-dccb-4b18-9bb2-f747f591e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = tokenizer.encode_plus(\n",
    "             ''.join( sample['discourse_text'].head(1).tolist()),\n",
    "            add_special_tokens=False,\n",
    "            return_offsets_mapping=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2a6f1724-9f8b-4377-ad78-3e36784582b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48083, 50118, 50118, 39631, 5868, 452, 32, 460, 15, 49, 1028, 4, 252, 32, 460, 15, 49, 1028, 55, 87, 195, 722, 10, 183, 117, 912, 479, 3684, 51, 109, 16, 2788, 124, 8, 556, 8, 95, 33, 333, 732, 2923, 15, 592, 433, 4, 252, 190, 109, 24, 150, 1428, 4, 252, 32, 103, 269, 1099, 4914, 77, 2682, 2594, 77, 24, 606, 7, 10, 1028, 4, 993, 1402, 911, 11, 5, 315, 532, 2020, 4247, 31, 1380, 5351, 95, 142, 9, 24, 4, 50118, 50118, 1779, 82, 33, 4247, 6, 51, 216, 59, 1402, 3798, 14, 51, 33, 479, 46036, 101, 622, 599, 1838, 8, 11477, 4, 407, 101, 114, 10, 1441, 3136, 409, 8, 47, 236, 7, 28, 11, 1511, 47, 64, 202, 28, 11, 1511, 30, 6016, 3424, 50, 2788, 3731, 4, 1806, 460, 33, 430, 1319, 141, 7, 8469, 19, 10, 1028, 4, 4129, 6909, 33, 1714, 528, 7, 84, 2706, 4, 50118, 50118, 34002, 6645, 16, 65, 9, 5, 169, 141, 7, 120, 198, 4, 1806, 460, 28, 15, 49, 4247, 150, 608, 24, 4, 6834, 64, 1303, 1473, 35677, 4, 280, 18, 596, 89, 18, 10, 631, 14, 18, 373, 117, 19943, 150, 1428, 4, 280, 18, 10, 269, 505, 631, 7, 2145, 4, 993, 82, 202, 109, 24, 142, 51, 206, 85, 18, 12103, 4, 440, 948, 99, 51, 109, 51, 202, 33, 7, 28616, 24, 142, 14, 18, 5, 129, 169, 141, 222, 37, 1871, 4, 50118, 50118, 13624, 15, 5, 340, 89, 16, 1169, 41, 3213, 50, 10, 4260, 4, 85, 429, 6877, 951, 45, 546, 147, 51, 214, 164, 50, 3545, 14, 951, 1051, 4, 85, 1169, 1356, 50, 744, 4, 318, 10, 12754, 346, 161, 38, 437, 164, 7, 3549, 47, 8, 51, 216, 147, 47, 697, 53, 47, 218, 75, 216, 5, 621, 18, 1511, 50118, 50118, 6, 243, 817, 47, 36742, 8, 146, 47, 386, 7, 21905, 66, 4, 6834, 64, 253, 62, 269, 7340, 4, 50118, 50118, 48083, 32, 2051, 7, 304, 8, 24, 18, 67, 5, 275, 169, 7, 283, 81, 244, 4, 318, 47, 213, 149, 10, 936, 8, 47, 64, 75, 465, 244, 47, 2156, 30035, 33, 10, 1028, 89, 19, 47, 4, 1648, 600, 4247, 32, 341, 818, 358, 183, 25, 251, 25, 47, 214, 1522, 24, 74, 283, 88, 304, 114, 47, 120, 88, 3605, 4, 5293, 686, 47, 109, 45, 28, 101, 42, 1028, 150, 47, 214, 11, 5, 1692, 9, 1428, 4, 20, 340, 460, 4752, 77, 82, 109, 402, 12103, 198, 14, 6890, 49, 4247, 4, 20, 25026, 169, 16, 5, 275, 169, 7, 1095, 1522, 4, 1437, 1437, 1437, 1437]\n"
     ]
    }
   ],
   "source": [
    "print(check_samples[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "99c0ce46-3e11-4277-959a-6336dea4918e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' respect.</s><pad>'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([2098, 4, 2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a324392-a809-4a1b-be19-72b46fe45329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3117, 3117)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_preds) , len(final_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "31ad16e1-51e2-494d-9bb6-75a44e023c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Modern humans today are always on their phone. They are always on their phone more than 5 hours a day no stop .All they do is text back and forward and just have group Chats on social media. They even do it while driving.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " sample['discourse_text'].head(1).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "abc6fdd1-8600-490d-9878-b91e9ff34a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39631, 5868, 452, 32, 460, 15, 49, 1028, 4, 252, 32, 460, 15, 49, 1028, 55, 87, 195, 722, 10, 183, 117, 912, 479, 3684, 51, 109, 16, 2788, 124, 8, 556, 8, 95, 33, 333, 732, 2923, 15, 592, 433, 4, 252, 190, 109, 24, 150, 1428, 4, 1213, 32, 103, 269, 1099, 4914, 77, 2682, 2594, 77, 24, 606, 7, 10, 1028, 4, 6323, 1402, 911, 11, 5, 315, 532, 2020, 4247, 31, 1380, 5351, 95, 142, 9, 24, 4, 520, 82, 33, 4247, 6, 51, 216, 59, 1402, 3798, 14, 51, 33, 479, 46036, 101, 622, 599, 1838, 8, 11477, 4, 407, 101, 114, 10, 1441, 3136, 409, 8, 47, 236, 7, 28, 11, 1511, 47, 64, 202, 28, 11, 1511, 30, 6016, 3424, 50, 2788, 3731, 4, 1806, 460, 33, 430, 1319, 141, 7, 8469, 19, 10, 1028, 4, 4129, 6909, 33, 1714, 528, 7, 84, 2706, 4, 19181, 16, 65, 9, 5, 169, 141, 7, 120, 198, 4, 1806, 460, 28, 15, 49, 4247, 150, 608, 24, 4, 6834, 64, 1303, 1473, 35677, 4, 1711, 18, 596, 89, 18, 10, 631, 14, 18, 373, 117, 19943, 150, 1428, 4, 280, 18, 10, 269, 505, 631, 7, 2145, 4, 993, 82, 202, 109, 24, 142, 51, 206, 85, 18, 12103, 4, 440, 948, 99, 51, 109, 51, 202, 33, 7, 28616, 24, 142, 14, 18, 5, 129, 169, 141, 222, 37, 1871, 4, 7411, 15, 5, 340, 89, 16, 1169, 41, 3213, 50, 10, 4260, 4, 85, 429, 6877, 951, 45, 546, 147, 51, 214, 164, 50, 3545, 14, 951, 1051, 4, 85, 1169, 1356, 50, 744, 4, 318, 10, 12754, 346, 161, 38, 437, 164, 7, 3549, 47, 8, 51, 216, 147, 47, 697, 53, 47, 218, 75, 216, 5, 621, 18, 1511, 50118, 50118, 6, 243, 817, 47, 36742, 8, 146, 47, 386, 7, 21905, 66, 4, 6834, 64, 253, 62, 269, 7340, 4, 4129, 6909, 32, 2051, 7, 304, 8, 24, 18, 67, 5, 275, 169, 7, 283, 81, 244, 4, 1106, 47, 213, 149, 10, 936, 8, 47, 64, 75, 465, 244, 47, 2156, 30035, 33, 10, 1028, 89, 19, 47, 4, 1648, 600, 4247, 32, 341, 818, 358, 183, 25, 251, 25, 47, 214, 1522, 24, 74, 283, 88, 304, 114, 47, 120, 88, 3605, 4, 5293, 686, 47, 109, 45, 28, 101, 42, 1028, 150, 47, 214, 11, 5, 1692, 9, 1428, 4, 133, 340, 460, 4752, 77, 82, 109, 402, 12103, 198, 14, 6890, 49, 4247, 4, 20, 25026, 169, 16, 5, 275, 169, 7, 1095, 1522, 4, 1437]\n"
     ]
    }
   ],
   "source": [
    "print(encoded_text['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d8147d-732b-47f9-8522-544bc7379e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd25609d-154e-44bb-bf5a-def9292ecce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(665, 664, 665, 664)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_preds[0]) , len(final_preds[0][1:]) , len(final_preds[1]) , len(final_preds[1][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "05af779c-e267-47ca-8d71-0b9507cd685e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(664, 420, '408A7D3D2EEC')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(check_samples_valid[0]['preds']),len(check_samples_valid[0]['offset_mapping']) , check_samples_valid[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c62ddbe3-4b32-43a6-b8a3-2a5fc05d0a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for j in range(len(check_samples_valid)):\n",
    "    tt = [id_target_map[p] for p in final_preds[j][1:]]\n",
    "    tt_score = final_scores[j][1:]\n",
    "    check_samples_valid[j][\"preds\"] = tt\n",
    "    check_samples_valid[j][\"pred_scores\"] = tt_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e471db80-42be-48bd-8a35-9e8fa9181613",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "277b809b-adea-41f3-a190-adda1b3d3b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jn(pst, start, end):\n",
    "    return \" \".join([str(x) for x in pst[start:end]])\n",
    "\n",
    "\n",
    "def link_evidence(oof):\n",
    "    thresh = 1\n",
    "    idu = oof['id'].unique()\n",
    "    idc = idu[1]\n",
    "    eoof = oof[oof['class'] == \"Evidence\"]\n",
    "    neoof = oof[oof['class'] != \"Evidence\"]\n",
    "    for thresh2 in range(26,27, 1):\n",
    "        retval = []\n",
    "        for idv in idu:\n",
    "            for c in  ['Lead', 'Position', 'Evidence', 'Claim', 'Concluding Statement',\n",
    "                   'Counterclaim', 'Rebuttal']:\n",
    "                q = eoof[(eoof['id'] == idv) & (eoof['class'] == c)]\n",
    "                if len(q) == 0:\n",
    "                    continue\n",
    "                pst = []\n",
    "                for i,r in q.iterrows():\n",
    "                    pst = pst +[-1] + [int(x) for x in r['predictionstring'].split()]\n",
    "                start = 1\n",
    "                end = 1\n",
    "                for i in range(2,len(pst)):\n",
    "                    cur = pst[i]\n",
    "                    end = i\n",
    "                    #if pst[start] == 205:\n",
    "                    #   print(cur, pst[start], cur - pst[start])\n",
    "                    if (cur == -1 and c != 'Evidence') or ((cur == -1) and ((pst[i+1] > pst[end-1] + thresh) or (pst[i+1] - pst[start] > thresh2))):\n",
    "                        retval.append((idv, c, jn(pst, start, end)))\n",
    "                        start = i + 1\n",
    "                v = (idv, c, jn(pst, start, end+1))\n",
    "                #print(v)\n",
    "                retval.append(v)\n",
    "        roof = pd.DataFrame(retval, columns = ['id', 'class', 'predictionstring']) \n",
    "        roof = roof.merge(neoof, how='outer')\n",
    "        return roof\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90fdbae7-d350-49dc-a406-3c39855b612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_thresh = {\n",
    "    \"Lead\": 0.7,\n",
    "    \"Position\": 0.55,\n",
    "    \"Evidence\": 0.65,\n",
    "    \"Claim\": 0.55,\n",
    "    \"Concluding Statement\": 0.7,\n",
    "    \"Counterclaim\": 0.5,\n",
    "    \"Rebuttal\": 0.55,\n",
    "}\n",
    "\n",
    "min_thresh = {\n",
    "    \"Lead\": 9,\n",
    "    \"Position\": 5,\n",
    "    \"Evidence\": 14,\n",
    "    \"Claim\": 3,\n",
    "    \"Concluding Statement\": 11,\n",
    "    \"Counterclaim\": 6,\n",
    "    \"Rebuttal\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "21cc92f0-b885-489f-bcad-25c5c9a75fdb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of preds is 2035  is less than 420\n",
      "the phrase preds are[('Imagine seeking advice from multiple people and choosing the best decision that suits you', 0, 89, 'Lead', [0.977799117565155, 0.887834906578064, 0.8756431341171265, 0.8663551211357117, 0.8837825059890747, 0.8859175443649292, 0.909008264541626, 0.9144768714904785, 0.8994033932685852, 0.8989217281341553, 0.9068255424499512, 0.9139044284820557, 0.9079236388206482, 0.9184635877609253]), ('', 89, 89, 'Evidence', [0.5107215046882629]), ('', 91, 89, 'Lead', [0.9472911357879639]), ('', 95, 89, 'Evidence', [0.4809758961200714]), ('that make you feel? Asking', 100, 126, 'Lead', [0.9255846738815308, 0.902938961982727, 0.9154528975486755, 0.9151118397712708, 0.7687293887138367, 0.49644407629966736, 0.5528085231781006]), ('', 127, 126, 'Position', [0.4952925145626068]), ('advice can be defined as someone who asks help from multiple people and makes the right decision', 131, 227, 'Lead', [0.6012212634086609, 0.6734776496887207, 0.7092001438140869, 0.7606051564216614, 0.7236178517341614, 0.7285948991775513, 0.7155464291572571, 0.6365951895713806, 0.639703094959259, 0.6143805384635925, 0.6200593709945679, 0.6426782011985779, 0.6691792011260986, 0.6409884095191956, 0.5848836898803711, 0.6259045600891113, 0.6713751554489136]), ('', 227, 227, 'Position', [0.5098192095756531]), ('Seeking multiple opinions can help someone make a better decision', 229, 294, 'Position', [0.8277563452720642, 0.910082221031189, 0.9073395133018494, 0.8834412097930908, 0.8951336741447449, 0.8996766805648804, 0.8999171257019043, 0.9034980535507202, 0.9088136553764343, 0.9022079110145569]), ('', 295, 294, 'O', [0.7679836750030518]), ('they can see which advice is better,', 303, 339, 'Claim', [0.8348014950752258, 0.9217634797096252, 0.945441484451294, 0.9350066184997559, 0.956838071346283, 0.9527890086174011, 0.9617458581924438, 0.7036993503570557]), ('more experienced', 340, 356, 'Claim', [0.924419641494751, 0.9685843586921692]), (', and', 356, 361, 'O', [0.571638822555542, 0.8439487814903259]), ('see the persons point of view.', 362, 392, 'Claim', [0.9267637729644775, 0.9587616920471191, 0.9714218974113464, 0.9660459756851196, 0.9647272229194641, 0.9677322506904602, 0.7883603572845459]), ('\\n\\nAsking advice from multiple people can help you\\xa0see\\xa0which advice is better.', 392, 469, 'O', [0.9975244402885437, 0.9975491166114807, 0.7058219909667969, 0.8103212118148804, 0.7796276807785034, 0.7853610515594482, 0.7785035967826843, 0.7765082120895386, 0.7737289667129517, 0.7602353096008301, 0.7598465085029602, 0.7551001310348511, 0.7669191360473633, 0.7539024949073792, 0.7754741907119751, 0.7361978888511658, 0.7583673000335693, 0.7629963755607605, 0.840787947177887]), (\"Let's say this person needs to ask their teacher what book to choose. But, they also asked their friends the same question. They can now see which decision is better for them. It also depends if the advice is decent or not because if the advice is horrible, then that decision you make can affect the outcome.\", 470, 779, 'Evidence', [0.7497983574867249, 0.8865038156509399, 0.9446765780448914, 0.9656517505645752, 0.977652907371521, 0.9812129139900208, 0.9774076342582703, 0.9862323999404907, 0.9884328246116638, 0.9915907382965088, 0.9923415184020996, 0.9919978976249695, 0.9919878244400024, 0.9921095967292786, 0.8492661714553833, 0.9916266202926636, 0.9886983036994934, 0.9917535781860352, 0.9919841885566711, 0.9925239682197571, 0.9914305806159973, 0.9927378296852112, 0.9910406470298767, 0.9910203814506531, 0.9926022887229919, 0.9874129295349121, 0.9895143508911133, 0.9861230850219727, 0.9910320043563843, 0.9876783490180969, 0.9913715124130249, 0.9918913841247559, 0.990205705165863, 0.9890359044075012, 0.9913068413734436, 0.9907459020614624, 0.9849934577941895, 0.9890525937080383, 0.9909851551055908, 0.9921669960021973, 0.9921380877494812, 0.989822506904602, 0.9913120865821838, 0.9905591011047363, 0.990685760974884, 0.9907994866371155, 0.9917424917221069, 0.9905338287353516, 0.991655707359314, 0.989427387714386, 0.9912872910499573, 0.9893448948860168, 0.9901746511459351, 0.8466713428497314, 0.9873378276824951, 0.9872065782546997, 0.9907636046409607, 0.990344226360321, 0.9893243908882141, 0.9899260997772217, 0.990656852722168, 0.9881941080093384, 0.9893669486045837, 0.9771689176559448]), ('\\n\\nAnother way asking advice from multiple people can help you is they might have more experience.', 779, 876, 'O', [0.9957393407821655, 0.997094988822937, 0.7982802391052246, 0.8607430458068848, 0.8667678833007812, 0.8683255314826965, 0.8593769669532776, 0.8555304408073425, 0.8582293391227722, 0.8431882858276367, 0.8417322635650635, 0.8316574692726135, 0.8542165160179138, 0.8125938773155212, 0.7818503379821777, 0.8024629354476929, 0.815536379814148, 0.8139901161193848, 0.8415601849555969]), (\"For instance, they need help picking a collage that suits their interest. When they ask their parents for advice, the parent might pick a different collage that could be better. But, that's because they have more experience and can see whats best for them. Grandparents especially, went through a lot when they were kids. So, if you need advice, ask adults who are more experienced in life!\", 877, 1267, 'Evidence', [0.6813843846321106, 0.7044767141342163, 0.7764503955841064, 0.8321250677108765, 0.9801644682884216, 0.987855851650238, 0.9888964891433716, 0.9890017509460449, 0.9895516037940979, 0.9882737398147583, 0.9876794815063477, 0.9873701333999634, 0.9859186410903931, 0.9895435571670532, 0.9849075078964233, 0.9853111505508423, 0.9894322156906128, 0.9906687140464783, 0.9912012815475464, 0.9915885329246521, 0.9915322661399841, 0.9912223815917969, 0.989863932132721, 0.9905385971069336, 0.9922303557395935, 0.9913114309310913, 0.9916384816169739, 0.9915547966957092, 0.9916691780090332, 0.9922657608985901, 0.9910646677017212, 0.9907322525978088, 0.991240918636322, 0.9903027415275574, 0.9900777339935303, 0.9877451062202454, 0.990715742111206, 0.9869801998138428, 0.9899665117263794, 0.9893271923065186, 0.991321861743927, 0.989546000957489, 0.9900227189064026, 0.9902752637863159, 0.9902066588401794, 0.9901846647262573, 0.9905440807342529, 0.9909785985946655, 0.9905601143836975, 0.9904758930206299, 0.9911791682243347, 0.9901869297027588, 0.9882180094718933, 0.9916850328445435, 0.9914997220039368, 0.991158664226532, 0.9905706644058228, 0.991650402545929, 0.9915614724159241, 0.9909166693687439, 0.9908314347267151, 0.9916241765022278, 0.9906409382820129, 0.9914786219596863, 0.992290198802948, 0.9859631657600403, 0.9892611503601074, 0.9846327304840088, 0.990474283695221, 0.9892441034317017, 0.988774299621582, 0.9891364574432373, 0.9885877370834351, 0.9899221062660217, 0.9891742467880249, 0.9881690740585327, 0.9864575266838074, 0.9855955839157104, 0.9855637550354004, 0.9881808757781982, 0.9878606200218201, 0.9826838374137878]), ('\\n\\nLastly, asking advice from multiple people can help you see the persons point of view.', 1267, 1355, 'O', [0.9669727087020874, 0.9964847564697266, 0.8658861517906189, 0.8967678546905518, 0.7620225548744202, 0.8348863124847412, 0.8418850302696228, 0.830959677696228, 0.8376889824867249, 0.840079665184021, 0.8394711017608643, 0.8239148259162903, 0.834886908531189, 0.8364875316619873, 0.8319611549377441, 0.8391633033752441, 0.8395254611968994, 0.8309634327888489, 0.7722377181053162]), (\"For example, they can see what other people have to say and can help you make that better decision. Let's say they need help painting their house but dont know what paint color to choose. But, when they ask someone for advice, they can see what the other person has to say and make the right decision based on that advice.\", 1356, 1678, 'Evidence', [0.6386589407920837, 0.7527222633361816, 0.7927741408348083, 0.7807705998420715, 0.9636560678482056, 0.9796145558357239, 0.9800674319267273, 0.9847092628479004, 0.9870561361312866, 0.9865662455558777, 0.9853695631027222, 0.9845336675643921, 0.9853472709655762, 0.9868038296699524, 0.9873710870742798, 0.9859980344772339, 0.9839606285095215, 0.9855329394340515, 0.9863669276237488, 0.987082839012146, 0.9865037202835083, 0.9820396304130554, 0.9880326986312866, 0.9897408485412598, 0.9906800389289856, 0.9911611080169678, 0.9925858378410339, 0.9925976991653442, 0.9918667674064636, 0.9923465251922607, 0.9920809864997864, 0.992925763130188, 0.9924582242965698, 0.9927380681037903, 0.9929459691047668, 0.9926692247390747, 0.9920406937599182, 0.9925016164779663, 0.9886335134506226, 0.9920111298561096, 0.9890542030334473, 0.9921784400939941, 0.9906822443008423, 0.9918798804283142, 0.9913316965103149, 0.9923612475395203, 0.9937618374824524, 0.9922274351119995, 0.9932663440704346, 0.9937769174575806, 0.9939433932304382, 0.9936344623565674, 0.994002640247345, 0.9941689968109131, 0.9940810799598694, 0.9941945672035217, 0.9938380122184753, 0.9935512542724609, 0.9935874938964844, 0.9935129284858704, 0.9932841062545776, 0.9933406710624695, 0.9932237863540649, 0.9937164187431335, 0.9931163191795349, 0.9924905896186829, 0.993518054485321, 0.9867115020751953]), ('\\n\\n', 1678, 1680, 'O', [0.9956817626953125, 0.9966505169868469]), ('In conclusion,', 1680, 1694, 'Concluding Statement', [0.5152314305305481, 0.6056836247444153, 0.5735740661621094]), ('asking advice can help someone make a better decision because they can see the persons point of view, more experienced, and they can see which advice is better. Asking for advice is important because they can see which\\xa0advice is better and can see other peoples perspective. This affects you because its on you to ask for advice and make the right decision!', 1695, 2052, 'Concluding Statement', [0.6115409731864929, 0.9299060702323914, 0.9387287497520447, 0.9423355460166931, 0.9451491832733154, 0.9475824236869812, 0.9398485422134399, 0.9414833188056946, 0.9508921504020691, 0.9532623887062073, 0.9645540714263916, 0.9686448574066162, 0.9704698920249939, 0.9697794914245605, 0.9732779860496521, 0.9754528999328613, 0.9758396148681641, 0.9741970300674438, 0.976334810256958, 0.9733586311340332, 0.9731441736221313, 0.9757798910140991, 0.9731143712997437, 0.9688572287559509, 0.9717885255813599, 0.9693158864974976, 0.9677864909172058, 0.9695144891738892, 0.9722518920898438, 0.9717605113983154, 0.9436626434326172, 0.8380259871482849, 0.9669592976570129, 0.965543270111084, 0.967677116394043, 0.9695055484771729, 0.9674420952796936, 0.9711252450942993, 0.9696462154388428, 0.9729530811309814, 0.9749696850776672, 0.974585235118866, 0.9658565521240234, 0.9688666462898254, 0.9724871516227722, 0.9776142835617065, 0.9766649007797241, 0.9767059683799744, 0.9733704924583435, 0.9759269952774048, 0.9752132892608643, 0.977264404296875, 0.9758475422859192, 0.4884604513645172, 0.959187388420105, 0.958844780921936, 0.9644954800605774, 0.9621257781982422, 0.9638756513595581, 0.9600340723991394, 0.965760350227356, 0.9686024785041809, 0.9677708745002747, 0.9686578512191772, 0.9710700511932373, 0.9711615443229675, 0.969770610332489, 0.9716905951499939, 0.9701569676399231, 0.972426176071167, 0.9619961977005005])]\n",
      "\n",
      "//////////// \n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      " 16 17 18 19 20 \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      " 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      " 39 40 41 42 43 44 45 46 47 48 \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      " 50 51 52 53 54 55 56 \n",
      " //////////////////////\n",
      "//////////// \n",
      " 57 58 \n",
      " //////////////////////\n",
      "//////////// \n",
      " 59 60 \n",
      " //////////////////////\n",
      "//////////// \n",
      " 60 61 62 63 64 65 \n",
      " //////////////////////\n",
      "//////////// \n",
      " 66 67 68 69 70 71 72 73 74 75 76 77 78 \n",
      " //////////////////////\n",
      "//////////// \n",
      " 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 \n",
      " //////////////////////\n",
      "//////////// \n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 \n",
      " //////////////////////\n",
      "//////////// \n",
      " 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 \n",
      " //////////////////////\n",
      "//////////// \n",
      " 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 \n",
      " //////////////////////\n",
      "//////////// \n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      " 295 296 \n",
      " //////////////////////\n",
      "//////////// \n",
      " 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 \n",
      " //////////////////////\n",
      "The length of preds is 2035  is less than 663\n",
      "the phrase preds are[(\"There has been at least one point in everyone's life where you have asked or been asked for advice on a certain topic or subject. Everyone needs help with something, and it is a genetic trait to ask someone else for advice. However, a lot of people can be dishonest, and in this day and age, that number only goes up. Because of this, sometimes, asking just one person is not enough. Now a\", 0, 389, 'Lead', [0.9412733316421509, 0.8866087794303894, 0.9085368514060974, 0.9198724031448364, 0.9184489250183105, 0.9278445243835449, 0.9223748445510864, 0.9094030857086182, 0.9221537709236145, 0.9000076651573181, 0.9102913737297058, 0.91336590051651, 0.9041114449501038, 0.8916257619857788, 0.8584948182106018, 0.8978290557861328, 0.8908290266990662, 0.882956326007843, 0.8653753995895386, 0.8866648077964783, 0.8899120092391968, 0.8964917659759521, 0.9004504680633545, 0.8963508605957031, 0.9004403948783875, 0.9023184180259705, 0.8567585945129395, 0.9100279808044434, 0.8598164319992065, 0.8716307878494263, 0.8773843050003052, 0.9017992615699768, 0.8915421962738037, 0.896313488483429, 0.8855197429656982, 0.8686202764511108, 0.8787588477134705, 0.855254590511322, 0.8547882437705994, 0.8538529872894287, 0.8615753054618835, 0.9006330370903015, 0.8947198390960693, 0.8666032552719116, 0.866703450679779, 0.4142475724220276, 0.8217222094535828, 0.7186981439590454, 0.7664589881896973, 0.7591661810874939, 0.7492251992225647, 0.7814283967018127, 0.7570644617080688, 0.7781171798706055, 0.7562310695648193, 0.8043779134750366, 0.8241499662399292, 0.7728042006492615, 0.7589709758758545, 0.8024413585662842, 0.7688807249069214, 0.7918450236320496, 0.780630886554718, 0.8186876177787781, 0.781583845615387, 0.8090822696685791, 0.8170549869537354, 0.8232993483543396, 0.7298293709754944, 0.8162975311279297, 0.6849310994148254, 0.6545220017433167, 0.6427561044692993, 0.6786127686500549, 0.6254543662071228, 0.6196392774581909, 0.6876495480537415, 0.6873053908348083, 0.6901468634605408, 0.6916717886924744, 0.6779426336288452, 0.6903893947601318, 0.596298336982727, 0.5621318221092224, 0.4871957302093506]), ('', 390, 389, 'Position', [0.4895438551902771]), (', a person looking for help will most likely confront', 394, 447, 'Lead', [0.5163643956184387, 0.5210712552070618, 0.5719594359397888, 0.5822652578353882, 0.5562505125999451, 0.5817738175392151, 0.5647587180137634, 0.5286622643470764, 0.5358521342277527, 0.489879310131073]), ('', 448, 447, 'Position', [0.4901348948478699]), ('people for advice to prevent problems with misinformation', 457, 514, 'Lead', [0.5341761708259583, 0.4823801815509796, 0.5061464905738831, 0.5654593706130981, 0.6072630286216736, 0.6581918001174927, 0.6719540357589722, 0.6097555160522461]), ('', 514, 514, 'Position', [0.6099245548248291]), ('The problem, while gigantic in scale now, can be rooted down to three different source problems I call \"The Three Probl-Ms of Advice-giving\". These three problems are:', 516, 683, 'Position', [0.4766848087310791, 0.8127396106719971, 0.6901189088821411, 0.8171529769897461, 0.8315328359603882, 0.8349881172180176, 0.8402465581893921, 0.851555347442627, 0.716970682144165, 0.828809916973114, 0.8338984251022339, 0.8508819937705994, 0.8411839604377747, 0.8358020782470703, 0.8605634570121765, 0.8491814136505127, 0.826472818851471, 0.810066282749176, 0.84663325548172, 0.8417561054229736, 0.8418734669685364, 0.835616946220398, 0.8178253769874573, 0.7697787880897522, 0.7806470990180969, 0.7972735166549683, 0.787979781627655, 0.7954699993133545, 0.8381995558738708, 0.8178589940071106, 0.8527156114578247, 0.7809857130050659, 0.300153911113739, 0.6070690155029297, 0.5561405420303345, 0.5930352210998535, 0.3934520483016968]), ('mistake,', 684, 692, 'Claim', [0.523624062538147, 0.5417040586471558]), ('', 693, 692, 'Claim', [0.4221213459968567]), ('', 709, 692, 'O', [0.3770480751991272]), ('', 711, 692, 'Claim', [0.34693974256515503]), ('misdeed.', 715, 723, 'Claim', [0.51405930519104, 0.5742781162261963, 0.5543914437294006, 0.47792917490005493]), ('\\n\\nWhile mistakes and misunderstanding might have similar definitions', 723, 791, 'O', [0.9948316812515259, 0.995822548866272, 0.6538519263267517, 0.7729761600494385, 0.7791597247123718, 0.7537620067596436, 0.7759534120559692, 0.754233181476593, 0.7864328026771545, 0.7783827781677246]), ('', 791, 791, 'Evidence', [0.559853732585907]), ('in this context they are two completely different things. First of all, mistakes are when the advice-giver confuses two similar things and gives the wrong advice.', 793, 955, 'O', [0.7675859332084656, 0.8065459132194519, 0.7835601568222046, 0.7472519874572754, 0.7411032915115356, 0.7678080201148987, 0.7536078691482544, 0.793743908405304, 0.7925160527229309, 0.7792513966560364, 0.8282681703567505, 0.7957848906517029, 0.7796870470046997, 0.766426146030426, 0.6555956602096558, 0.6318562626838684, 0.5777752995491028, 0.528171181678772, 0.4665695130825043, 0.49661993980407715, 0.5186492800712585, 0.5203427076339722, 0.44444534182548523, 0.4680940806865692, 0.4665737450122833, 0.4778316020965576, 0.49055957794189453, 0.5214361548423767, 0.48707741498947144, 0.5290899276733398, 0.5220121145248413, 0.4612933099269867, 0.52516108751297]), ('A good example of this is when you are talking about a level on a video game you are having trouble with, and your friend, thinking about a similar level, gives you incorrect advice. Now you are going to have a harder time beating the level because your friend told you about a different level. However, this could have all been avoided if you had asked three or four more people for advice on the level. The more similar iterations people give you, the better the chance that the information your getting is true.', 956, 1470, 'Evidence', [0.701586127281189, 0.9411492347717285, 0.937260627746582, 0.9517026543617249, 0.8785828351974487, 0.941909909248352, 0.9689419269561768, 0.9807202219963074, 0.987572431564331, 0.9903311729431152, 0.9922522902488708, 0.9905400276184082, 0.9916794896125793, 0.993357241153717, 0.9922244548797607, 0.9927546381950378, 0.9922352433204651, 0.9925440549850464, 0.9931508302688599, 0.9930474162101746, 0.992870032787323, 0.992841362953186, 0.9922741055488586, 0.9917353391647339, 0.9928598999977112, 0.9921900629997253, 0.9928025603294373, 0.9928796887397766, 0.9929481744766235, 0.9927240014076233, 0.9930404424667358, 0.9930042624473572, 0.993601381778717, 0.9923736453056335, 0.9923658967018127, 0.9922878742218018, 0.992211103439331, 0.9921296238899231, 0.9870193004608154, 0.9930035471916199, 0.9922260046005249, 0.9921715259552002, 0.9921640157699585, 0.9925689101219177, 0.9931315779685974, 0.9930511713027954, 0.9923690557479858, 0.9925324320793152, 0.9931856393814087, 0.9927828311920166, 0.9926580786705017, 0.9929169416427612, 0.9922593235969543, 0.9916763305664062, 0.9931312203407288, 0.9921476244926453, 0.9927151799201965, 0.9927934408187866, 0.9923338890075684, 0.9754502773284912, 0.9398963451385498, 0.9378538131713867, 0.9472301602363586, 0.9444509744644165, 0.943128764629364, 0.9426767826080322, 0.9446508288383484, 0.9468012452125549, 0.9448691606521606, 0.9504691958427429, 0.950825572013855, 0.9436030983924866, 0.9484789967536926, 0.9553391933441162, 0.9458181858062744, 0.9477858543395996, 0.9514657258987427, 0.9494986534118652, 0.9513540267944336, 0.948050856590271, 0.9529637098312378, 0.9548516869544983, 0.9431560039520264, 0.8372170329093933, 0.8935109972953796, 0.9040560126304626, 0.9111651182174683, 0.9140599370002747, 0.8997118473052979, 0.855552613735199, 0.8687037229537964, 0.8963369727134705, 0.8850218653678894, 0.8771544694900513, 0.8740792870521545, 0.8676445484161377, 0.8947514295578003, 0.8968979716300964, 0.8761259317398071, 0.8909451961517334, 0.8950496912002563, 0.8781010508537292, 0.8397250175476074]), ('\\n\\n', 1470, 1472, 'O', [0.9920159578323364, 0.9928939938545227]), ('', 1472, 1472, 'Claim', [0.5261111259460449]), ('', 1475, 1472, 'O', [0.490217387676239]), ('', 1480, 1472, 'Claim', [0.42321744561195374]), ('ings are harder to', 1485, 1503, 'O', [0.505680501461029, 0.4860905110836029, 0.4725726544857025, 0.4310508370399475]), ('', 1504, 1503, 'Claim', [0.4525931775569916]), ('', 1510, 1503, 'O', [0.47405001521110535]), ('these problems will most likely arise from the environment or conditions you are in.', 1518, 1602, 'Claim', [0.4676589369773865, 0.4766385555267334, 0.46949321031570435, 0.5222069621086121, 0.49236154556274414, 0.506378173828125, 0.5342624187469482, 0.5471020936965942, 0.5343849658966064, 0.5380868911743164, 0.5295952558517456, 0.5072172284126282, 0.4976920783519745, 0.5251373648643494, 0.3566921651363373]), ('an example of this is you are making a phone call, and the connection is pretty terrible. It is hard to understand what uncle Generic_Name is trying to tell you through all the static. There is really no way to fix the connection nor is there a way to prevent all of the static. The best thing to do in a situation like that is to just get more advice from more people. Uncle Generic_Name is only one person any way.', 1603, 2019, 'Evidence', [0.5944118499755859, 0.9675268530845642, 0.9858468174934387, 0.9845238327980042, 0.9895944595336914, 0.992182195186615, 0.9941960573196411, 0.9940664768218994, 0.9937471151351929, 0.9935510158538818, 0.9934874773025513, 0.9935465455055237, 0.9937527775764465, 0.9937506318092346, 0.9934942126274109, 0.9939853549003601, 0.9940359592437744, 0.9933376312255859, 0.8912352323532104, 0.9626622200012207, 0.9932824373245239, 0.9925436973571777, 0.9925907850265503, 0.9918334484100342, 0.9932864308357239, 0.9919772744178772, 0.9915137887001038, 0.9927753210067749, 0.9915885329246521, 0.9933410286903381, 0.992655873298645, 0.9927883744239807, 0.9921676516532898, 0.9922692179679871, 0.9942985773086548, 0.9936244487762451, 0.9935193657875061, 0.9929704070091248, 0.8980351090431213, 0.9760878086090088, 0.9922112226486206, 0.9915404915809631, 0.9920685291290283, 0.9899287819862366, 0.9918357133865356, 0.9918877482414246, 0.9923849105834961, 0.9911224842071533, 0.9911928772926331, 0.9917190074920654, 0.9918935298919678, 0.9921267032623291, 0.9910138249397278, 0.9912281036376953, 0.9900552034378052, 0.9908740520477295, 0.9893378019332886, 0.9906595945358276, 0.987575352191925, 0.9479197263717651, 0.8895354270935059, 0.8405881524085999, 0.8760803937911987, 0.9024180173873901, 0.8858641982078552, 0.9088014364242554, 0.9262555241584778, 0.9273936152458191, 0.933800458908081, 0.9420217871665955, 0.893821120262146, 0.9132696986198425, 0.9034401178359985, 0.9091684222221375, 0.8928860425949097, 0.8919879794120789, 0.8936722278594971, 0.8898053765296936, 0.8960952758789062, 0.9337801337242126, 0.9389449954032898, 0.9278150796890259, 0.9278742074966431, 0.9302945137023926, 0.9318457841873169, 0.9251430630683899, 0.9250091314315796, 0.9278820753097534, 0.9344819188117981, 0.9392831325531006, 0.9179113507270813]), ('\\n\\n', 2019, 2021, 'O', [0.9911670088768005, 0.9933652281761169]), ('', 2021, 2021, 'Claim', [0.5602906346321106]), ('', 2028, 2021, 'O', [0.5083038210868835]), ('misdeeds are when the advice-giver is purposely tampering with information to mess with you', 2030, 2121, 'Claim', [0.3610749840736389, 0.5706706643104553, 0.5544106960296631, 0.5807077288627625, 0.6894567012786865, 0.6688147783279419, 0.6870255470275879, 0.658950924873352, 0.6698987483978271, 0.6654291152954102, 0.690689206123352, 0.7633285522460938, 0.7357813119888306, 0.7344602346420288, 0.7048172354698181, 0.7085105180740356, 0.7277793884277344, 0.7272183299064636, 0.7007954120635986]), ('', 2121, 2121, 'Evidence', [0.8314111828804016]), ('An example of this is when you ask Generic_Name how to play the accordion better. Generic_Name, thinking that it would be funny, tells you that you need to aggressively compress and decompress the accordion repeatedly. you accidentally break the accordion, and Now you have a broken accordion, some damaged pride, and still no idea how to play the accordion. However, this could have all been avoided if you had asked all of the accordion players from your music class for advice on playing the accordion. Also you should not have trusted Generic_Name advice in the first place.', 2123, 2701, 'Evidence', [0.8965501189231873, 0.932694137096405, 0.9473921656608582, 0.921326756477356, 0.9537104368209839, 0.9567743539810181, 0.9819475412368774, 0.9861544966697693, 0.9807387590408325, 0.9807837605476379, 0.9807631969451904, 0.9877556562423706, 0.9867477416992188, 0.9839178323745728, 0.9852316379547119, 0.9849075078964233, 0.9821814894676208, 0.9834659099578857, 0.906596302986145, 0.8655307292938232, 0.9897447228431702, 0.989595353603363, 0.9918631315231323, 0.9916312098503113, 0.991844117641449, 0.992155909538269, 0.9925609230995178, 0.9911749362945557, 0.9895355105400085, 0.9917422533035278, 0.9916846752166748, 0.9918463826179504, 0.9920713305473328, 0.9932072758674622, 0.9922508597373962, 0.9924754500389099, 0.9919167160987854, 0.9912978410720825, 0.9919053316116333, 0.991824209690094, 0.9911549091339111, 0.9922938346862793, 0.9924854636192322, 0.9916748404502869, 0.9917564392089844, 0.9916731715202332, 0.9891022443771362, 0.9910355806350708, 0.9917775392532349, 0.9922728538513184, 0.9919869899749756, 0.9916560649871826, 0.9902192950248718, 0.9917539358139038, 0.991738498210907, 0.9898265600204468, 0.9900796413421631, 0.9913984537124634, 0.9909001588821411, 0.9911518692970276, 0.9908696413040161, 0.990594744682312, 0.9913103580474854, 0.9905098080635071, 0.9894927740097046, 0.9892934560775757, 0.9914224743843079, 0.9906891584396362, 0.9907546639442444, 0.9891265034675598, 0.9897536039352417, 0.9807819128036499, 0.9876130819320679, 0.9898468852043152, 0.9886704683303833, 0.9871389269828796, 0.9658311605453491, 0.9353930950164795, 0.9390489459037781, 0.9403348565101624, 0.9272428154945374, 0.9270485043525696, 0.9285624623298645, 0.9303072094917297, 0.928493082523346, 0.9333458542823792, 0.946332573890686, 0.9381087422370911, 0.9324753284454346, 0.9287258982658386, 0.9346834421157837, 0.9371539354324341, 0.9465643167495728, 0.946190595626831, 0.9425959587097168, 0.9451037645339966, 0.9586898684501648, 0.9487876296043396, 0.9456673264503479, 0.9372270703315735, 0.9405829906463623, 0.9369744062423706, 0.9420568943023682, 0.9365937113761902, 0.9491143822669983, 0.9491718411445618, 0.9441872239112854, 0.9437656402587891, 0.9520680904388428, 0.9403406977653503, 0.9430156350135803, 0.9363982677459717, 0.9375554919242859, 0.9424079656600952, 0.9468573331832886, 0.9437997341156006, 0.9498646259307861, 0.9478150606155396, 0.9447594285011292, 0.9385283589363098, 0.9434476494789124, 0.9254501461982727]), ('\\n\\n', 2701, 2703, 'O', [0.9699060916900635, 0.9870384931564331]), ('Now, I know what you probably saying \"But what if everyone you ask gives you incorrect advice?\" and to that I say: what are the odds that seven of your close friends do not no what you are talking about? The odds are in your favor; and the on the off chance that the odds are not in you favor? Just expand your focus group, ask new people, be confident. You just need to ask more people. Now go ask those questions, and get some answers.', 2703, 3140, 'Concluding Statement', [0.9066633582115173, 0.7971606850624084, 0.7350893616676331, 0.9058061242103577, 0.8806551098823547, 0.8796146512031555, 0.8895183205604553, 0.8926807641983032, 0.8837403059005737, 0.7786197662353516, 0.9061704874038696, 0.9135332703590393, 0.9085702300071716, 0.9005650877952576, 0.9101646542549133, 0.9054309129714966, 0.899266242980957, 0.9003345370292664, 0.9041975736618042, 0.9030522704124451, 0.9102032780647278, 0.9125668406486511, 0.9067301750183105, 0.8999367952346802, 0.9094972610473633, 0.9115940928459167, 0.9239436388015747, 0.9075563549995422, 0.9034168124198914, 0.9060289859771729, 0.9037502408027649, 0.8993608951568604, 0.9065805673599243, 0.9064951539039612, 0.9062122106552124, 0.9119992852210999, 0.9073625206947327, 0.9059484601020813, 0.8919585347175598, 0.9086492657661438, 0.9053714871406555, 0.9079182147979736, 0.907757580280304, 0.9093549251556396, 0.9087404012680054, 0.9221135377883911, 0.9167400598526001, 0.9125282764434814, 0.9069821238517761, 0.9062293171882629, 0.9076384902000427, 0.9118795394897461, 0.9148666262626648, 0.9186987280845642, 0.9173204898834229, 0.910312294960022, 0.9163224697113037, 0.9208131432533264, 0.914313018321991, 0.9126059412956238, 0.9180326461791992, 0.9139479994773865, 0.9118579626083374, 0.9118922352790833, 0.9108302593231201, 0.912822425365448, 0.9172724485397339, 0.9247238039970398, 0.9197896718978882, 0.9158912897109985, 0.9199617505073547, 0.9190751910209656, 0.9184136986732483, 0.9219486713409424, 0.9167529940605164, 0.9205411672592163, 0.9193811416625977, 0.9222944378852844, 0.9155225157737732, 0.9110580682754517, 0.9235509037971497, 0.9165634512901306, 0.9193643927574158, 0.9186864495277405, 0.9193429350852966, 0.9164717793464661, 0.9224178194999695, 0.9141707420349121, 0.9132133722305298, 0.9107232093811035, 0.9063997268676758, 0.9168312549591064, 0.9148479104042053, 0.9074310064315796, 0.9048247933387756, 0.9083009362220764, 0.9096695780754089, 0.9152523279190063, 0.904331624507904])]\n",
      "\n",
      "//////////// \n",
      " 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      " 75 76 77 78 79 80 81 82 83 84 \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      " 85 86 87 88 89 90 91 92 \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      " 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 \n",
      " //////////////////////\n",
      "//////////// \n",
      " 120 \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      " 123 \n",
      " //////////////////////\n",
      "//////////// \n",
      " 124 125 126 127 128 129 130 131 \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      " 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 \n",
      " //////////////////////\n",
      "//////////// \n",
      " 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      " 253 254 255 256 \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      " 258 259 260 261 262 263 264 265 266 267 268 269 270 271 \n",
      " //////////////////////\n",
      "//////////// \n",
      " 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      " 354 355 356 357 358 359 360 361 362 363 364 365 366 367 \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      " 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 \n",
      " //////////////////////\n",
      "//////////// \n",
      "  \n",
      " //////////////////////\n",
      "//////////// \n",
      " 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 \n",
      " //////////////////////\n"
     ]
    }
   ],
   "source": [
    "\n",
    "submission = []\n",
    "for sample_idx, sample in enumerate(check_samples_valid):\n",
    "    \n",
    "    preds = sample[\"preds\"]\n",
    "    offset_mapping = sample[\"offset_mapping\"]\n",
    "    sample_id = sample[\"id\"]\n",
    "    sample_text = sample[\"text\"]\n",
    "    sample_input_ids = sample[\"input_ids\"]\n",
    "    sample_pred_scores = sample[\"pred_scores\"]\n",
    "    sample_preds = []\n",
    "\n",
    "    print(f\"The length of preds is {len(preds)}  is less than {len(offset_mapping)}\")\n",
    "    if len(preds) < len(offset_mapping):\n",
    "        \n",
    "        preds = preds + [\"O\"] * (len(offset_mapping) - len(preds))\n",
    "        sample_pred_scores = sample_pred_scores + [0] * (len(offset_mapping) - len(sample_pred_scores))\n",
    "    \n",
    "    idx = 0\n",
    "    phrase_preds = []\n",
    "    while idx < len(offset_mapping):\n",
    "        start, _ = offset_mapping[idx]\n",
    "        if preds[idx] != \"O\":\n",
    "            label = preds[idx][2:]\n",
    "        else:\n",
    "            label = \"O\"\n",
    "        phrase_scores = []\n",
    "#         print(\"aaaaaaaaaaaaaa\")\n",
    "#         print(sample_pred_scores[idx])\n",
    "#         print(\"aaaaaaaaaaaaaa\")\n",
    "        phrase_scores.append(sample_pred_scores[idx])\n",
    "        idx += 1\n",
    "        while idx < len(offset_mapping):\n",
    "            if label == \"O\":\n",
    "                matching_label = \"O\"\n",
    "            else:\n",
    "                matching_label = f\"I-{label}\"\n",
    "            if preds[idx] == matching_label:\n",
    "                _, end = offset_mapping[idx]\n",
    "#                 print(\"bbbbbbbbbbbb\")\n",
    "#                 print(sample_pred_scores[idx])\n",
    "#                 print(\"bbbbbbbbbbbbbb\")\n",
    "                phrase_scores.append(sample_pred_scores[idx])\n",
    "                idx += 1\n",
    "            else:\n",
    "                break\n",
    "        if \"end\" in locals():\n",
    "            phrase = sample_text[start:end]\n",
    "            phrase_preds.append((phrase, start, end, label, phrase_scores))\n",
    "            \n",
    "\n",
    "    temp_df = []\n",
    "    print(f\"the phrase preds are{phrase_preds}\\n\")\n",
    "    for phrase_idx, (phrase, start, end, label, phrase_scores) in enumerate(phrase_preds):\n",
    "        word_start = len(sample_text[:start].split())\n",
    "        word_end = word_start + len(sample_text[start:end].split())\n",
    "        word_end = min(word_end, len(sample_text.split()))\n",
    "        ps = \" \".join([str(x) for x in range(word_start, word_end)])\n",
    "        print(\"////////////\",'\\n',ps,'\\n',\"//////////////////////\")\n",
    "        \n",
    "        if label != \"O\":\n",
    "            if sum(phrase_scores) / len(phrase_scores) >= proba_thresh[label]:\n",
    "                if len(ps.split()) >= min_thresh[label]:\n",
    "                    temp_df.append((sample_id, label, ps))\n",
    "#         else:\n",
    "#             temp_df.append((sample_id, label, ps))\n",
    "    \n",
    "    temp_df = pd.DataFrame(temp_df, columns=[\"id\", \"class\", \"predictionstring\"])\n",
    "    submission.append(temp_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6a447f08-73e6-4a12-9f50-c31cf8d572ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat(submission).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c39e492b-5a63-4137-b342-b655a7305102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>Position</td>\n",
       "      <td>39 40 41 42 43 44 45 46 47 48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>Claim</td>\n",
       "      <td>50 51 52 53 54 55 56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>Claim</td>\n",
       "      <td>60 61 62 63 64 65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>152 153 154 155 156 157 158 159 160 161 162 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>234 235 236 237 238 239 240 241 242 243 244 24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>297 298 299 300 301 302 303 304 305 306 307 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>Position</td>\n",
       "      <td>93 94 95 96 97 98 99 100 101 102 103 104 105 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>158 159 160 161 162 163 164 165 166 167 168 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>272 273 274 275 276 277 278 279 280 281 282 28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>Claim</td>\n",
       "      <td>354 355 356 357 358 359 360 361 362 363 364 36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>368 369 370 371 372 373 374 375 376 377 378 37...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>465 466 467 468 469 470 471 472 473 474 475 47...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                 class  \\\n",
       "0   408A7D3D2EEC                  Lead   \n",
       "1   408A7D3D2EEC              Position   \n",
       "2   408A7D3D2EEC                 Claim   \n",
       "3   408A7D3D2EEC                 Claim   \n",
       "4   408A7D3D2EEC              Evidence   \n",
       "5   408A7D3D2EEC              Evidence   \n",
       "6   408A7D3D2EEC              Evidence   \n",
       "7   408A7D3D2EEC  Concluding Statement   \n",
       "8   AFEC37C2D43F                  Lead   \n",
       "9   AFEC37C2D43F              Position   \n",
       "10  AFEC37C2D43F              Evidence   \n",
       "11  AFEC37C2D43F              Evidence   \n",
       "12  AFEC37C2D43F                 Claim   \n",
       "13  AFEC37C2D43F              Evidence   \n",
       "14  AFEC37C2D43F  Concluding Statement   \n",
       "\n",
       "                                     predictionstring  \n",
       "0                     0 1 2 3 4 5 6 7 8 9 10 11 12 13  \n",
       "1                       39 40 41 42 43 44 45 46 47 48  \n",
       "2                                50 51 52 53 54 55 56  \n",
       "3                                   60 61 62 63 64 65  \n",
       "4   79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 9...  \n",
       "5   152 153 154 155 156 157 158 159 160 161 162 16...  \n",
       "6   234 235 236 237 238 239 240 241 242 243 244 24...  \n",
       "7   297 298 299 300 301 302 303 304 305 306 307 30...  \n",
       "8   0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...  \n",
       "9   93 94 95 96 97 98 99 100 101 102 103 104 105 1...  \n",
       "10  158 159 160 161 162 163 164 165 166 167 168 16...  \n",
       "11  272 273 274 275 276 277 278 279 280 281 282 28...  \n",
       "12  354 355 356 357 358 359 360 361 362 363 364 36...  \n",
       "13  368 369 370 371 372 373 374 375 376 377 378 37...  \n",
       "14  465 466 467 468 469 470 471 472 473 474 475 47...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "02738a4a-7698-4f7d-99b8-3e2513140682",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = link_evidence(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c57f5ff-c38e-45ad-a91c-7316f9b39621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "33ff1a0a-7d1e-46fc-a532-261047bab9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>152 153 154 155 156 157 158 159 160 161 162 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>234 235 236 237 238 239 240 241 242 243 244 24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>Position</td>\n",
       "      <td>39 40 41 42 43 44 45 46 47 48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>Claim</td>\n",
       "      <td>50 51 52 53 54 55 56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>Claim</td>\n",
       "      <td>60 61 62 63 64 65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>297 298 299 300 301 302 303 304 305 306 307 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>158 159 160 161 162 163 164 165 166 167 168 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>272 273 274 275 276 277 278 279 280 281 282 28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>368 369 370 371 372 373 374 375 376 377 378 37...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>Position</td>\n",
       "      <td>93 94 95 96 97 98 99 100 101 102 103 104 105 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>Claim</td>\n",
       "      <td>354 355 356 357 358 359 360 361 362 363 364 36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>465 466 467 468 469 470 471 472 473 474 475 47...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                 class  \\\n",
       "0   408A7D3D2EEC              Evidence   \n",
       "1   408A7D3D2EEC              Evidence   \n",
       "2   408A7D3D2EEC              Evidence   \n",
       "6   408A7D3D2EEC                  Lead   \n",
       "7   408A7D3D2EEC              Position   \n",
       "8   408A7D3D2EEC                 Claim   \n",
       "9   408A7D3D2EEC                 Claim   \n",
       "10  408A7D3D2EEC  Concluding Statement   \n",
       "3   AFEC37C2D43F              Evidence   \n",
       "4   AFEC37C2D43F              Evidence   \n",
       "5   AFEC37C2D43F              Evidence   \n",
       "11  AFEC37C2D43F                  Lead   \n",
       "12  AFEC37C2D43F              Position   \n",
       "13  AFEC37C2D43F                 Claim   \n",
       "14  AFEC37C2D43F  Concluding Statement   \n",
       "\n",
       "                                     predictionstring  \n",
       "0   79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 9...  \n",
       "1   152 153 154 155 156 157 158 159 160 161 162 16...  \n",
       "2   234 235 236 237 238 239 240 241 242 243 244 24...  \n",
       "6                     0 1 2 3 4 5 6 7 8 9 10 11 12 13  \n",
       "7                       39 40 41 42 43 44 45 46 47 48  \n",
       "8                                50 51 52 53 54 55 56  \n",
       "9                                   60 61 62 63 64 65  \n",
       "10  297 298 299 300 301 302 303 304 305 306 307 30...  \n",
       "3   158 159 160 161 162 163 164 165 166 167 168 16...  \n",
       "4   272 273 274 275 276 277 278 279 280 281 282 28...  \n",
       "5   368 369 370 371 372 373 374 375 376 377 378 37...  \n",
       "11  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...  \n",
       "12  93 94 95 96 97 98 99 100 101 102 103 104 105 1...  \n",
       "13  354 355 356 357 358 359 360 361 362 363 364 36...  \n",
       "14  465 466 467 468 469 470 471 472 473 474 475 47...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.sort_values(by='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f6db47e4-23ce-4a5b-a54b-8849cc4faf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_valid = train[train.id.isin(['408A7D3D2EEC', 'AFEC37C2D43F'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a6cf8b3c-7545-41a5-8c20-724efba66c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>length_of_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144261</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>Imagine seeking advice from multiple people an...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144262</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>229.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>Seeking multiple opinions can help someone mak...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>39 40 41 42 43 44 45 46 47 48</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144263</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>303.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>they can see which advice is better</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>50 51 52 53 54 55 56</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144264</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>340.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>more experienced</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 2</td>\n",
       "      <td>57 58</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144265</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>362.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>see the persons point of view.</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 3</td>\n",
       "      <td>60 61 62 63 64 65</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144266</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>470.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>Let's say this person needs to ask their teach...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 9...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144267</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>876.0</td>\n",
       "      <td>1267.0</td>\n",
       "      <td>For instance, they need help picking a collag...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>152 153 154 155 156 157 158 159 160 161 162 16...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144268</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>1356.0</td>\n",
       "      <td>1679.0</td>\n",
       "      <td>For example, they can see what other people ha...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 3</td>\n",
       "      <td>234 235 236 237 238 239 240 241 242 243 244 24...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144269</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>2052.0</td>\n",
       "      <td>In conclusion, asking advice can help someone ...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>295 296 297 298 299 300 301 302 303 304 305 30...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144270</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>There has been at least one point in everyone'...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144271</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>318.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>Because of this, sometimes, asking just one pe...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 7...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144272</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>684.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>mistake,</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144273</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>693.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>misunderstanding,</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 2</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144274</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>714.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>misdeed.</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 3</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144275</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>725.0</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>While mistakes and misunderstanding might have...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>124 125 126 127 128 129 130 131 132 133 134 13...</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144276</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>1361.0</td>\n",
       "      <td>1471.0</td>\n",
       "      <td>The more similar iterations people give you, t...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 4</td>\n",
       "      <td>234 235 236 237 238 239 240 241 242 243 244 24...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144277</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>1881.0</td>\n",
       "      <td>Misunderstandings are harder to avoid because ...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>252 253 254 255 256 257 258 259 260 261 262 26...</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144278</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>1882.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>The best thing to do in a situation like that ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 5</td>\n",
       "      <td>326 327 328 329 330 331 332 333 334 335 336 33...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144279</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>2029.0</td>\n",
       "      <td>2123.0</td>\n",
       "      <td>misdeeds are when the advice-giver is purpose...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 6</td>\n",
       "      <td>354 355 356 357 358 359 360 361 362 363 364 36...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144280</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>2123.0</td>\n",
       "      <td>2702.0</td>\n",
       "      <td>An example of this is when you ask Generic_Nam...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 3</td>\n",
       "      <td>368 369 370 371 372 373 374 375 376 377 378 37...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144281</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>2703.0</td>\n",
       "      <td>2799.0</td>\n",
       "      <td>Now, I know what you probably saying \"But what...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Counterclaim 1</td>\n",
       "      <td>465 466 467 468 469 470 471 472 473 474 475 47...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144282</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>2817.0</td>\n",
       "      <td>2907.0</td>\n",
       "      <td>what are the odds that seven of your close fr...</td>\n",
       "      <td>Rebuttal</td>\n",
       "      <td>Rebuttal 1</td>\n",
       "      <td>487 488 489 490 491 492 493 494 495 496 497 49...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144283</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>2907.0</td>\n",
       "      <td>3140.0</td>\n",
       "      <td>The odds are in your favor; and the on the off...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>505 506 507 508 509 510 511 512 513 514 515 51...</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  discourse_id  discourse_start  discourse_end  \\\n",
       "144261  408A7D3D2EEC  1.618325e+12              0.0          228.0   \n",
       "144262  408A7D3D2EEC  1.618325e+12            229.0          294.0   \n",
       "144263  408A7D3D2EEC  1.618325e+12            303.0          339.0   \n",
       "144264  408A7D3D2EEC  1.618325e+12            340.0          356.0   \n",
       "144265  408A7D3D2EEC  1.618325e+12            362.0          392.0   \n",
       "144266  408A7D3D2EEC  1.618325e+12            470.0          779.0   \n",
       "144267  408A7D3D2EEC  1.618325e+12            876.0         1267.0   \n",
       "144268  408A7D3D2EEC  1.618325e+12           1356.0         1679.0   \n",
       "144269  408A7D3D2EEC  1.618325e+12           1680.0         2052.0   \n",
       "144270  AFEC37C2D43F  1.617803e+12              0.0          317.0   \n",
       "144271  AFEC37C2D43F  1.617803e+12            318.0          515.0   \n",
       "144272  AFEC37C2D43F  1.617803e+12            684.0          692.0   \n",
       "144273  AFEC37C2D43F  1.617803e+12            693.0          710.0   \n",
       "144274  AFEC37C2D43F  1.617803e+12            714.0          724.0   \n",
       "144275  AFEC37C2D43F  1.617803e+12            725.0         1360.0   \n",
       "144276  AFEC37C2D43F  1.617803e+12           1361.0         1471.0   \n",
       "144277  AFEC37C2D43F  1.617803e+12           1472.0         1881.0   \n",
       "144278  AFEC37C2D43F  1.617803e+12           1882.0         2019.0   \n",
       "144279  AFEC37C2D43F  1.617803e+12           2029.0         2123.0   \n",
       "144280  AFEC37C2D43F  1.617803e+12           2123.0         2702.0   \n",
       "144281  AFEC37C2D43F  1.617803e+12           2703.0         2799.0   \n",
       "144282  AFEC37C2D43F  1.617803e+12           2817.0         2907.0   \n",
       "144283  AFEC37C2D43F  1.617803e+12           2907.0         3140.0   \n",
       "\n",
       "                                           discourse_text  \\\n",
       "144261  Imagine seeking advice from multiple people an...   \n",
       "144262  Seeking multiple opinions can help someone mak...   \n",
       "144263               they can see which advice is better    \n",
       "144264                                   more experienced   \n",
       "144265                     see the persons point of view.   \n",
       "144266  Let's say this person needs to ask their teach...   \n",
       "144267   For instance, they need help picking a collag...   \n",
       "144268  For example, they can see what other people ha...   \n",
       "144269  In conclusion, asking advice can help someone ...   \n",
       "144270  There has been at least one point in everyone'...   \n",
       "144271  Because of this, sometimes, asking just one pe...   \n",
       "144272                                           mistake,   \n",
       "144273                                  misunderstanding,   \n",
       "144274                                          misdeed.    \n",
       "144275  While mistakes and misunderstanding might have...   \n",
       "144276  The more similar iterations people give you, t...   \n",
       "144277  Misunderstandings are harder to avoid because ...   \n",
       "144278  The best thing to do in a situation like that ...   \n",
       "144279   misdeeds are when the advice-giver is purpose...   \n",
       "144280  An example of this is when you ask Generic_Nam...   \n",
       "144281  Now, I know what you probably saying \"But what...   \n",
       "144282   what are the odds that seven of your close fr...   \n",
       "144283  The odds are in your favor; and the on the off...   \n",
       "\n",
       "              discourse_type      discourse_type_num  \\\n",
       "144261                  Lead                  Lead 1   \n",
       "144262              Position              Position 1   \n",
       "144263                 Claim                 Claim 1   \n",
       "144264                 Claim                 Claim 2   \n",
       "144265                 Claim                 Claim 3   \n",
       "144266              Evidence              Evidence 1   \n",
       "144267              Evidence              Evidence 2   \n",
       "144268              Evidence              Evidence 3   \n",
       "144269  Concluding Statement  Concluding Statement 1   \n",
       "144270                  Lead                  Lead 1   \n",
       "144271              Position              Position 1   \n",
       "144272                 Claim                 Claim 1   \n",
       "144273                 Claim                 Claim 2   \n",
       "144274                 Claim                 Claim 3   \n",
       "144275              Evidence              Evidence 1   \n",
       "144276                 Claim                 Claim 4   \n",
       "144277              Evidence              Evidence 2   \n",
       "144278                 Claim                 Claim 5   \n",
       "144279                 Claim                 Claim 6   \n",
       "144280              Evidence              Evidence 3   \n",
       "144281          Counterclaim          Counterclaim 1   \n",
       "144282              Rebuttal              Rebuttal 1   \n",
       "144283  Concluding Statement  Concluding Statement 1   \n",
       "\n",
       "                                         predictionstring  length_of_text  \n",
       "144261  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...              39  \n",
       "144262                      39 40 41 42 43 44 45 46 47 48              10  \n",
       "144263                               50 51 52 53 54 55 56               7  \n",
       "144264                                              57 58               2  \n",
       "144265                                  60 61 62 63 64 65               6  \n",
       "144266  79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 9...              57  \n",
       "144267  152 153 154 155 156 157 158 159 160 161 162 16...              67  \n",
       "144268  234 235 236 237 238 239 240 241 242 243 244 24...              61  \n",
       "144269  295 296 297 298 299 300 301 302 303 304 305 30...              65  \n",
       "144270  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...              61  \n",
       "144271  61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 7...              32  \n",
       "144272                                                120               1  \n",
       "144273                                                121               1  \n",
       "144274                                                123               1  \n",
       "144275  124 125 126 127 128 129 130 131 132 133 134 13...             110  \n",
       "144276  234 235 236 237 238 239 240 241 242 243 244 24...              18  \n",
       "144277  252 253 254 255 256 257 258 259 260 261 262 26...              74  \n",
       "144278  326 327 328 329 330 331 332 333 334 335 336 33...              27  \n",
       "144279  354 355 356 357 358 359 360 361 362 363 364 36...              14  \n",
       "144280  368 369 370 371 372 373 374 375 376 377 378 37...              97  \n",
       "144281  465 466 467 468 469 470 471 472 473 474 475 47...              17  \n",
       "144282  487 488 489 490 491 492 493 494 495 496 497 49...              18  \n",
       "144283  505 506 507 508 509 510 511 512 513 514 515 51...              46  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a82957d7-9740-4f44-b46b-e321ba0ab9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 scores\n",
      " * Lead      : 0.500000\n",
      " * Position  : 0.500000\n",
      " * Claim     : 0.500000\n",
      " * Counterclaim: 0.000000\n",
      " * Rebuttal  : 0.000000\n",
      " * Evidence  : 1.000000\n",
      " * Concluding Statement: 1.000000\n",
      "Overall Validation avg F1: 0.5000 \n"
     ]
    }
   ],
   "source": [
    "cc =gen_validation_report(submission,sample_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "971c9ea2-d036-400c-9ade-96a5f7e89a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 scores\n",
      " * Lead      : 0.500000\n",
      " * Position  : 0.500000\n",
      " * Claim     : 0.500000\n",
      " * Counterclaim: 0.000000\n",
      " * Rebuttal  : 0.000000\n",
      " * Evidence  : 1.000000\n",
      " * Concluding Statement: 1.000000\n",
      "Overall Validation avg F1: 0.5000 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "f1score =[]\n",
    "# classes = oof['class'].unique()\n",
    "classes = ['Lead', 'Position', 'Claim','Counterclaim', 'Rebuttal','Evidence','Concluding Statement']\n",
    "print(f\"Validation F1 scores\")\n",
    "\n",
    "for c in classes:\n",
    "    pred_df = submission.loc[submission['class'] == c].copy()\n",
    "    gt_df = sample_valid.loc[sample_valid['discourse_type'] == c].copy()\n",
    "    f1 = preprocessing.score_feedback_comp(pred_df, gt_df)\n",
    "    print(f' * {c:<10}: {f1:4f}')\n",
    "    f1score.append(f1)\n",
    "f1avg = np.mean(f1score)\n",
    "print(f'Overall Validation avg F1: {f1avg:.4f} ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9363723f-b16a-4f23-920d-408df91aa2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>294 295 296 297 298 299 300 301 302 303 304 30...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                 class  \\\n",
       "11  AFEC37C2D43F  Concluding Statement   \n",
       "\n",
       "                                     predictionstring  \n",
       "11  294 295 296 297 298 299 300 301 302 303 304 30...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "afa72037-4477-4059-b6a9-21f02b818b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id class                                   predictionstring\n",
       "5  408A7D3D2EEC  Lead  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...\n",
       "7  AFEC37C2D43F  Lead                       0 1 2 3 4 5 6 7 8 9 10 11 12"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.loc[submission['class'] == 'Lead']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "444e40ee-5bfd-4b59-83bd-9c3a145e44ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>length_of_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144261</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>Imagine seeking advice from multiple people an...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144270</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>There has been at least one point in everyone'...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  discourse_id  discourse_start  discourse_end  \\\n",
       "144261  408A7D3D2EEC  1.618325e+12              0.0          228.0   \n",
       "144270  AFEC37C2D43F  1.617803e+12              0.0          317.0   \n",
       "\n",
       "                                           discourse_text discourse_type  \\\n",
       "144261  Imagine seeking advice from multiple people an...           Lead   \n",
       "144270  There has been at least one point in everyone'...           Lead   \n",
       "\n",
       "       discourse_type_num                                   predictionstring  \\\n",
       "144261             Lead 1  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...   \n",
       "144270             Lead 1  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...   \n",
       "\n",
       "        length_of_text  \n",
       "144261              39  \n",
       "144270              61  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_valid.loc[sample_valid['discourse_type'] == 'Lead']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e001ba61-1846-4523-8f08-51d245c1dd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for discourse_type, gt_subset in gt_df.groupby(\"discourse_type\"):\n",
    "        pred_subset = pred_df.loc[pred_df[\"class\"] == discourse_type].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "86487530-d40c-4e3d-b2d0-8786957cf720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>294 295 296 297 298 299 300 301 302 303 304 30...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                 class  \\\n",
       "0  AFEC37C2D43F  Concluding Statement   \n",
       "\n",
       "                                    predictionstring  \n",
       "0  294 295 296 297 298 299 300 301 302 303 304 30...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3180ff41-6b38-4fe9-b2bb-7d1bc6a92972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>294 295 296 297 298 299 300 301 302 303 304 30...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                 class  \\\n",
       "11  AFEC37C2D43F  Concluding Statement   \n",
       "\n",
       "                                     predictionstring  \n",
       "11  294 295 296 297 298 299 300 301 302 303 304 30...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0081bdc8-d218-4418-990d-f062297341a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>length_of_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144269</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>2052.0</td>\n",
       "      <td>In conclusion, asking advice can help someone ...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>295 296 297 298 299 300 301 302 303 304 305 30...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144283</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>2907.0</td>\n",
       "      <td>3140.0</td>\n",
       "      <td>The odds are in your favor; and the on the off...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>505 506 507 508 509 510 511 512 513 514 515 51...</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  discourse_id  discourse_start  discourse_end  \\\n",
       "144269  408A7D3D2EEC  1.618325e+12           1680.0         2052.0   \n",
       "144283  AFEC37C2D43F  1.617803e+12           2907.0         3140.0   \n",
       "\n",
       "                                           discourse_text  \\\n",
       "144269  In conclusion, asking advice can help someone ...   \n",
       "144283  The odds are in your favor; and the on the off...   \n",
       "\n",
       "              discourse_type      discourse_type_num  \\\n",
       "144269  Concluding Statement  Concluding Statement 1   \n",
       "144283  Concluding Statement  Concluding Statement 1   \n",
       "\n",
       "                                         predictionstring  length_of_text  \n",
       "144269  295 296 297 298 299 300 301 302 303 304 305 30...              65  \n",
       "144283  505 506 507 508 509 510 511 512 513 514 515 51...              46  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2396526c-41fa-41f6-a175-983d8e7f3d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = pred_df.merge(\n",
    "    gt_df,\n",
    "    left_on=[\"id\", \"class\"],\n",
    "    right_on=[\"id\", \"discourse_type\"],\n",
    "    how=\"outer\",\n",
    "    suffixes=(\"_pred\", \"_gt\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b1135114-4f57-410a-8dec-2872d31fd344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predictionstring_pred</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring_gt</th>\n",
       "      <th>length_of_text</th>\n",
       "      <th>overlaps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>294 295 296 297 298 299 300 301 302 303 304 30...</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>2907.0</td>\n",
       "      <td>3140.0</td>\n",
       "      <td>The odds are in your favor; and the on the off...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>505 506 507 508 509 510 511 512 513 514 515 51...</td>\n",
       "      <td>46</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>2052.0</td>\n",
       "      <td>In conclusion, asking advice can help someone ...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>295 296 297 298 299 300 301 302 303 304 305 30...</td>\n",
       "      <td>65</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                 class  \\\n",
       "0  AFEC37C2D43F  Concluding Statement   \n",
       "1  408A7D3D2EEC                   NaN   \n",
       "\n",
       "                               predictionstring_pred  discourse_id  \\\n",
       "0  294 295 296 297 298 299 300 301 302 303 304 30...  1.617803e+12   \n",
       "1                                                     1.618325e+12   \n",
       "\n",
       "   discourse_start  discourse_end  \\\n",
       "0           2907.0         3140.0   \n",
       "1           1680.0         2052.0   \n",
       "\n",
       "                                      discourse_text        discourse_type  \\\n",
       "0  The odds are in your favor; and the on the off...  Concluding Statement   \n",
       "1  In conclusion, asking advice can help someone ...  Concluding Statement   \n",
       "\n",
       "       discourse_type_num                                predictionstring_gt  \\\n",
       "0  Concluding Statement 1  505 506 507 508 509 510 511 512 513 514 515 51...   \n",
       "1  Concluding Statement 1  295 296 297 298 299 300 301 302 303 304 305 30...   \n",
       "\n",
       "   length_of_text    overlaps  \n",
       "0              46  [0.0, 0.0]  \n",
       "1              65  [0.0, 0.0]  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "992cb1c7-260b-47a5-9935-cb26649d7e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_overlap(row):\n",
    "    \"\"\"\n",
    "    Calculates the overlap between prediction and\n",
    "    ground truth and overlap percentages used for determining\n",
    "    true positives.\n",
    "    \"\"\"\n",
    "    set_pred = set(row.predictionstring_pred.split(\" \"))\n",
    "    set_gt = set(row.predictionstring_gt.split(\" \"))\n",
    "    # Length of each and intersection\n",
    "    len_gt = len(set_gt)\n",
    "    len_pred = len(set_pred)\n",
    "    inter = len(set_gt.intersection(set_pred))\n",
    "    overlap_1 = inter / len_gt\n",
    "    overlap_2 = inter / len_pred\n",
    "    return [overlap_1, overlap_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "674138bc-d56c-4345-b1b8-a5d0ebf55c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined[\"predictionstring_gt\"] = joined[\"predictionstring_gt\"].fillna(\" \")\n",
    "joined[\"predictionstring_pred\"] = joined[\"predictionstring_pred\"].fillna(\" \")\n",
    "\n",
    "joined[\"overlaps\"] = joined.apply(calc_overlap, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c497e7-c090-44be-ba82-784ad521d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[\"pred_id\"] = pred_df.index\n",
    "gt_df[\"gt_id\"] = gt_df.index\n",
    "# Step 1. all ground truths and predictions for a given class are compared.\n",
    "joined = pred_df.merge(\n",
    "    gt_df,\n",
    "    left_on=[\"id\", \"class\"],\n",
    "    right_on=[\"id\", \"discourse_type\"],\n",
    "    how=\"outer\",\n",
    "    suffixes=(\"_pred\", \"_gt\"),\n",
    ")\n",
    "joined[\"predictionstring_gt\"] = joined[\"predictionstring_gt\"].fillna(\" \")\n",
    "joined[\"predictionstring_pred\"] = joined[\"predictionstring_pred\"].fillna(\" \")\n",
    "\n",
    "joined[\"overlaps\"] = joined.apply(calc_overlap, axis=1)\n",
    "\n",
    "# 2. If the overlap between the ground truth and prediction is >= 0.5,\n",
    "# and the overlap between the prediction and the ground truth >= 0.5,\n",
    "# the prediction is a match and considered a true positive.\n",
    "# If multiple matches exist, the match with the highest pair of overlaps is taken.\n",
    "joined[\"overlap1\"] = joined[\"overlaps\"].apply(lambda x: eval(str(x))[0])\n",
    "joined[\"overlap2\"] = joined[\"overlaps\"].apply(lambda x: eval(str(x))[1])\n",
    "\n",
    "joined[\"potential_TP\"] = (joined[\"overlap1\"] >= 0.5) & (joined[\"overlap2\"] >= 0.5)\n",
    "joined[\"max_overlap\"] = joined[[\"overlap1\", \"overlap2\"]].max(axis=1)\n",
    "tp_pred_ids = (\n",
    "    joined.query(\"potential_TP\")\n",
    "    .sort_values(\"max_overlap\", ascending=False)\n",
    "    .groupby([\"id\", \"predictionstring_gt\"])\n",
    "    .first()[\"pred_id\"]\n",
    "    .values\n",
    ")\n",
    "\n",
    "# 3. Any unmatched ground truths are false negatives\n",
    "# and any unmatched predictions are false positives.\n",
    "fp_pred_ids = [p for p in joined[\"pred_id\"].unique() if p not in tp_pred_ids]\n",
    "\n",
    "matched_gt_ids = joined.query(\"potential_TP\")[\"gt_id\"].unique()\n",
    "unmatched_gt_ids = [c for c in joined[\"gt_id\"].unique() if c not in matched_gt_ids]\n",
    "\n",
    "# Get numbers of each type\n",
    "TP = len(tp_pred_ids)\n",
    "FP = len(fp_pred_ids)\n",
    "FN = len(unmatched_gt_ids)\n",
    "# calc microf1\n",
    "my_f1_score = TP / (TP + 0.5 * (FP + FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50706db-e8b5-4f71-98a5-fc7db7fa1c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be81ace-d895-47ea-ba41-0b4cce24399a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0581798-034a-40c1-8927-3ee832f6dd7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36a8d56-9113-448e-8d56-378330fe621e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9a9ce22-6248-4174-bd43-b1394917a70c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>length_of_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144261</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>Imagine seeking advice from multiple people an...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144262</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>229.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>Seeking multiple opinions can help someone mak...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>39 40 41 42 43 44 45 46 47 48</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144263</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>303.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>they can see which advice is better</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>50 51 52 53 54 55 56</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144264</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>340.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>more experienced</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 2</td>\n",
       "      <td>57 58</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144265</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>362.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>see the persons point of view.</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 3</td>\n",
       "      <td>60 61 62 63 64 65</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144266</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>470.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>Let's say this person needs to ask their teach...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 9...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144267</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>876.0</td>\n",
       "      <td>1267.0</td>\n",
       "      <td>For instance, they need help picking a collag...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>152 153 154 155 156 157 158 159 160 161 162 16...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144268</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>1356.0</td>\n",
       "      <td>1679.0</td>\n",
       "      <td>For example, they can see what other people ha...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 3</td>\n",
       "      <td>234 235 236 237 238 239 240 241 242 243 244 24...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144269</th>\n",
       "      <td>408A7D3D2EEC</td>\n",
       "      <td>1.618325e+12</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>2052.0</td>\n",
       "      <td>In conclusion, asking advice can help someone ...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>295 296 297 298 299 300 301 302 303 304 305 30...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144270</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>There has been at least one point in everyone'...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144271</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>318.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>Because of this, sometimes, asking just one pe...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 7...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144272</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>684.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>mistake,</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144273</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>693.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>misunderstanding,</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 2</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144274</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>714.0</td>\n",
       "      <td>724.0</td>\n",
       "      <td>misdeed.</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 3</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144275</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>725.0</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>While mistakes and misunderstanding might have...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>124 125 126 127 128 129 130 131 132 133 134 13...</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144276</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>1361.0</td>\n",
       "      <td>1471.0</td>\n",
       "      <td>The more similar iterations people give you, t...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 4</td>\n",
       "      <td>234 235 236 237 238 239 240 241 242 243 244 24...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144277</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>1881.0</td>\n",
       "      <td>Misunderstandings are harder to avoid because ...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>252 253 254 255 256 257 258 259 260 261 262 26...</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144278</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>1882.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>The best thing to do in a situation like that ...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 5</td>\n",
       "      <td>326 327 328 329 330 331 332 333 334 335 336 33...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144279</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>2029.0</td>\n",
       "      <td>2123.0</td>\n",
       "      <td>misdeeds are when the advice-giver is purpose...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 6</td>\n",
       "      <td>354 355 356 357 358 359 360 361 362 363 364 36...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144280</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>2123.0</td>\n",
       "      <td>2702.0</td>\n",
       "      <td>An example of this is when you ask Generic_Nam...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 3</td>\n",
       "      <td>368 369 370 371 372 373 374 375 376 377 378 37...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144281</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>2703.0</td>\n",
       "      <td>2799.0</td>\n",
       "      <td>Now, I know what you probably saying \"But what...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Counterclaim 1</td>\n",
       "      <td>465 466 467 468 469 470 471 472 473 474 475 47...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144282</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>2817.0</td>\n",
       "      <td>2907.0</td>\n",
       "      <td>what are the odds that seven of your close fr...</td>\n",
       "      <td>Rebuttal</td>\n",
       "      <td>Rebuttal 1</td>\n",
       "      <td>487 488 489 490 491 492 493 494 495 496 497 49...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144283</th>\n",
       "      <td>AFEC37C2D43F</td>\n",
       "      <td>1.617803e+12</td>\n",
       "      <td>2907.0</td>\n",
       "      <td>3140.0</td>\n",
       "      <td>The odds are in your favor; and the on the off...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>Concluding Statement 1</td>\n",
       "      <td>505 506 507 508 509 510 511 512 513 514 515 51...</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  discourse_id  discourse_start  discourse_end  \\\n",
       "144261  408A7D3D2EEC  1.618325e+12              0.0          228.0   \n",
       "144262  408A7D3D2EEC  1.618325e+12            229.0          294.0   \n",
       "144263  408A7D3D2EEC  1.618325e+12            303.0          339.0   \n",
       "144264  408A7D3D2EEC  1.618325e+12            340.0          356.0   \n",
       "144265  408A7D3D2EEC  1.618325e+12            362.0          392.0   \n",
       "144266  408A7D3D2EEC  1.618325e+12            470.0          779.0   \n",
       "144267  408A7D3D2EEC  1.618325e+12            876.0         1267.0   \n",
       "144268  408A7D3D2EEC  1.618325e+12           1356.0         1679.0   \n",
       "144269  408A7D3D2EEC  1.618325e+12           1680.0         2052.0   \n",
       "144270  AFEC37C2D43F  1.617803e+12              0.0          317.0   \n",
       "144271  AFEC37C2D43F  1.617803e+12            318.0          515.0   \n",
       "144272  AFEC37C2D43F  1.617803e+12            684.0          692.0   \n",
       "144273  AFEC37C2D43F  1.617803e+12            693.0          710.0   \n",
       "144274  AFEC37C2D43F  1.617803e+12            714.0          724.0   \n",
       "144275  AFEC37C2D43F  1.617803e+12            725.0         1360.0   \n",
       "144276  AFEC37C2D43F  1.617803e+12           1361.0         1471.0   \n",
       "144277  AFEC37C2D43F  1.617803e+12           1472.0         1881.0   \n",
       "144278  AFEC37C2D43F  1.617803e+12           1882.0         2019.0   \n",
       "144279  AFEC37C2D43F  1.617803e+12           2029.0         2123.0   \n",
       "144280  AFEC37C2D43F  1.617803e+12           2123.0         2702.0   \n",
       "144281  AFEC37C2D43F  1.617803e+12           2703.0         2799.0   \n",
       "144282  AFEC37C2D43F  1.617803e+12           2817.0         2907.0   \n",
       "144283  AFEC37C2D43F  1.617803e+12           2907.0         3140.0   \n",
       "\n",
       "                                           discourse_text  \\\n",
       "144261  Imagine seeking advice from multiple people an...   \n",
       "144262  Seeking multiple opinions can help someone mak...   \n",
       "144263               they can see which advice is better    \n",
       "144264                                   more experienced   \n",
       "144265                     see the persons point of view.   \n",
       "144266  Let's say this person needs to ask their teach...   \n",
       "144267   For instance, they need help picking a collag...   \n",
       "144268  For example, they can see what other people ha...   \n",
       "144269  In conclusion, asking advice can help someone ...   \n",
       "144270  There has been at least one point in everyone'...   \n",
       "144271  Because of this, sometimes, asking just one pe...   \n",
       "144272                                           mistake,   \n",
       "144273                                  misunderstanding,   \n",
       "144274                                          misdeed.    \n",
       "144275  While mistakes and misunderstanding might have...   \n",
       "144276  The more similar iterations people give you, t...   \n",
       "144277  Misunderstandings are harder to avoid because ...   \n",
       "144278  The best thing to do in a situation like that ...   \n",
       "144279   misdeeds are when the advice-giver is purpose...   \n",
       "144280  An example of this is when you ask Generic_Nam...   \n",
       "144281  Now, I know what you probably saying \"But what...   \n",
       "144282   what are the odds that seven of your close fr...   \n",
       "144283  The odds are in your favor; and the on the off...   \n",
       "\n",
       "              discourse_type      discourse_type_num  \\\n",
       "144261                  Lead                  Lead 1   \n",
       "144262              Position              Position 1   \n",
       "144263                 Claim                 Claim 1   \n",
       "144264                 Claim                 Claim 2   \n",
       "144265                 Claim                 Claim 3   \n",
       "144266              Evidence              Evidence 1   \n",
       "144267              Evidence              Evidence 2   \n",
       "144268              Evidence              Evidence 3   \n",
       "144269  Concluding Statement  Concluding Statement 1   \n",
       "144270                  Lead                  Lead 1   \n",
       "144271              Position              Position 1   \n",
       "144272                 Claim                 Claim 1   \n",
       "144273                 Claim                 Claim 2   \n",
       "144274                 Claim                 Claim 3   \n",
       "144275              Evidence              Evidence 1   \n",
       "144276                 Claim                 Claim 4   \n",
       "144277              Evidence              Evidence 2   \n",
       "144278                 Claim                 Claim 5   \n",
       "144279                 Claim                 Claim 6   \n",
       "144280              Evidence              Evidence 3   \n",
       "144281          Counterclaim          Counterclaim 1   \n",
       "144282              Rebuttal              Rebuttal 1   \n",
       "144283  Concluding Statement  Concluding Statement 1   \n",
       "\n",
       "                                         predictionstring  length_of_text  \n",
       "144261  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...              39  \n",
       "144262                      39 40 41 42 43 44 45 46 47 48              10  \n",
       "144263                               50 51 52 53 54 55 56               7  \n",
       "144264                                              57 58               2  \n",
       "144265                                  60 61 62 63 64 65               6  \n",
       "144266  79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 9...              57  \n",
       "144267  152 153 154 155 156 157 158 159 160 161 162 16...              67  \n",
       "144268  234 235 236 237 238 239 240 241 242 243 244 24...              61  \n",
       "144269  295 296 297 298 299 300 301 302 303 304 305 30...              65  \n",
       "144270  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...              61  \n",
       "144271  61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 7...              32  \n",
       "144272                                                120               1  \n",
       "144273                                                121               1  \n",
       "144274                                                123               1  \n",
       "144275  124 125 126 127 128 129 130 131 132 133 134 13...             110  \n",
       "144276  234 235 236 237 238 239 240 241 242 243 244 24...              18  \n",
       "144277  252 253 254 255 256 257 258 259 260 261 262 26...              74  \n",
       "144278  326 327 328 329 330 331 332 333 334 335 336 33...              27  \n",
       "144279  354 355 356 357 358 359 360 361 362 363 364 36...              14  \n",
       "144280  368 369 370 371 372 373 374 375 376 377 378 37...              97  \n",
       "144281  465 466 467 468 469 470 471 472 473 474 475 47...              17  \n",
       "144282  487 488 489 490 491 492 493 494 495 496 497 49...              18  \n",
       "144283  505 506 507 508 509 510 511 512 513 514 515 51...              46  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882f48b6-c4f5-4841-83ec-7e3711e90960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fe669e-b375-418a-8849-ec895327f764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5048ab38-8614-487d-8ef5-28f5972a6814",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7bc52060-d3e9-4b02-bdc9-ed62dda3579d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 test texts.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# GET TEST TEXT IDS\n",
    "files = os.listdir('inputs/test/')\n",
    "TEST_IDS = [f.replace('.txt','') for f in files if 'txt' in f]\n",
    "print('There are',len(TEST_IDS),'test texts.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8eb97028-3f8b-4867-a078-51783eea3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT TEST TEXT TO TOKENS\n",
    "MAX_LEN= 4096\n",
    "test_tokens = np.zeros((len(TEST_IDS),MAX_LEN), dtype='int32')\n",
    "test_attention = np.zeros((len(TEST_IDS),MAX_LEN), dtype='int32')\n",
    "\n",
    "for id_num in range(len(TEST_IDS)):\n",
    "        \n",
    "    # READ TRAIN TEXT, TOKENIZE, AND SAVE IN TOKEN ARRAYS    \n",
    "    n = TEST_IDS[id_num]\n",
    "    name = f'inputs/test/{n}.txt'\n",
    "    txt = open(name, 'r').read()\n",
    "    tokens = tokenizer.encode_plus(txt, max_length=MAX_LEN, padding='max_length',\n",
    "                                   truncation=True, return_offsets_mapping=True)\n",
    "    test_tokens[id_num,] = tokens['input_ids']\n",
    "    test_attention[id_num,] = tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "872b54c9-4455-4c29-90a8-b436e4b4c238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,  2940,   207, ...,     1,     1,     1],\n",
       "       [    0,  1779,    82, ...,     1,     1,     1],\n",
       "       [    0, 14229,    10, ...,     1,     1,     1],\n",
       "       [    0, 17781,    47, ...,     1,     1,     1],\n",
       "       [    0, 31845,  5717, ...,     1,     1,     1]], dtype=int32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d2c29ccf-0ed8-4188-9141-4ef3501d6ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70f2ba4-b785-44c0-b6af-518af1fbfd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' model.predict([test_tokens, test_attention], \n",
    "                  batch_size=16, verbose=2)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
